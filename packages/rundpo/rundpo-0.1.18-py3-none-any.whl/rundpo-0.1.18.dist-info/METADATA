Metadata-Version: 2.4
Name: rundpo
Version: 0.1.18
Summary: A modern, async-first Python client for the Rundpo API
Project-URL: Homepage, https://github.com/rundpo/rundpo-python
Project-URL: Bug Tracker, https://github.com/rundpo/rundpo-python/issues
Author-email: Rundpo Team <team@rundpo.com>
License-File: LICENSE
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: requests>=2.28.0
Description-Content-Type: text/markdown

# Rundpo Python Client

A modern, async-first Python client for the Rundpo API. This client provides a convenient way to interact with the Rundpo API for running DPO (Direct Preference Optimization) training.

## Installation

```bash
pip install rundpo
```

## Usage

The client provides both async and sync interfaces. Here's how to use them:

### Async Usage

```python
import os
import asyncio
import time
from rundpo import AsyncRundpoClient, DPOConfig, RunConfig, RunStatus

async def main():
    # Initialize the client
    async with AsyncRundpoClient(
        api_key=os.environ.get("RUNDPO_API_KEY")
    ) as client:
        # Check credits
        credits = await client.get_credits()
        print(f"Remaining credits: {credits}")

        # Upload a file
        file_upload = await client.upload_file("path/to/your/data.jsonl")
        print(f"File uploaded successfully! ID: {file_upload.file_id}")
        
        # Configure DPO run
        config = DPOConfig(
            file_id=file_upload.file_id,
            run_config=RunConfig(
                model_name="mistralai/Mistral-7B-v0.1",
                learning_rate=1e-5,
                num_epochs=3,
                batch_size=8,
                gradient_accumulation_steps=4,
                warmup_steps=100
            )
        )
        
        # Start DPO training
        run_id = await client.run_dpo(config)
        print(f"Started DPO run with ID: {run_id}")
        
        # Poll for completion
        while True:
            status = await client.get_status(run_id)
            print(f"Run status: {status}")
            
            if status in [RunStatus.COMPLETED, RunStatus.FAILED]:
                break
                
            # Wait 30 seconds before checking again
            await asyncio.sleep(30)

asyncio.run(main())
```

### Sync Usage

```python
from rundpo import RundpoClient, DPOConfig, RunConfig, RunStatus
import time

# Initialize the client
client = RundpoClient(api_key="your-api-key")

# Check credits
credits = client.get_credits()
print(f"Remaining credits: {credits}")

# List existing files
files = client.list_files()
for file in files:
    print(f"File: {file.file_id}")

# Run DPO using HuggingFace datasets
config = DPOConfig(
    hf_sft_dataset_name="your-sft-dataset",
    hf_dpo_dataset_name="your-dpo-dataset",
    run_config=RunConfig(
        model_name="mistralai/Mistral-7B-v0.1",
        learning_rate=1e-5,
        num_epochs=3,
        batch_size=8,
        gradient_accumulation_steps=4,
        warmup_steps=100
    )
)

run_id = client.run_dpo(config)
print(f"Started DPO run with ID: {run_id}")

# Poll for completion
while True:
    status = client.get_status(run_id)
    print(f"Run status: {status}")
    
    if status in [RunStatus.COMPLETED, RunStatus.FAILED]:
        break
        
    # Wait 30 seconds before checking again
    time.sleep(30)
```

## API Reference

### Clients

- `AsyncRundpoClient`: Async-first client for modern Python applications
- `RundpoClient`: Synchronous client for simpler use cases

### Data Classes

- `RunConfig`: Configuration for training runs
- `DPOConfig`: Configuration specific to DPO training
- `FileUpload`: Represents an uploaded file
- `RunStatus`: Enum of possible run statuses:
  - `PENDING`: Initial state
  - `PROVISIONING`: Setting up GPUs
  - `LAUNCHING_SFT`: Starting SFT training
  - `TRAINING_SFT`: Running SFT training
  - `PREPARING_DPO`: Preparing for DPO training
  - `LAUNCHING_DPO`: Starting DPO training
  - `TRAINING_DPO`: Running DPO training
  - `SAVING_MODEL`: Saving the trained model
  - `FREEING_GPUS`: Cleaning up resources
  - `COMPLETED`: Run completed successfully
  - `FAILED`: Run failed

## License

MIT
