{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatizing new matches downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import requests\n",
    "from io import StringIO\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining match data from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match_data:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the class with the given URL.\n",
    "        \n",
    "        Args:\n",
    "            url (str): The URL to scrape match data from.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.links = []  # List to store match links\n",
    "        self.gameweeks = []  # List to store gameweek data\n",
    "    \n",
    "    def get_links(self):\n",
    "        \"\"\"\n",
    "        Get the match report links from the provided URL.\n",
    "        \n",
    "        This function scrapes the provided URL for match report links and stores them in the 'links' list.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the match report links.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)  # Send HTTP request to the URL\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')  # Parse the HTML content\n",
    "\n",
    "        # Find all cells containing match report links\n",
    "        report_cells = soup.find_all('td', {'data-stat': 'match_report'})\n",
    "\n",
    "        # Loop through each cell to extract the match links\n",
    "        for idx, cell in enumerate(report_cells):\n",
    "            link = cell.find('a')  # Find the anchor tag in the cell\n",
    "            if link:\n",
    "                url = link['href']  # Extract the link URL\n",
    "                self.links.append(f'https://fbref.com{url}')  # Append the full URL to the links list\n",
    "\n",
    "            # Stop after extracting a certain number of links (e.g., 5)\n",
    "            #if len(self.links) >= 2:\n",
    "            #    break\n",
    "            \n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        # Save the links to a DataFrame\n",
    "        df_links = pd.DataFrame(self.links, columns=['link'])\n",
    "\n",
    "        return df_links  # Return the cleaned DataFrame of links\n",
    "\n",
    "    def get_gameweek(self):\n",
    "        \"\"\"\n",
    "        Get the gameweek data from the provided URL.\n",
    "        \n",
    "        This function scrapes the provided URL for gameweek data and stores it in the 'gameweeks' list.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the gameweek data.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)  # Send HTTP request to the URL\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')  # Parse the HTML content\n",
    "\n",
    "        # Find all cells containing gameweek data\n",
    "        gameweek_cells = soup.find_all('th', {'data-stat': 'gameweek'})\n",
    "\n",
    "        # Loop through each cell to extract the gameweek values\n",
    "        for idx, cell in enumerate(gameweek_cells):\n",
    "            gameweek_value = cell.text.strip() if cell else 'N/A'  # Extract and clean the gameweek value\n",
    "\n",
    "            # Skip the 'Sem.' or empty values\n",
    "            if gameweek_value in ['Sem.', '']:\n",
    "                continue  # Skip this iteration and move to the next cell\n",
    "\n",
    "            self.gameweeks.append(gameweek_value)  # Append the value to the gameweeks list\n",
    "\n",
    "            # Stop after extracting a certain number of valid gameweeks (e.g., 5)\n",
    "            #if len(self.gameweeks) >= 2:\n",
    "            #    break\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        # Create a DataFrame from the gameweeks list\n",
    "        df_gameweeks = pd.DataFrame(self.gameweeks, columns=['gameweek'])\n",
    "\n",
    "        # Remove rows where the gameweek is 'Sem.' or empty\n",
    "        df_gameweeks = df_gameweeks[~df_gameweeks['gameweek'].isin(['Sem.', ''])]\n",
    "\n",
    "        return df_gameweeks  # Return the cleaned DataFrame of gameweeks\n",
    "\n",
    "    def create_matches_csv(self):\n",
    "        \"\"\"\n",
    "        Create a CSV file with match data, combining gameweek and match information.\n",
    "        \n",
    "        This function combines match details (e.g., teams, date, time) and gameweek data into a single DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing match details and gameweek data.\n",
    "        \"\"\"\n",
    "        # Create a DataFrame with empty values for the match data\n",
    "        df = pd.DataFrame({\n",
    "            'id': pd.Series([None] * len(self.links)),  # Create a new column with unique IDs for each match\n",
    "            'date_of_match': pd.Series([None] * len(self.links)),  \n",
    "            'hour_of_the_match': pd.Series([None] * len(self.links)),  \n",
    "            'home_team_name': pd.Series([None] * len(self.links)),  \n",
    "            'away_team_name': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'home_trainer': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'away_trainer': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'stadium': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'attendance': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'referee': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'var': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'home_team_lineup': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'away_team_lineup': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'home_possession': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'away_possession': pd.Series([None] * len(self.links), dtype='object')\n",
    "        })\n",
    "\n",
    "        # Ensure that the 'date_of_match' column is converted to datetime format\n",
    "        df['date_of_match'] = pd.to_datetime(df['date_of_match'], format='%Y-%m-%d', errors='coerce') \n",
    "        # Ensure that the 'hour_of_the_match' column is converted to string format\n",
    "        df['hour_of_the_match'] = df['hour_of_the_match'].astype(str)\n",
    "\n",
    "        # Ensure that other columns are of the correct data type (string)\n",
    "        df['home_team_name'] = df['home_team_name'].astype(object)\n",
    "        df['away_team_name'] = df['away_team_name'].astype(str)\n",
    "        df['home_trainer'] = df['home_trainer'].astype(str)\n",
    "        df['away_trainer'] = df['away_trainer'].astype(str)\n",
    "        df['stadium'] = df['stadium'].astype(str)\n",
    "        df['attendance'] = df['attendance'].astype(str)\n",
    "        df['referee'] = df['referee'].astype(str)\n",
    "        df['var'] = df['var'].astype(str)\n",
    "        df['home_team_lineup'] = df['home_team_lineup'].astype(str)\n",
    "        df['away_team_lineup'] = df['away_team_lineup'].astype(str)\n",
    "        df['home_possession'] = df['home_possession'].astype(str)\n",
    "        df['away_possession'] = df['away_possession'].astype(str)\n",
    "\n",
    "        # Get the links data\n",
    "        links = self.get_links()\n",
    "\n",
    "        # Get the gameweek data\n",
    "        gameweeks = self.get_gameweek()\n",
    "\n",
    "        # Create a DataFrame from the gameweek data and links data\n",
    "        df_gameweeks = pd.DataFrame(gameweeks, columns=['gameweek'])\n",
    "        df_links = pd.DataFrame(links, columns=['link'])\n",
    "\n",
    "        df_final = pd.concat([gameweeks, df], axis=1)\n",
    "        df_final = pd.concat([df_final, df_links], axis=1)\n",
    "\n",
    "        # Assign the final DataFrame to the class attribute with the new name\n",
    "        self.df_final = df_final  \n",
    "\n",
    "        return self.df_final  # Return the DataFrame to be used later\n",
    "\n",
    "    def get_statistics(self):\n",
    "        \"\"\"\n",
    "        Get match statistics from the links and save them to a CSV file.\n",
    "        \n",
    "        This function extracts detailed statistics (e.g., team lineups, referee, attendance) from the match links.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing match statistics.\n",
    "        \"\"\"\n",
    "        # Directly use the self.df DataFrame that contains the match and link data\n",
    "        \n",
    "        links = self.df_final['link'].tolist()  \n",
    "\n",
    "        id = 0\n",
    "\n",
    "        # Loop through each match link and extract the statistics\n",
    "        for idx, link in enumerate(links):\n",
    "            try:\n",
    "                print(f\"Processing link {idx + 1}: {link}\")\n",
    "                headers = {\n",
    "                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "                    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "                    \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "                    \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "                    \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "                    \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "                    \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "                }\n",
    "                response = requests.get(link, headers=headers)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Initialize default values for match statistics\n",
    "                match_date = \"Unknown\"\n",
    "                match_time = \"Unknown\"\n",
    "                home_team_name = \"Unknown\"\n",
    "                away_team_name = \"Unknown\"\n",
    "                home_trainer = \"Unknown\"\n",
    "                away_trainer = \"Unknown\"\n",
    "                stadium = \"Unknown\"\n",
    "                attendance = \"Unknown\"\n",
    "                referee = \"Unknown\"\n",
    "                var = \"Unknown\"\n",
    "                home_team_lineup = \"Unknown\"\n",
    "                away_team_lineup = \"Unknown\"\n",
    "                home_possession = \"Unknown\"\n",
    "                away_possession = \"Unknown\"\n",
    "\n",
    "                # ID for each match\n",
    "                id += 1\n",
    "                self.df_final.at[idx, 'id'] = id\n",
    "\n",
    "                # Extract match date and time\n",
    "                date_element = soup.find('span', {'class': 'venuetime'})\n",
    "                if date_element:\n",
    "                    match_date = date_element.get('data-venue-date', \"Unknown\")\n",
    "                    match_time = date_element.get('data-venue-time', \"Unknown\")\n",
    "                self.df_final.at[idx, 'date_of_match'] = match_date\n",
    "                self.df_final.at[idx, 'hour_of_the_match'] = match_time\n",
    "\n",
    "                # Extract team names\n",
    "                teams_elements = soup.find_all('span', class_='teamandlogo')\n",
    "                if len(teams_elements) >= 2:\n",
    "                    home_team_name = teams_elements[0].text.strip()\n",
    "                    away_team_name = teams_elements[1].text.strip()\n",
    "                self.df_final.at[idx, 'home_team_name'] = home_team_name\n",
    "                self.df_final.at[idx, 'away_team_name'] = away_team_name\n",
    "\n",
    "                # Extract trainers (coaches) names\n",
    "                trainers_elements = soup.find_all('div', class_='datapoint')\n",
    "                trainer_count = 0\n",
    "                for trainer_element in trainers_elements:\n",
    "                    if 'Director Técnico' in trainer_element.text:\n",
    "                        trainer_name = trainer_element.text.split(':')[-1].strip()\n",
    "                        if trainer_count == 0:\n",
    "                            home_trainer = trainer_name\n",
    "                            trainer_count += 1\n",
    "                        elif trainer_count == 1:\n",
    "                            away_trainer = trainer_name\n",
    "                            trainer_count += 1\n",
    "                self.df_final.at[idx, 'home_trainer'] = home_trainer\n",
    "                self.df_final.at[idx, 'away_trainer'] = away_trainer\n",
    "\n",
    "                # Extract stadium information\n",
    "                stadium_element = soup.find('div', class_='scorebox_meta')\n",
    "                if stadium_element:\n",
    "                    stadium_info = stadium_element.find('strong', string=\"Sedes\")\n",
    "                    if stadium_info:\n",
    "                        stadium = stadium_info.find_next('small').find_next('small').text.strip()\n",
    "                self.df_final.at[idx, 'stadium'] = stadium\n",
    "\n",
    "                # Extract attendance information\n",
    "                attendance_element = soup.find('div', class_='scorebox_meta')\n",
    "                if attendance_element:\n",
    "                    attendance_info = attendance_element.find('strong', string=\"Asistencia\")\n",
    "                    if attendance_info:\n",
    "                        attendance = attendance_info.find_next('small').find_next('small').text.strip()\n",
    "                        try:\n",
    "                            attendance = int(attendance.replace(',', '').replace('.', ''))\n",
    "                        except ValueError:\n",
    "                            attendance = None\n",
    "                self.df_final.at[idx, 'attendance'] = attendance\n",
    "\n",
    "                # Extract referee information\n",
    "                referee_element = soup.find('div', class_='scorebox_meta')\n",
    "                if referee_element:\n",
    "                    referee_info = referee_element.find_next('strong', string=\"Autoridades\")\n",
    "                    if referee_info:\n",
    "                        referee_span = referee_info.find_next('small').find_next('small').find('span', style=\"display:inline-block\")\n",
    "                        if referee_span:\n",
    "                            referee = referee_span.text.strip()\n",
    "                self.df_final.at[idx, 'referee'] = referee\n",
    "\n",
    "                # Extract VAR information\n",
    "                var_element = soup.find('div', class_='scorebox_meta')\n",
    "                if var_element:\n",
    "                    var_info = var_element.find_next('strong', string=\"Autoridades\")\n",
    "                    if var_info:\n",
    "                        var_span = var_info.find_next('small').find_next('small').find_next('span').find_next('span').find_next('span').find_next('span').find_next('span')\n",
    "                        if var_span:\n",
    "                            var = var_span.text.strip()\n",
    "                self.df_final.at[idx, 'var'] = var\n",
    "\n",
    "                # Extract team lineups\n",
    "                lineup_elements = soup.find_all('th', string=lambda text: text and '(' in text and ')' in text)\n",
    "                if len(lineup_elements) >= 1:\n",
    "                    home_match = re.search(r'\\((.*?)\\)', lineup_elements[0].text)\n",
    "                    if home_match:\n",
    "                        home_team_lineup = home_match.group(1)\n",
    "                if len(lineup_elements) >= 2:\n",
    "                    away_match = re.search(r'\\((.*?)\\)', lineup_elements[1].text)\n",
    "                    if away_match:\n",
    "                        away_team_lineup = away_match.group(1)\n",
    "                self.df_final.at[idx, 'home_team_lineup'] = home_team_lineup\n",
    "                self.df_final.at[idx, 'away_team_lineup'] = away_team_lineup\n",
    "\n",
    "                # Extract team possession\n",
    "                # Find the header \"Posesión del balón\" (Ball Possession)\n",
    "                possession_header = soup.find('th', string=\"Posesión del balón\")\n",
    "\n",
    "                # If the header is found, extract the corresponding values\n",
    "                if possession_header:\n",
    "                    # Find the <tr> following the header and extract all <strong> elements\n",
    "                    possession_values = possession_header.find_next('tr').find_all('strong')\n",
    "                    if len(possession_values) == 2:\n",
    "                        # Extract and clean the values (remove the '%' symbol)\n",
    "                        home_possession = possession_values[0].text.strip('%')  # Home team's possession\n",
    "                        away_possession = possession_values[1].text.strip('%')  # Away team's possession\n",
    "                    else:\n",
    "                        print(\"Possession values not found.\")\n",
    "                else:\n",
    "                    print(\"Header 'Posesión del balón' not found.\")\n",
    "\n",
    "                # Remove rows that are completely empty\n",
    "                self.df_final = self.df_final.dropna(how='all')\n",
    "\n",
    "                time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing link {link}: {e}\")\n",
    "                continue\n",
    "\n",
    "        self.df_matches = self.df_final \n",
    "        return self.df_matches\n",
    "\n",
    "    def save_to_csv(self, season):\n",
    "        \"\"\"\n",
    "        Save the processed data into a CSV file, with the season included in the filename.\n",
    "        \n",
    "        Args:\n",
    "            season (str): The season to be included in the filename.\n",
    "        \"\"\"\n",
    "        # Define the filename with the season\n",
    "        filename = f'matches_{season}.csv'\n",
    "\n",
    "        # Save the DataFrame to a CSV file in the parent directory\n",
    "        self.df_matches.to_csv(filename, index=False)\n",
    "\n",
    "        # Print confirmation message with the file path\n",
    "        print(f\"File saved as {filename}\")\n",
    "\n",
    "    def run(self, url):\n",
    "        \"\"\"\n",
    "        Execute the full process: get links, get gameweeks, get statistics, and save to CSV files for both teams.\n",
    "        \n",
    "        Args:\n",
    "            url (str): The URL to start scraping the data from.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting matches data...\")\n",
    "\n",
    "        # Step 1: Extract the season from the URL\n",
    "        season_match = re.search(r'(\\d{4})-(\\d{4})', url)\n",
    "        if season_match:\n",
    "            season = season_match.group(0)\n",
    "        else:\n",
    "            season = 'unknown_season'  # Default value if the season cannot be extracted\n",
    "\n",
    "        # Step 2: Get all the links to the match pages from the provided URL\n",
    "\n",
    "        # Step 3: Get the gameweek data from the provided URL\n",
    "\n",
    "        # Step 4: Create a CSV file with match details, such as teams, dates, and other match-related information\n",
    "        self.create_matches_csv()\n",
    "\n",
    "        # Step 5: Retrieve statistics for each match, such as goals, assists, and other relevant data\n",
    "        df_matches = self.get_statistics()\n",
    "\n",
    "        # Step 6: Save the processed data into a CSV file with the season name in the filename\n",
    "        self.save_to_csv(season)\n",
    "\n",
    "        print(f\"Collecting matches data process completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining players and keeper data from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Players_data:\n",
    "    def __init__(self, url, gameweek):\n",
    "        \"\"\"\n",
    "        Initializes the MultiTableExtractor with a URL and gameweek.\n",
    "        - url: URL of the page to scrape.\n",
    "        - gameweek: The gameweek number to associate with the data.\n",
    "        \"\"\"\n",
    "        self.url = url  # Store the URL to scrape\n",
    "        self.gameweek = gameweek  # Store the gameweek number\n",
    "        self.soup = None  # Initialize BeautifulSoup object as None\n",
    "        self.teams_data = {}  # Dictionary to store team information\n",
    "\n",
    "    def fetch_page(self):\n",
    "        \"\"\"\n",
    "        Fetches the web page content from the provided URL and initializes BeautifulSoup.\n",
    "        Adds a delay to prevent overloading the server.\n",
    "        \"\"\"\n",
    "        # Send a GET request to the URL\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Error accessing the page: {response.status_code}\")\n",
    "\n",
    "        # Parse the page content using BeautifulSoup\n",
    "        self.soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def extract_teams_ids(self):\n",
    "        \"\"\"\n",
    "        Extracts the IDs and names of the home and away teams using team logos.\n",
    "        Raises an exception if less than two team logos are found.\n",
    "        \"\"\"\n",
    "        self.fetch_page()  # Fetch the web page content\n",
    "\n",
    "        # Find all team logos in the page (identified by the 'teamlogo' class)\n",
    "        team_imgs = self.soup.find_all('img', class_='teamlogo', src=True)\n",
    "\n",
    "        # Check if at least two team logos are found\n",
    "        if len(team_imgs) >= 2:\n",
    "            # Extract team IDs and names from the logos\n",
    "            self.teams_data = {\n",
    "                \"home\": {\n",
    "                    \"id\": team_imgs[0]['src'].split('/')[-1].split('.')[0],  # Extract ID from the image URL\n",
    "                    \"name\": team_imgs[0]['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\"),  # Extract team name from the alt attribute\n",
    "                },\n",
    "                \"away\": {\n",
    "                    \"id\": team_imgs[1]['src'].split('/')[-1].split('.')[0],\n",
    "                    \"name\": team_imgs[1]['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\"),  \n",
    "                },\n",
    "            }\n",
    "        else:\n",
    "            # Raise an error if less than two team logos are found\n",
    "            raise Exception(\"Not enough team logos found.\")\n",
    "\n",
    "    def extract_players_table(self, team_type, table_type, header_offset, columns_to_drop):\n",
    "        \"\"\"\n",
    "        Extracts a specific player statistics table for the given team and table type.\n",
    "        - team_type: \"home\" or \"away\".\n",
    "        - table_type: Type of the table (e.g., \"summary\", \"passing\").\n",
    "        - header_offset: Number of header columns to skip.\n",
    "        - columns_to_drop: List of columns to drop from the table.\n",
    "        \"\"\"\n",
    "        # Get the team ID based on the team type (home or away)\n",
    "        team_id = self.teams_data[team_type][\"id\"]\n",
    "\n",
    "        # Construct the CSS selector for the specific table\n",
    "        players_table_selector = f\"#div_stats_{team_id}_{table_type}\"\n",
    "\n",
    "        # Select the table element using the constructed selector\n",
    "        table = self.soup.select_one(players_table_selector)\n",
    "\n",
    "        # Check if the table exists\n",
    "        if not table:\n",
    "            raise Exception(f\"Payers table {table_type} not found for team {team_type}.\")\n",
    "\n",
    "        # Extract headers from the table, skipping the specified number of columns\n",
    "        headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")][header_offset:]\n",
    "\n",
    "        # Extract rows of data from the table body\n",
    "        rows = [\n",
    "            [cell.text.strip() for cell in row.find_all([\"td\", \"th\"])]\n",
    "            for row in table.find(\"tbody\").find_all(\"tr\")\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame from the extracted rows and headers\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        # Drop unnecessary columns specified in the columns_to_drop list\n",
    "        df = df.loc[:, ~df.columns.isin(columns_to_drop)]\n",
    "\n",
    "        return df\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def process_players_data(self, team_type):\n",
    "        \"\"\"\n",
    "        Processes all player statistics tables for a specific team (home or away).\n",
    "        Combines data from multiple table types into a dictionary of DataFrames.\n",
    "        \"\"\"\n",
    "        # Define columns to drop for each table type\n",
    "        columns_to_drop = {\n",
    "            \"summary\": ['Ass', 'TP', 'TPint', 'TA', 'TR', 'Toques', 'Tkl', 'Int', 'Bloqueos', 'xG', 'npxG', 'xAG', 'ACT', 'ACG', 'Cmp', 'Int.', '% Cmp', 'PrgP', 'Transportes', 'PrgC', 'Att', 'Succ'],\n",
    "            \"passing\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín'],\n",
    "            \"passing_types\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín', 'Int.', 'Cmp'],\n",
    "            \"defense\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín'],\n",
    "            \"possession\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín', 'Tkld', 'Tkld%'],\n",
    "            \"misc\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín', 'Pcz', 'PA', 'Int', 'TklG', 'GC'],\n",
    "        }\n",
    "\n",
    "        # Initialize an empty dictionary to store DataFrames for each table type\n",
    "        tables = {}\n",
    "\n",
    "        # Loop through each table type and extract its data\n",
    "        for table_type, header_offset in [\n",
    "            (\"summary\", 7), (\"passing\", 9), (\"passing_types\", 4),\n",
    "            (\"defense\", 5), (\"possession\", 5), (\"misc\", 3)\n",
    "        ]:\n",
    "            tables[table_type] = self.extract_players_table(\n",
    "                team_type, table_type, header_offset, columns_to_drop.get(table_type, [])\n",
    "            )\n",
    "\n",
    "        return tables\n",
    "\n",
    "    def save_players_tables(self, match, season):\n",
    "        \"\"\"\n",
    "        Processes and saves player statistics tables for both home and away teams.\n",
    "        Combines data from all table types and writes the final table to a CSV file.\n",
    "        \"\"\"\n",
    "        # Extract IDs and names of the teams\n",
    "        self.extract_teams_ids()\n",
    "\n",
    "        # Process data for both home and away teams\n",
    "        for team_type in [\"home\", \"away\"]:\n",
    "            # Get the team name\n",
    "            team_name = self.teams_data[team_type][\"name\"]\n",
    "\n",
    "            # Extract and process all player statistics tables for the team\n",
    "            team_tables = self.process_players_data(team_type)\n",
    "\n",
    "            # Combine all extracted tables into a single DataFrame\n",
    "            final_table = pd.concat(team_tables.values(), axis=1)\n",
    "\n",
    "            # Define the new column names for the dataset with the team_type prefix\n",
    "            new_columns = [\n",
    "                f\"{team_type}_Players\", f\"{team_type}_Number\", f\"{team_type}_Nationality\", f\"{team_type}_Position\", \n",
    "                f\"{team_type}_PlayersAge\", f\"{team_type}_PlayersMinutes\", f\"{team_type}_PlayersGoals\", \n",
    "                f\"{team_type}_PlayersShots\", f\"{team_type}_PlayersShotsOnTarget\", f\"{team_type}_PlayersCompletedPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedPasses\", f\"{team_type}_Players%CompletedPasses\", \n",
    "                f\"{team_type}_PlayersDistancePasses\", f\"{team_type}_PlayersDistanceProgression\", \n",
    "                f\"{team_type}_PlayersShortPasses\", f\"{team_type}_PlayersAttemptedShortPasses\", \n",
    "                f\"{team_type}_Players%ShortCompletedPasses\", f\"{team_type}_PlayersMediumPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\", f\"{team_type}_Players%MediumCompletedPasses\", \n",
    "                f\"{team_type}_PlayersLongPasses\", f\"{team_type}_PlayersAttemptedLongPasses\", \n",
    "                f\"{team_type}_Players%LongCompletedPasses\", f\"{team_type}_PlayersAssistance\", \n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\", f\"{team_type}_PlayersExpectedAssistance\", \n",
    "                f\"{team_type}_PlayersKeyPasses\", f\"{team_type}_PlayersLast1/3Passes\", f\"{team_type}_PlayersGoalAreaPasses\", \n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\", f\"{team_type}_PlayersGoalPasses\", f\"{team_type}_PlayersLiveBallPasses\", \n",
    "                f\"{team_type}_PlayersDeadBallPasses\", f\"{team_type}_PlayersFreeKick\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersSidePasses\", f\"{team_type}_PlayersCrosses\", f\"{team_type}_PlayersStrongcrosses\", \n",
    "                f\"{team_type}_PlayersCorner\", f\"{team_type}_PlayersCornerIn\", f\"{team_type}_PlayersCornerOut\", \n",
    "                f\"{team_type}_PlayersCornerRect\", f\"{team_type}_PlayersOffsidePasses\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersTackles\", f\"{team_type}_PlayersSuccessfulTackles\", f\"{team_type}_PlayersTacklesInDefense\", \n",
    "                f\"{team_type}_PlayersTacklesInMedium\", f\"{team_type}_PlayersTacklesInAttack\", f\"{team_type}_PlayersDribblerTackles\", \n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\", f\"{team_type}_Players%DribblerTacklesCompleted\", \n",
    "                f\"{team_type}_PlayersDribblerTacklesNonCompleted\", f\"{team_type}_PlayersBallsBlocked\", \n",
    "                f\"{team_type}_PlayersShotsBlocked\", f\"{team_type}_PlayersPassesBlocked\", f\"{team_type}_PlayersInterceptions\", \n",
    "                f\"{team_type}_PlayersTackles+Interceptions\", f\"{team_type}_PlayersClearances\", f\"{team_type}_PlayersMistakesRivalShots\", \n",
    "                f\"{team_type}_PlayersTouches\", f\"{team_type}_PlayersOwnPenaltyAreaTouches\", f\"{team_type}_PlayersTouchesInDefense\", \n",
    "                f\"{team_type}_PlayersTouchesInMedium\", f\"{team_type}_PlayersTouchesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\", f\"{team_type}_PlayersLiveBallTouches\", \n",
    "                f\"{team_type}_PlayersAttemptedDribbles\", f\"{team_type}_PlayersDribblesCompleted\", \n",
    "                f\"{team_type}_Players%DribblesCompleted\", f\"{team_type}_PlayersBallCarries\", f\"{team_type}_PlayersDistanceCarried\", \n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\", f\"{team_type}_PlayersForwardCarries\", \n",
    "                f\"{team_type}_PlayersCarriesInAttack\", f\"{team_type}_PlayersAwayPenaltyAreaCarries\", \n",
    "                f\"{team_type}_PlayersLostControlCarries\", f\"{team_type}_PlayersLostCarries\", f\"{team_type}_PlayersPassesReception\", \n",
    "                f\"{team_type}_PlayersAttackPassesReception\", f\"{team_type}_PlayersYellowCards\", f\"{team_type}_PlayersRedCards\", \n",
    "                f\"{team_type}_PlayersSecondYellowCards\", f\"{team_type}_PlayersFouls\", f\"{team_type}_PlayersOffside\", \n",
    "                f\"{team_type}_PlayersPenalties\", f\"{team_type}_PlayersPenaltiesConceded\", f\"{team_type}_PlayersLostBallRecoveries\", \n",
    "                f\"{team_type}_PlayersAerialsWon\", f\"{team_type}_PlayersAerialsLost\", f\"{team_type}_Players%AerialsWon\"\n",
    "            ]\n",
    "\n",
    "            # Rename the columns of the DataFrame\n",
    "            final_table.columns = new_columns\n",
    "\n",
    "            # Convert the 'Age' column to integer by extracting the first two characters\n",
    "            final_table[f'{team_type}_PlayersAge'] = final_table[f'{team_type}_PlayersAge'].apply(\n",
    "                lambda x: int(x[:2]) if isinstance(x, str) else 0\n",
    "            )\n",
    "\n",
    "            # Define columns to calculate the mean\n",
    "            columns_to_mean = [\n",
    "                f\"{team_type}_PlayersAge\", f\"{team_type}_Players%CompletedPasses\", \n",
    "                f\"{team_type}_Players%ShortCompletedPasses\", f\"{team_type}_Players%MediumCompletedPasses\", \n",
    "                f\"{team_type}_Players%LongCompletedPasses\", f\"{team_type}_Players%DribblerTacklesCompleted\", \n",
    "                f\"{team_type}_Players%DribblesCompleted\", f\"{team_type}_Players%AerialsWon\"\n",
    "            ]\n",
    "\n",
    "            # Define columns to calculate the sum\n",
    "            columns_to_sum = [\n",
    "                f\"{team_type}_PlayersMinutes\", f\"{team_type}_PlayersGoals\", f\"{team_type}_PlayersShots\", \n",
    "                f\"{team_type}_PlayersShotsOnTarget\", f\"{team_type}_PlayersCompletedPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedPasses\", f\"{team_type}_PlayersDistancePasses\", \n",
    "                f\"{team_type}_PlayersDistanceProgression\", f\"{team_type}_PlayersShortPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedShortPasses\", f\"{team_type}_PlayersMediumPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedLongPasses\", f\"{team_type}_PlayersAssistance\", \n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\", f\"{team_type}_PlayersExpectedAssistance\", \n",
    "                f\"{team_type}_PlayersKeyPasses\", f\"{team_type}_PlayersLast1/3Passes\", f\"{team_type}_PlayersGoalAreaPasses\", \n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\", f\"{team_type}_PlayersGoalPasses\", f\"{team_type}_PlayersLiveBallPasses\", \n",
    "                f\"{team_type}_PlayersDeadBallPasses\", f\"{team_type}_PlayersFreeKick\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersSidePasses\", f\"{team_type}_PlayersCrosses\", f\"{team_type}_PlayersStrongcrosses\", \n",
    "                f\"{team_type}_PlayersCorner\", f\"{team_type}_PlayersCornerIn\", f\"{team_type}_PlayersCornerOut\", \n",
    "                f\"{team_type}_PlayersCornerRect\", f\"{team_type}_PlayersOffsidePasses\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersTackles\", f\"{team_type}_PlayersSuccessfulTackles\", f\"{team_type}_PlayersTacklesInDefense\", \n",
    "                f\"{team_type}_PlayersTacklesInMedium\", f\"{team_type}_PlayersTacklesInAttack\", f\"{team_type}_PlayersDribblerTackles\", \n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\", f\"{team_type}_PlayersDribblerTacklesNonCompleted\", \n",
    "                f\"{team_type}_PlayersBallsBlocked\", f\"{team_type}_PlayersShotsBlocked\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersInterceptions\", f\"{team_type}_PlayersTackles+Interceptions\", f\"{team_type}_PlayersClearances\", \n",
    "                f\"{team_type}_PlayersMistakesRivalShots\", f\"{team_type}_PlayersTouches\", f\"{team_type}_PlayersOwnPenaltyAreaTouches\", \n",
    "                f\"{team_type}_PlayersTouchesInDefense\", f\"{team_type}_PlayersTouchesInMedium\", f\"{team_type}_PlayersTouchesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\", f\"{team_type}_PlayersLiveBallTouches\", f\"{team_type}_PlayersAttemptedDribbles\", \n",
    "                f\"{team_type}_PlayersDribblesCompleted\", f\"{team_type}_PlayersBallCarries\", f\"{team_type}_PlayersDistanceCarried\", \n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\", f\"{team_type}_PlayersForwardCarries\", f\"{team_type}_PlayersCarriesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaCarries\", f\"{team_type}_PlayersLostControlCarries\", f\"{team_type}_PlayersLostCarries\", \n",
    "                f\"{team_type}_PlayersPassesReception\", f\"{team_type}_PlayersAttackPassesReception\", f\"{team_type}_PlayersYellowCards\", \n",
    "                f\"{team_type}_PlayersRedCards\", f\"{team_type}_PlayersSecondYellowCards\", f\"{team_type}_PlayersFouls\", \n",
    "                f\"{team_type}_PlayersOffside\", f\"{team_type}_PlayersPenalties\", f\"{team_type}_PlayersPenaltiesConceded\", \n",
    "                f\"{team_type}_PlayersLostBallRecoveries\", f\"{team_type}_PlayersAerialsWon\", f\"{team_type}_PlayersAerialsLost\"\n",
    "            ]\n",
    "\n",
    "            # Convert the mean columns to numeric\n",
    "            for col in columns_to_mean:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Convert the sum columns to numeric\n",
    "            for col in columns_to_sum:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Calculate the mean and sum for specified columns\n",
    "            mean_values = final_table[columns_to_mean].mean()\n",
    "            sum_values = final_table[columns_to_sum].sum()\n",
    "\n",
    "            # Create a new row for totals with placeholder values\n",
    "            total_row = {col: '-' for col in final_table.columns}\n",
    "\n",
    "            # Populate the total row with mean values\n",
    "            for col, mean in mean_values.items():\n",
    "                total_row[col] = mean\n",
    "\n",
    "            # Populate the total row with sum values\n",
    "            for col, total in sum_values.items():\n",
    "                total_row[col] = total\n",
    "\n",
    "            # Add the number of rows (lines) to the first column of the total row\n",
    "            num_lines = len(final_table)\n",
    "            total_row[final_table.columns[0]] = num_lines\n",
    "\n",
    "            # Check if the 'id' column exists, if not, create it with NaN values\n",
    "            if 'id' not in final_table.columns:\n",
    "                final_table['id'] = np.nan  # Create the column with NaN values\n",
    "\n",
    "            # Add the match ID to the total row\n",
    "            total_row['id'] = match\n",
    "\n",
    "            # Append the total row to the DataFrame\n",
    "            final_table.loc[len(final_table)] = total_row\n",
    "\n",
    "            # Save the combined table to a CSV file\n",
    "            #output_filename = f\"{self.gameweek}_{match}_{team_name}_{team_type}_players_table.csv\"\n",
    "            #final_table.to_csv(output_filename, index=False)\n",
    "\n",
    "            # Define the columns to append to the existing CSV\n",
    "            columns_to_append = [\n",
    "                f\"{team_type}_Players\", \n",
    "                f\"{team_type}_PlayersAge\", f\"{team_type}_PlayersMinutes\", f\"{team_type}_PlayersGoals\", \n",
    "                f\"{team_type}_PlayersShots\", f\"{team_type}_PlayersShotsOnTarget\", f\"{team_type}_PlayersCompletedPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedPasses\", f\"{team_type}_Players%CompletedPasses\", \n",
    "                f\"{team_type}_PlayersDistancePasses\", f\"{team_type}_PlayersDistanceProgression\", \n",
    "                f\"{team_type}_PlayersShortPasses\", f\"{team_type}_PlayersAttemptedShortPasses\", \n",
    "                f\"{team_type}_Players%ShortCompletedPasses\", f\"{team_type}_PlayersMediumPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\", f\"{team_type}_Players%MediumCompletedPasses\", \n",
    "                f\"{team_type}_PlayersLongPasses\", f\"{team_type}_PlayersAttemptedLongPasses\", \n",
    "                f\"{team_type}_Players%LongCompletedPasses\", f\"{team_type}_PlayersAssistance\", \n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\", f\"{team_type}_PlayersExpectedAssistance\", \n",
    "                f\"{team_type}_PlayersKeyPasses\", f\"{team_type}_PlayersLast1/3Passes\", f\"{team_type}_PlayersGoalAreaPasses\", \n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\", f\"{team_type}_PlayersGoalPasses\", f\"{team_type}_PlayersLiveBallPasses\", \n",
    "                f\"{team_type}_PlayersDeadBallPasses\", f\"{team_type}_PlayersFreeKick\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersSidePasses\", f\"{team_type}_PlayersCrosses\", f\"{team_type}_PlayersStrongcrosses\", \n",
    "                f\"{team_type}_PlayersCorner\", f\"{team_type}_PlayersCornerIn\", f\"{team_type}_PlayersCornerOut\", \n",
    "                f\"{team_type}_PlayersCornerRect\", f\"{team_type}_PlayersOffsidePasses\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersTackles\", f\"{team_type}_PlayersSuccessfulTackles\", f\"{team_type}_PlayersTacklesInDefense\", \n",
    "                f\"{team_type}_PlayersTacklesInMedium\", f\"{team_type}_PlayersTacklesInAttack\", f\"{team_type}_PlayersDribblerTackles\", \n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\", f\"{team_type}_Players%DribblerTacklesCompleted\", \n",
    "                f\"{team_type}_PlayersDribblerTacklesNonCompleted\", f\"{team_type}_PlayersBallsBlocked\", \n",
    "                f\"{team_type}_PlayersShotsBlocked\", f\"{team_type}_PlayersPassesBlocked\", f\"{team_type}_PlayersInterceptions\", \n",
    "                f\"{team_type}_PlayersTackles+Interceptions\", f\"{team_type}_PlayersClearances\", f\"{team_type}_PlayersMistakesRivalShots\", \n",
    "                f\"{team_type}_PlayersTouches\", f\"{team_type}_PlayersOwnPenaltyAreaTouches\", f\"{team_type}_PlayersTouchesInDefense\", \n",
    "                f\"{team_type}_PlayersTouchesInMedium\", f\"{team_type}_PlayersTouchesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\", f\"{team_type}_PlayersLiveBallTouches\", \n",
    "                f\"{team_type}_PlayersAttemptedDribbles\", f\"{team_type}_PlayersDribblesCompleted\", \n",
    "                f\"{team_type}_Players%DribblesCompleted\", f\"{team_type}_PlayersBallCarries\", f\"{team_type}_PlayersDistanceCarried\", \n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\", f\"{team_type}_PlayersForwardCarries\", \n",
    "                f\"{team_type}_PlayersCarriesInAttack\", f\"{team_type}_PlayersAwayPenaltyAreaCarries\", \n",
    "                f\"{team_type}_PlayersLostControlCarries\", f\"{team_type}_PlayersLostCarries\", f\"{team_type}_PlayersPassesReception\", \n",
    "                f\"{team_type}_PlayersAttackPassesReception\", f\"{team_type}_PlayersYellowCards\", f\"{team_type}_PlayersRedCards\", \n",
    "                f\"{team_type}_PlayersSecondYellowCards\", f\"{team_type}_PlayersFouls\", f\"{team_type}_PlayersOffside\", \n",
    "                f\"{team_type}_PlayersPenalties\", f\"{team_type}_PlayersPenaltiesConceded\", f\"{team_type}_PlayersLostBallRecoveries\", \n",
    "                f\"{team_type}_PlayersAerialsWon\", f\"{team_type}_PlayersAerialsLost\", f\"{team_type}_Players%AerialsWon\"\n",
    "            ]\n",
    "\n",
    "            # Extract the last row from final_table (this contains the sums and means)\n",
    "            last_row = final_table.iloc[-1][columns_to_append]\n",
    "\n",
    "            #Define the filename for the current season\n",
    "            filename = f\"matches_{season}.csv\"\n",
    "\n",
    "            # Load the existing CSV file from the parent directory\n",
    "            existing_df = pd.read_csv(filename)\n",
    "\n",
    "            # Get the ID from the last row of final_table\n",
    "            last_row_id = final_table.iloc[-1]['id']\n",
    "\n",
    "            # Find the row in the existing CSV based on the ID\n",
    "            row_index = existing_df[existing_df['id'] == last_row_id].index\n",
    "\n",
    "            # Check if the row exists\n",
    "            if row_index.empty:\n",
    "                raise ValueError(f\"Error: No row with ID {last_row_id} found in {filename}\")\n",
    "\n",
    "            # Check if the columns exist in the existing CSV, if not, create them after the existing columns\n",
    "            for column in columns_to_append:\n",
    "                if column not in existing_df.columns:\n",
    "                    existing_df[column] = pd.NA  # Create the column with missing values\n",
    "\n",
    "            # Ensure the new columns are placed after the existing columns\n",
    "            existing_columns = existing_df.columns.tolist()\n",
    "            new_columns = [column for column in columns_to_append if column not in existing_columns]\n",
    "            existing_df = existing_df[existing_columns + new_columns]\n",
    "\n",
    "            # Update the row with the new data from last_row\n",
    "            for column, value in last_row.items():\n",
    "                existing_df.at[row_index[0], column] = value\n",
    "\n",
    "            # Save the updated DataFrame back to the CSV\n",
    "            existing_df.to_csv(filename, index=False)\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "    \n",
    "    def extract_keeper_table(self, team_type, header_offset):\n",
    "        \"\"\"\n",
    "        Extracts a specific keeper statistics table for the given team.\n",
    "        - team_type: \"home\" or \"away\".\n",
    "        - header_offset: Number of header columns to skip.\n",
    "        \"\"\"\n",
    "        # Get the team ID based on the team type (home or away)\n",
    "        team_id = self.teams_data[team_type][\"id\"]\n",
    "\n",
    "        # Construct the CSS selector for the specific table\n",
    "        keeper_table_selector = f\"#keeper_stats_{team_id}\"\n",
    "\n",
    "        # Select the table element using the constructed selector\n",
    "        table = self.soup.select_one(keeper_table_selector)\n",
    "\n",
    "        # Check if the table exists\n",
    "        if not table:\n",
    "            raise Exception(f\"Keeper table not found for team {team_type}.\")\n",
    "\n",
    "        # Extract headers from the table, skipping the specified number of columns\n",
    "        headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")][header_offset:]\n",
    "\n",
    "        # Extract rows of data from the table body\n",
    "        rows = [\n",
    "            [cell.text.strip() for cell in row.find_all([\"td\", \"th\"])]\n",
    "            for row in table.find(\"tbody\").find_all(\"tr\")\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame from the extracted rows and headers\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        return df\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def process_keeper_data(self, team_type):\n",
    "        \"\"\"\n",
    "        Processes all keeper statistics tables for a specific team (home or away).\n",
    "        Combines data into a dictionary of DataFrames.\n",
    "        \"\"\"\n",
    "        # Extract data from the keeper statistics table\n",
    "        table = self.extract_keeper_table(\n",
    "                team_type, header_offset=7)\n",
    "\n",
    "        return table\n",
    "\n",
    "    def save_keeper_tables(self, match, season):\n",
    "        \"\"\"\n",
    "        Processes and saves keeper statistics table for both home and away teams.\n",
    "        Writes the final table to a CSV file.\n",
    "        \"\"\"\n",
    "        # Extract IDs and names of the teams\n",
    "        self.extract_teams_ids()\n",
    "\n",
    "        # Process data for both home and away teams\n",
    "        for team_type in [\"home\", \"away\"]:\n",
    "            # Get the team name\n",
    "            team_name = self.teams_data[team_type][\"name\"]\n",
    "\n",
    "            # Extract and process all keeper statistics tables for the team\n",
    "            final_table = self.process_keeper_data(team_type)\n",
    "\n",
    "            # Define the new column names for the dataset\n",
    "            new_columns = [\n",
    "                f\"{team_type}_KeepersKeepers\", f\"{team_type}_KeepersNationality\", f\"{team_type}_KeepersAge\", \n",
    "                f\"{team_type}_KeepersMinutes\", f\"{team_type}_KeepersShotsOnTargetAgainst\", \n",
    "                f\"{team_type}_KeepersGoalsAgainst\", f\"{team_type}_KeepersSaved\", \n",
    "                f\"{team_type}_Keepers%Saved\", f\"{team_type}_KeepersxG\", f\"{team_type}_KeepersPassesLaunched\", \n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\", f\"{team_type}_Keepers%CompletedPassesLaunched\", \n",
    "                f\"{team_type}_KeepersPasses\", f\"{team_type}_KeepersAttemptedPasses\", \n",
    "                f\"{team_type}_Keepers%CompletedPasses\", f\"{team_type}_KeepersPassesDistance\", \n",
    "                f\"{team_type}_KeepersAttemptedKicks\", f\"{team_type}_Keepers%Kicks\", \n",
    "                f\"{team_type}_KeepersKicksDistance\", f\"{team_type}_KeepersCrosses\", \n",
    "                f\"{team_type}_KeepersCrossesStopped\", f\"{team_type}_Keepers%CrossesStopped\", \n",
    "                f\"{team_type}_KeepersActionsOutsideArea\", f\"{team_type}_KeepersDistanceActionsArea\"\n",
    "            ]\n",
    "\n",
    "            # Rename the columns of the DataFrame\n",
    "            final_table.columns = new_columns\n",
    "\n",
    "            # Convert the 'Age' column to integer by extracting the first two characters\n",
    "            final_table[f'{team_type}_KeepersAge'] = final_table[f'{team_type}_KeepersAge'].apply(\n",
    "                lambda x: int(x[:2]) if isinstance(x, str) else 0\n",
    "            )\n",
    "\n",
    "            # Define columns to calculate the mean\n",
    "            columns_to_mean = [\n",
    "                f\"{team_type}_KeepersAge\", f\"{team_type}_Keepers%Saved\", \n",
    "                f\"{team_type}_Keepers%CompletedPassesLaunched\", f\"{team_type}_Keepers%CompletedPasses\", \n",
    "                f\"{team_type}_KeepersPassesDistance\", f\"{team_type}_Keepers%Kicks\", \n",
    "                f\"{team_type}_KeepersKicksDistance\", f\"{team_type}_Keepers%CrossesStopped\", \n",
    "                f\"{team_type}_KeepersDistanceActionsArea\"\n",
    "            ]\n",
    "\n",
    "            # Define columns to calculate the sum\n",
    "            columns_to_sum = [\n",
    "                f\"{team_type}_KeepersKeepers\", f\"{team_type}_KeepersMinutes\", \n",
    "                f\"{team_type}_KeepersShotsOnTargetAgainst\", f\"{team_type}_KeepersGoalsAgainst\", \n",
    "                f\"{team_type}_KeepersSaved\", f\"{team_type}_KeepersxG\", f\"{team_type}_KeepersPassesLaunched\", \n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\", f\"{team_type}_KeepersPasses\", \n",
    "                f\"{team_type}_KeepersAttemptedPasses\", f\"{team_type}_KeepersAttemptedKicks\", \n",
    "                f\"{team_type}_KeepersCrosses\", f\"{team_type}_KeepersCrossesStopped\", \n",
    "                f\"{team_type}_KeepersActionsOutsideArea\"\n",
    "            ]\n",
    "\n",
    "            # Convert the mean columns to numeric\n",
    "            for col in columns_to_mean:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Convert the sum columns to numeric\n",
    "            for col in columns_to_sum:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Calculate the mean and sum for specified columns\n",
    "            mean_values = final_table[columns_to_mean].mean()\n",
    "            sum_values = final_table[columns_to_sum].sum()\n",
    "\n",
    "            # Create a new row for totals with placeholder values\n",
    "            total_row = {col: '-' for col in final_table.columns}\n",
    "\n",
    "            # Populate the total row with mean values\n",
    "            for col, mean in mean_values.items():\n",
    "                total_row[col] = mean\n",
    "\n",
    "            # Populate the total row with sum values\n",
    "            for col, total in sum_values.items():\n",
    "                total_row[col] = total\n",
    "\n",
    "            # Add the number of rows (lines) to the first column of the total row\n",
    "            num_lines = len(final_table)\n",
    "            total_row[final_table.columns[0]] = num_lines\n",
    "\n",
    "            # Check if the 'id' column exists, if not, create it with NaN values\n",
    "            if 'id' not in final_table.columns:\n",
    "                final_table['id'] = np.nan  # Create the column with NaN values\n",
    "\n",
    "            # Add the match ID to the total row\n",
    "            total_row['id'] = match\n",
    "\n",
    "            # Append the total row to the DataFrame\n",
    "            final_table.loc[len(final_table)] = total_row\n",
    "\n",
    "            # Save the combined table to a CSV file\n",
    "            #output_filename = f\"{self.gameweek}_{match}_{team_name}_{team_type}_keeper_table.csv\"\n",
    "            #final_table.to_csv(output_filename, index=False)\n",
    "\n",
    "            # Define the columns to append to the existing CSV\n",
    "            columns_to_append = [\n",
    "                f\"{team_type}_KeepersKeepers\", f\"{team_type}_KeepersMinutes\",\n",
    "                f\"{team_type}_KeepersShotsOnTargetAgainst\", f\"{team_type}_KeepersGoalsAgainst\", f\"{team_type}_KeepersSaved\", \n",
    "                f\"{team_type}_Keepers%Saved\", f\"{team_type}_KeepersxG\", f\"{team_type}_KeepersPassesLaunched\", \n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\", f\"{team_type}_Keepers%CompletedPassesLaunched\", \n",
    "                f\"{team_type}_KeepersPasses\", f\"{team_type}_KeepersAttemptedPasses\", f\"{team_type}_Keepers%CompletedPasses\", \n",
    "                f\"{team_type}_KeepersPassesDistance\", f\"{team_type}_KeepersAttemptedKicks\", f\"{team_type}_Keepers%Kicks\", \n",
    "                f\"{team_type}_KeepersKicksDistance\", f\"{team_type}_KeepersCrosses\", f\"{team_type}_KeepersCrossesStopped\", \n",
    "                f\"{team_type}_Keepers%CrossesStopped\", f\"{team_type}_KeepersActionsOutsideArea\", f\"{team_type}_KeepersDistanceActionsArea\"\n",
    "            ]\n",
    "\n",
    "            # Extract the last row from final_table (this contains the sums and means)\n",
    "            last_row = final_table.iloc[-1][columns_to_append]\n",
    "\n",
    "            #Define the filename for the current season\n",
    "            filename = f\"matches_{season}.csv\"\n",
    "\n",
    "            # Load the existing CSV file from the parent directory\n",
    "            existing_df = pd.read_csv(filename)\n",
    "\n",
    "            # Get the ID from the last row of final_table\n",
    "            last_row_id = final_table.iloc[-1]['id']\n",
    "\n",
    "            # Find the row in the existing CSV based on the ID\n",
    "            row_index = existing_df[existing_df['id'] == last_row_id].index\n",
    "\n",
    "            # Check if the row exists\n",
    "            if row_index.empty:\n",
    "                raise ValueError(f\"Error: No row with ID {last_row_id} found in {filename}\")\n",
    "\n",
    "            # Check if the columns exist in the existing CSV, if not, create them after the existing columns\n",
    "            for column in columns_to_append:\n",
    "                if column not in existing_df.columns:\n",
    "                    existing_df[column] = pd.NA  # Create the column with missing values\n",
    "\n",
    "            # Ensure the new columns are placed after the existing columns\n",
    "            existing_columns = existing_df.columns.tolist()\n",
    "            new_columns = [column for column in columns_to_append if column not in existing_columns]\n",
    "            existing_df = existing_df[existing_columns + new_columns]\n",
    "\n",
    "            # Update the row with the new data from last_row\n",
    "            for column, value in last_row.items():\n",
    "                existing_df.at[row_index[0], column] = value\n",
    "\n",
    "            # Save the updated DataFrame back to the CSV\n",
    "            existing_df.to_csv(filename, index=False)\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "    def run(self, url, links_file, gameweeks_file):\n",
    "        \"\"\"\n",
    "        Processes multiple gameweek URLs by reading from a file of links and gameweeks.\n",
    "        For each URL, extracts and saves player and keeper statistics tables.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting players data...\")\n",
    "\n",
    "        #Extract the season from the URL\n",
    "        season_match = re.search(r'(\\d{4})-(\\d{4})', url)\n",
    "        if season_match:\n",
    "            season = season_match.group(0)\n",
    "        else:\n",
    "            season = 'unknown_season'  # Default value if the season cannot be extracted\n",
    "            \n",
    "        # Read the links and gameweeks from CSV files\n",
    "        links_df = pd.read_csv(links_file)\n",
    "        gameweeks_df = pd.read_csv(gameweeks_file)\n",
    "\n",
    "        # Initialize match as an integer\n",
    "        match = 1  # Start match numbering from 100\n",
    "\n",
    "        # Loop through each link and its corresponding gameweek starting from index 99 (100th link)\n",
    "        for index in range(0, len(links_df)):  # Adjust starting index to 99 (Python indexing starts at 0)\n",
    "            link = links_df.iloc[index]['link']\n",
    "            gameweek = gameweeks_df.iloc[index]['gameweek']\n",
    "\n",
    "            print(f\"Processing link {index + 1}: {link}\")\n",
    "\n",
    "            # Create an extractor for the current URL and gameweek\n",
    "            extractor = Players_data(link, gameweek)\n",
    "\n",
    "            # Save the extracted players tables for the current URL\n",
    "            extractor.save_players_tables(match, season)\n",
    "\n",
    "            # Save the extracted keepers tables for the current URL\n",
    "            extractor.save_keeper_tables(match, season)\n",
    "\n",
    "            # Increment the match counter\n",
    "            match += 1\n",
    "\n",
    "            time.sleep(6)\n",
    "\n",
    "        print(f\"Collecting players data process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining time data from the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match_events:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the extractor with the URL of the match page.\n",
    "        This sets up the URL, initializes placeholders for parsed HTML content,\n",
    "        and lists to store events for both teams.\n",
    "        \"\"\"\n",
    "        self.url = url  # URL of the match page\n",
    "        self.soup = None  # Placeholder for the parsed HTML content\n",
    "        self.events_team_a = []  # List to store events for Team A\n",
    "        self.events_team_b = []  # List to store events for Team B\n",
    "\n",
    "    def fetch_html(self):\n",
    "        \"\"\"\n",
    "        Fetch the HTML content from the given URL.\n",
    "        This method makes an HTTP GET request to the URL and parses the HTML if the request is successful.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            self.soup = BeautifulSoup(response.text, 'html.parser')  # Parse the HTML content\n",
    "        else:\n",
    "            raise Exception(f\"Failed to fetch HTML content. Status code: {response.status_code}\")\n",
    "\n",
    "    def parse_events(self):\n",
    "        \"\"\"\n",
    "        Extract match events from the HTML content for both teams.\n",
    "        This method locates the event container in the HTML and extracts relevant data for both teams.\n",
    "        \"\"\"\n",
    "        # Ensure that the HTML content has been loaded\n",
    "        if not self.soup:\n",
    "            raise Exception(\"HTML content not loaded. Call 'fetch_html()' first.\")\n",
    "        \n",
    "        # Locate the main container that holds all the events\n",
    "        events_wrap = self.soup.find('div', id='events_wrap')\n",
    "        if not events_wrap:\n",
    "            raise Exception(\"Event container not found in the HTML.\")\n",
    "\n",
    "        # Parse events for Team A\n",
    "        for event in events_wrap.find_all('div', class_='event a'):  # Look for events with class 'event a'\n",
    "            minute = event.find('small').text.strip() if event.find('small') else None  # Get the minute of the event\n",
    "            event_icon = event.find('div', class_='event_icon')\n",
    "            event_type = event_icon['class'][1] if event_icon else None  # Get the type of event (e.g., goal, yellow card)\n",
    "            player_tag = event.find('a')\n",
    "            player = player_tag.text.strip() if player_tag else None  # Get the player involved in the event\n",
    "            team_logo = event.find('img', class_='teamlogo')\n",
    "            team = team_logo['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\") if team_logo else None  # Get the team name\n",
    "\n",
    "            # Append the extracted details to the Team A events list\n",
    "            self.events_team_a.append({\n",
    "                'Minute': minute,\n",
    "                'EventType': event_type,\n",
    "                'Player': player,\n",
    "                'Team': team\n",
    "            })\n",
    "\n",
    "        # Parse events for Team B\n",
    "        for event in events_wrap.find_all('div', class_='event b'):  # Look for events with class 'event b'\n",
    "            minute = event.find('small').text.strip() if event.find('small') else None  # Get the minute of the event\n",
    "            event_icon = event.find('div', class_='event_icon')\n",
    "            event_type = event_icon['class'][1] if event_icon else None  # Get the type of event (e.g., goal, yellow card)\n",
    "            player_tag = event.find('a')\n",
    "            player = player_tag.text.strip() if player_tag else None  # Get the player involved in the event\n",
    "            team_logo = event.find('img', class_='teamlogo')\n",
    "            team = team_logo['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\") if team_logo else None  # Get the team name\n",
    "\n",
    "            # Append the extracted details to the Team B events list\n",
    "            self.events_team_b.append({\n",
    "                'Minute': minute,\n",
    "                'EventType': event_type,\n",
    "                'Player': player,\n",
    "                'Team': team\n",
    "            })\n",
    "\n",
    "    def save_to_csv(self, match, gameweek):\n",
    "        \"\"\"\n",
    "        Save the extracted events for both Team A and Team B to separate CSV files.\n",
    "        This method ensures that events are saved only after they have been parsed.\n",
    "        \"\"\"\n",
    "        if not self.events_team_a:\n",
    "            raise Exception(\"No events for Team A to save. Make sure to call 'parse_events()' first.\")\n",
    "        if not self.events_team_b:\n",
    "            raise Exception(\"No events for Team B to save. Make sure to call 'parse_events()' first.\")\n",
    "        \n",
    "        # Convert the events for Team A and Team B to DataFrames\n",
    "        events_team_a_df = pd.DataFrame(self.events_team_a)\n",
    "        events_team_b_df = pd.DataFrame(self.events_team_b)\n",
    "\n",
    "        # Get the team names for the output filenames\n",
    "        team_name_a = self.events_team_a[0]['Team']\n",
    "        team_name_b = self.events_team_b[0]['Team']\n",
    "\n",
    "        # Define output filenames for the CSV files\n",
    "        output_filename_a = f\"{gameweek}_{match}_{team_name_a}_events.csv\"\n",
    "        output_filename_b = f\"{gameweek}_{match}_{team_name_b}_events.csv\"\n",
    "        \n",
    "        # Save the extracted events to CSV files for both teams\n",
    "        events_team_a_df.to_csv(output_filename_a, index=False)\n",
    "        events_team_b_df.to_csv(output_filename_b, index=False)\n",
    "\n",
    "    def run(self, links_file, gameweeks_file):\n",
    "        \"\"\"\n",
    "        Execute the full process: fetch HTML, parse events, and save to CSV files for both teams.\n",
    "        This method orchestrates the entire extraction process by reading the necessary input files,\n",
    "        fetching the HTML content, parsing events, and saving the results to CSV files.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting events data...\")\n",
    "\n",
    "        # Read the links and gameweeks from CSV files\n",
    "        links_df = pd.read_csv(links_file)\n",
    "        gameweeks_df = pd.read_csv(gameweeks_file)\n",
    "\n",
    "        # Initialize match as an integer\n",
    "        match = 1\n",
    "\n",
    "        # Loop through each link and its corresponding gameweek\n",
    "        for index, link in enumerate(links_df['link']):\n",
    "            gameweek = gameweeks_df.iloc[index]['gameweek']\n",
    "\n",
    "            print(f\"Processing link {index + 1}: {link}\")\n",
    "\n",
    "            # Create an extractor for the current URL and gameweek\n",
    "            extractor = Match_events(link)\n",
    "\n",
    "            # Fetch the HTML content for the match page\n",
    "            extractor.fetch_html()\n",
    "\n",
    "            # Parse the events for both teams\n",
    "            extractor.parse_events()\n",
    "\n",
    "            # Save the extracted events to CSV files for both teams\n",
    "            extractor.save_to_csv(match, gameweek)\n",
    "\n",
    "            # Increment the match counter\n",
    "            match += 1\n",
    "\n",
    "            time.sleep(6)\n",
    "\n",
    "        print(f\"Collecting events data process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_process():\n",
    "    \"\"\"\n",
    "    Runs the full data extraction process for a given league URL. \n",
    "    It involves extracting match data, player statistics, and match events.\n",
    "    \"\"\"\n",
    "    # Define the league URL (La Liga for the 2023-2024 season)\n",
    "    league_url = 'https://fbref.com/es/comps/12/2022-2023/horario/Marcadores-y-partidos-de-2022-2023-La-Liga'\n",
    "    \n",
    "    # First class: Extract match data from the league URL\n",
    "    # Create an instance of Match_data and run the extraction process\n",
    "    Match_data_extractor = Match_data(league_url)\n",
    "    Match_data_extractor.run(league_url)\n",
    "    \n",
    "    # Second class: Extract player data for each match\n",
    "    # Extract the season from the URL using a regular expression\n",
    "    season_match = re.search(r'(\\d{4})-(\\d{4})', league_url)\n",
    "    if season_match:\n",
    "        season = season_match.group(0)  # Get the season\n",
    "    else:\n",
    "        season = 'unknown_season'  # Default value if the season cannot be extracted\n",
    "\n",
    "    #Define the filename for the current season\n",
    "    filename = f\"matches_{season}.csv\"\n",
    "\n",
    "    # Load the existing CSV file from the parent directory\n",
    "    data = pd.read_csv(filename)\n",
    "    \n",
    "    # Define file paths for temporary CSV files containing links and gameweeks\n",
    "    links_file = 'links_temp.csv'\n",
    "    gameweeks_file = 'gameweeks_temp.csv'\n",
    "\n",
    "    # Save only the 'link' column from the match data to the links file\n",
    "    data[['link']].to_csv(links_file, index=False)\n",
    "    \n",
    "    # Save only the 'gameweek' column from the match data to the gameweeks file\n",
    "    data[['gameweek']].to_csv(gameweeks_file, index=False)\n",
    "\n",
    "    # Call the function to extract player data using the links and gameweeks files\n",
    "    Players_data_extractor = Players_data(league_url, None)\n",
    "    Players_data_extractor.run(league_url, links_file, gameweeks_file)\n",
    "    \n",
    "    # Third class: Extract match events data\n",
    "    # Create an instance of Match_events and run the extraction process\n",
    "    #Match_events_extractor = Match_events(league_url)\n",
    "    #Match_events_extractor.run(links_file, filename)\n",
    "\n",
    "    # Clean up by removing the temporary CSV files after the process is complete\n",
    "    os.remove(links_file)\n",
    "    os.remove(gameweeks_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting collecting players data...\n",
      "Processing link 1: https://fbref.com/es/partidos/1edcbf7a/Osasuna-Sevilla-Agosto-12-2022-La-Liga\n",
      "Processing link 2: https://fbref.com/es/partidos/73b529f2/Celta-Vigo-Espanyol-Agosto-13-2022-La-Liga\n",
      "Processing link 3: https://fbref.com/es/partidos/be7e4222/Valladolid-Villarreal-Agosto-13-2022-La-Liga\n",
      "Processing link 4: https://fbref.com/es/partidos/cbe0a303/Barcelona-Rayo-Vallecano-Agosto-13-2022-La-Liga\n",
      "Processing link 5: https://fbref.com/es/partidos/7fbde755/Cadiz-Real-Sociedad-Agosto-14-2022-La-Liga\n",
      "Processing link 6: https://fbref.com/es/partidos/aaab7ab9/Valencia-Girona-Agosto-14-2022-La-Liga\n",
      "Processing link 7: https://fbref.com/es/partidos/c1e42359/Almeria-Real-Madrid-Agosto-14-2022-La-Liga\n",
      "Processing link 8: https://fbref.com/es/partidos/ab058eb9/Athletic-Club-Mallorca-Agosto-15-2022-La-Liga\n",
      "Processing link 9: https://fbref.com/es/partidos/9993b01a/Getafe-Atletico-Madrid-Agosto-15-2022-La-Liga\n",
      "Processing link 10: https://fbref.com/es/partidos/1f998adf/Real-Betis-Elche-Agosto-15-2022-La-Liga\n",
      "Processing link 11: https://fbref.com/es/partidos/cb92acb9/Espanyol-Rayo-Vallecano-Agosto-19-2022-La-Liga\n",
      "Processing link 12: https://fbref.com/es/partidos/bc5ec3c6/Sevilla-Valladolid-Agosto-19-2022-La-Liga\n",
      "Processing link 13: https://fbref.com/es/partidos/39d72386/Osasuna-Cadiz-Agosto-20-2022-La-Liga\n",
      "Processing link 14: https://fbref.com/es/partidos/f06f275b/Mallorca-Real-Betis-Agosto-20-2022-La-Liga\n",
      "Processing link 15: https://fbref.com/es/partidos/65ccc663/Celta-Vigo-Real-Madrid-Agosto-20-2022-La-Liga\n",
      "Processing link 16: https://fbref.com/es/partidos/615ccfb0/Athletic-Club-Valencia-Agosto-21-2022-La-Liga\n",
      "Processing link 17: https://fbref.com/es/partidos/ebb32848/Atletico-Madrid-Villarreal-Agosto-21-2022-La-Liga\n",
      "Processing link 18: https://fbref.com/es/partidos/9a5e0f15/Real-Sociedad-Barcelona-Agosto-21-2022-La-Liga\n",
      "Processing link 19: https://fbref.com/es/partidos/6f633cb1/Elche-Almeria-Agosto-22-2022-La-Liga\n",
      "Processing link 20: https://fbref.com/es/partidos/1253bef2/Girona-Getafe-Agosto-22-2022-La-Liga\n",
      "Processing link 21: https://fbref.com/es/partidos/3cce40a3/Girona-Celta-Vigo-Agosto-26-2022-La-Liga\n",
      "Processing link 22: https://fbref.com/es/partidos/8ed0d2b7/Real-Betis-Osasuna-Agosto-26-2022-La-Liga\n",
      "Processing link 23: https://fbref.com/es/partidos/0839f02f/Elche-Real-Sociedad-Agosto-27-2022-La-Liga\n",
      "Processing link 24: https://fbref.com/es/partidos/21b1f2fd/Rayo-Vallecano-Mallorca-Agosto-27-2022-La-Liga\n",
      "Processing link 25: https://fbref.com/es/partidos/ef9a3cb4/Almeria-Sevilla-Agosto-27-2022-La-Liga\n",
      "Processing link 26: https://fbref.com/es/partidos/834124a1/Getafe-Villarreal-Agosto-28-2022-La-Liga\n",
      "Processing link 27: https://fbref.com/es/partidos/4ed9f64b/Barcelona-Valladolid-Agosto-28-2022-La-Liga\n",
      "Processing link 28: https://fbref.com/es/partidos/36d21a47/Espanyol-Real-Madrid-Agosto-28-2022-La-Liga\n",
      "Processing link 29: https://fbref.com/es/partidos/af336b4a/Cadiz-Athletic-Club-Agosto-29-2022-La-Liga\n",
      "Processing link 30: https://fbref.com/es/partidos/da3b5ed5/Valencia-Atletico-Madrid-Agosto-29-2022-La-Liga\n",
      "Processing link 31: https://fbref.com/es/partidos/66ac20bd/Celta-Vigo-Cadiz-Septiembre-2-2022-La-Liga\n",
      "Processing link 32: https://fbref.com/es/partidos/5d51fa0c/Mallorca-Girona-Septiembre-3-2022-La-Liga\n",
      "Processing link 33: https://fbref.com/es/partidos/7f84388c/Real-Madrid-Real-Betis-Septiembre-3-2022-La-Liga\n",
      "Processing link 34: https://fbref.com/es/partidos/ccb89898/Real-Sociedad-Atletico-Madrid-Septiembre-3-2022-La-Liga\n",
      "Processing link 35: https://fbref.com/es/partidos/7952eab7/Sevilla-Barcelona-Septiembre-3-2022-La-Liga\n",
      "Processing link 36: https://fbref.com/es/partidos/ef71bc61/Osasuna-Rayo-Vallecano-Septiembre-4-2022-La-Liga\n",
      "Processing link 37: https://fbref.com/es/partidos/9c491e2b/Athletic-Club-Espanyol-Septiembre-4-2022-La-Liga\n",
      "Processing link 38: https://fbref.com/es/partidos/1c460149/Villarreal-Elche-Septiembre-4-2022-La-Liga\n",
      "Processing link 39: https://fbref.com/es/partidos/65797851/Valencia-Getafe-Septiembre-4-2022-La-Liga\n",
      "Processing link 40: https://fbref.com/es/partidos/33b0a63b/Valladolid-Almeria-Septiembre-5-2022-La-Liga\n",
      "Processing link 41: https://fbref.com/es/partidos/67a548bd/Girona-Valladolid-Septiembre-9-2022-La-Liga\n",
      "Processing link 42: https://fbref.com/es/partidos/c159b9d8/Rayo-Vallecano-Valencia-Septiembre-10-2022-La-Liga\n",
      "Processing link 43: https://fbref.com/es/partidos/2705dc41/Espanyol-Sevilla-Septiembre-10-2022-La-Liga\n",
      "Processing link 44: https://fbref.com/es/partidos/50a0b6b9/Cadiz-Barcelona-Septiembre-10-2022-La-Liga\n",
      "Processing link 45: https://fbref.com/es/partidos/cc61d2ba/Atletico-Madrid-Celta-Vigo-Septiembre-10-2022-La-Liga\n",
      "Processing link 46: https://fbref.com/es/partidos/6cf98669/Real-Madrid-Mallorca-Septiembre-11-2022-La-Liga\n",
      "Processing link 47: https://fbref.com/es/partidos/ab2a8ab6/Elche-Athletic-Club-Septiembre-11-2022-La-Liga\n",
      "Processing link 48: https://fbref.com/es/partidos/3e47416b/Getafe-Real-Sociedad-Septiembre-11-2022-La-Liga\n",
      "Processing link 49: https://fbref.com/es/partidos/287c6564/Real-Betis-Villarreal-Septiembre-11-2022-La-Liga\n",
      "Processing link 50: https://fbref.com/es/partidos/12e36761/Almeria-Osasuna-Septiembre-12-2022-La-Liga\n",
      "Processing link 51: https://fbref.com/es/partidos/ec90c2fe/Valladolid-Cadiz-Septiembre-16-2022-La-Liga\n",
      "Processing link 52: https://fbref.com/es/partidos/8d5bc7c7/Mallorca-Almeria-Septiembre-17-2022-La-Liga\n",
      "Processing link 53: https://fbref.com/es/partidos/edcc3e7a/Barcelona-Elche-Septiembre-17-2022-La-Liga\n",
      "Processing link 54: https://fbref.com/es/partidos/5b51dc48/Valencia-Celta-Vigo-Septiembre-17-2022-La-Liga\n",
      "Processing link 55: https://fbref.com/es/partidos/dd04c982/Athletic-Club-Rayo-Vallecano-Septiembre-17-2022-La-Liga\n",
      "Processing link 56: https://fbref.com/es/partidos/c6483087/Osasuna-Getafe-Septiembre-18-2022-La-Liga\n",
      "Processing link 57: https://fbref.com/es/partidos/28815113/Villarreal-Sevilla-Septiembre-18-2022-La-Liga\n",
      "Processing link 58: https://fbref.com/es/partidos/cb6bce1d/Real-Betis-Girona-Septiembre-18-2022-La-Liga\n",
      "Processing link 59: https://fbref.com/es/partidos/ee1f906d/Real-Sociedad-Espanyol-Septiembre-18-2022-La-Liga\n",
      "Processing link 60: https://fbref.com/es/partidos/c554c5ac/El-Derbi-Madrileno-Atletico-Madrid-Real-Madrid-Septiembre-18-2022-La-Liga\n",
      "Processing link 61: https://fbref.com/es/partidos/54d6b3fc/Athletic-Club-Almeria-Septiembre-30-2022-La-Liga\n",
      "Processing link 62: https://fbref.com/es/partidos/c0d557e1/Cadiz-Villarreal-Octubre-1-2022-La-Liga\n",
      "Processing link 63: https://fbref.com/es/partidos/09f36184/Getafe-Valladolid-Octubre-1-2022-La-Liga\n",
      "Processing link 64: https://fbref.com/es/partidos/069f9f40/Sevilla-Atletico-Madrid-Octubre-1-2022-La-Liga\n",
      "Processing link 65: https://fbref.com/es/partidos/5e73ad1a/Mallorca-Barcelona-Octubre-1-2022-La-Liga\n",
      "Processing link 66: https://fbref.com/es/partidos/841d1e2c/Espanyol-Valencia-Octubre-2-2022-La-Liga\n",
      "Processing link 67: https://fbref.com/es/partidos/849eee87/Celta-Vigo-Real-Betis-Octubre-2-2022-La-Liga\n",
      "Processing link 68: https://fbref.com/es/partidos/3b56db84/Girona-Real-Sociedad-Octubre-2-2022-La-Liga\n",
      "Processing link 69: https://fbref.com/es/partidos/0665a24f/Real-Madrid-Osasuna-Octubre-2-2022-La-Liga\n",
      "Processing link 70: https://fbref.com/es/partidos/7044faa9/Rayo-Vallecano-Elche-Octubre-3-2022-La-Liga\n",
      "Processing link 71: https://fbref.com/es/partidos/ad03c9e1/Osasuna-Valencia-Octubre-7-2022-La-Liga\n",
      "Processing link 72: https://fbref.com/es/partidos/5fd47c38/Almeria-Rayo-Vallecano-Octubre-8-2022-La-Liga\n",
      "Processing link 73: https://fbref.com/es/partidos/87353d2b/Atletico-Madrid-Girona-Octubre-8-2022-La-Liga\n",
      "Processing link 74: https://fbref.com/es/partidos/6558ecf4/Sevilla-Athletic-Club-Octubre-8-2022-La-Liga\n",
      "Processing link 75: https://fbref.com/es/partidos/3e3f4235/Getafe-Real-Madrid-Octubre-8-2022-La-Liga\n",
      "Processing link 76: https://fbref.com/es/partidos/49ec6969/Valladolid-Real-Betis-Octubre-9-2022-La-Liga\n",
      "Processing link 77: https://fbref.com/es/partidos/77173e8b/Cadiz-Espanyol-Octubre-9-2022-La-Liga\n",
      "Processing link 78: https://fbref.com/es/partidos/058c86cf/Real-Sociedad-Villarreal-Octubre-9-2022-La-Liga\n",
      "Processing link 79: https://fbref.com/es/partidos/a32c09d3/Barcelona-Celta-Vigo-Octubre-9-2022-La-Liga\n",
      "Processing link 80: https://fbref.com/es/partidos/d3056cab/Elche-Mallorca-Octubre-10-2022-La-Liga\n",
      "Processing link 81: https://fbref.com/es/partidos/64f3e100/Rayo-Vallecano-Getafe-Octubre-14-2022-La-Liga\n",
      "Processing link 82: https://fbref.com/es/partidos/85293f4f/Girona-Cadiz-Octubre-15-2022-La-Liga\n",
      "Processing link 83: https://fbref.com/es/partidos/7493a41f/Valencia-Elche-Octubre-15-2022-La-Liga\n",
      "Processing link 84: https://fbref.com/es/partidos/1019503c/Mallorca-Sevilla-Octubre-15-2022-La-Liga\n",
      "Processing link 85: https://fbref.com/es/partidos/ca6228b4/Athletic-Club-Atletico-Madrid-Octubre-15-2022-La-Liga\n",
      "Processing link 86: https://fbref.com/es/partidos/7b270235/Celta-Vigo-Real-Sociedad-Octubre-16-2022-La-Liga\n",
      "Processing link 87: https://fbref.com/es/partidos/c1875f22/El-Clasico-Real-Madrid-Barcelona-Octubre-16-2022-La-Liga\n",
      "Processing link 88: https://fbref.com/es/partidos/3f1977ac/Espanyol-Valladolid-Octubre-16-2022-La-Liga\n",
      "Processing link 89: https://fbref.com/es/partidos/6510e441/Real-Betis-Almeria-Octubre-16-2022-La-Liga\n",
      "Processing link 90: https://fbref.com/es/partidos/4760076d/Villarreal-Osasuna-Octubre-17-2022-La-Liga\n",
      "Processing link 91: https://fbref.com/es/partidos/a3f2e116/Sevilla-Valencia-Octubre-18-2022-La-Liga\n",
      "Processing link 92: https://fbref.com/es/partidos/8b08659c/Getafe-Athletic-Club-Octubre-18-2022-La-Liga\n",
      "Processing link 93: https://fbref.com/es/partidos/99d51f3f/Atletico-Madrid-Rayo-Vallecano-Octubre-18-2022-La-Liga\n",
      "Processing link 94: https://fbref.com/es/partidos/1a9c7a37/Cadiz-Real-Betis-Octubre-19-2022-La-Liga\n",
      "Processing link 95: https://fbref.com/es/partidos/aa565872/Valladolid-Celta-Vigo-Octubre-19-2022-La-Liga\n",
      "Processing link 96: https://fbref.com/es/partidos/60393b8c/Real-Sociedad-Mallorca-Octubre-19-2022-La-Liga\n",
      "Processing link 97: https://fbref.com/es/partidos/8cccf9d8/Elche-Real-Madrid-Octubre-19-2022-La-Liga\n",
      "Processing link 98: https://fbref.com/es/partidos/49912abe/Almeria-Girona-Octubre-20-2022-La-Liga\n",
      "Processing link 99: https://fbref.com/es/partidos/01037ff0/Osasuna-Espanyol-Octubre-20-2022-La-Liga\n",
      "Processing link 100: https://fbref.com/es/partidos/1fc0e34e/Barcelona-Villarreal-Octubre-20-2022-La-Liga\n",
      "Processing link 101: https://fbref.com/es/partidos/d30035ab/Rayo-Vallecano-Cadiz-Octubre-22-2022-La-Liga\n",
      "Processing link 102: https://fbref.com/es/partidos/8aae24d6/Valladolid-Real-Sociedad-Octubre-22-2022-La-Liga\n",
      "Processing link 103: https://fbref.com/es/partidos/a9afb44e/Valencia-Mallorca-Octubre-22-2022-La-Liga\n",
      "Processing link 104: https://fbref.com/es/partidos/c5d94024/Real-Madrid-Sevilla-Octubre-22-2022-La-Liga\n",
      "Processing link 105: https://fbref.com/es/partidos/dfc7863c/Espanyol-Elche-Octubre-23-2022-La-Liga\n",
      "Processing link 106: https://fbref.com/es/partidos/ad6d83f1/Real-Betis-Atletico-Madrid-Octubre-23-2022-La-Liga\n",
      "Processing link 107: https://fbref.com/es/partidos/764f1270/Girona-Osasuna-Octubre-23-2022-La-Liga\n",
      "Processing link 108: https://fbref.com/es/partidos/fda8965c/Villarreal-Almeria-Octubre-23-2022-La-Liga\n",
      "Processing link 109: https://fbref.com/es/partidos/2fb55ba0/Barcelona-Athletic-Club-Octubre-23-2022-La-Liga\n",
      "Processing link 110: https://fbref.com/es/partidos/44682e39/Celta-Vigo-Getafe-Octubre-24-2022-La-Liga\n",
      "Processing link 111: https://fbref.com/es/partidos/2ce5c331/Mallorca-Espanyol-Octubre-28-2022-La-Liga\n",
      "Processing link 112: https://fbref.com/es/partidos/8fd8c270/Almeria-Celta-Vigo-Octubre-29-2022-La-Liga\n",
      "Processing link 113: https://fbref.com/es/partidos/bc23d0ab/Cadiz-Atletico-Madrid-Octubre-29-2022-La-Liga\n",
      "Processing link 114: https://fbref.com/es/partidos/a8b647af/Sevilla-Rayo-Vallecano-Octubre-29-2022-La-Liga\n",
      "Processing link 115: https://fbref.com/es/partidos/9abb9c34/Valencia-Barcelona-Octubre-29-2022-La-Liga\n",
      "Processing link 116: https://fbref.com/es/partidos/82851200/Osasuna-Valladolid-Octubre-30-2022-La-Liga\n",
      "Processing link 117: https://fbref.com/es/partidos/ffde27ac/Real-Madrid-Girona-Octubre-30-2022-La-Liga\n",
      "Processing link 118: https://fbref.com/es/partidos/4c9c43b6/Athletic-Club-Villarreal-Octubre-30-2022-La-Liga\n",
      "Processing link 119: https://fbref.com/es/partidos/dad5414f/Real-Sociedad-Real-Betis-Octubre-30-2022-La-Liga\n",
      "Processing link 120: https://fbref.com/es/partidos/4f0d05ab/Elche-Getafe-Octubre-31-2022-La-Liga\n",
      "Processing link 121: https://fbref.com/es/partidos/fbc9070c/Girona-Athletic-Club-Noviembre-4-2022-La-Liga\n",
      "Processing link 122: https://fbref.com/es/partidos/70ec6175/Getafe-Cadiz-Noviembre-5-2022-La-Liga\n",
      "Processing link 123: https://fbref.com/es/partidos/db09f5b6/Valladolid-Elche-Noviembre-5-2022-La-Liga\n",
      "Processing link 124: https://fbref.com/es/partidos/e551bbc8/Celta-Vigo-Osasuna-Noviembre-5-2022-La-Liga\n",
      "Processing link 125: https://fbref.com/es/partidos/b9cc54ac/Barcelona-Almeria-Noviembre-5-2022-La-Liga\n",
      "Processing link 126: https://fbref.com/es/partidos/19c1fbec/Atletico-Madrid-Espanyol-Noviembre-6-2022-La-Liga\n",
      "Processing link 127: https://fbref.com/es/partidos/86ebf3d1/Real-Sociedad-Valencia-Noviembre-6-2022-La-Liga\n",
      "Processing link 128: https://fbref.com/es/partidos/610230c8/Villarreal-Mallorca-Noviembre-6-2022-La-Liga\n",
      "Processing link 129: https://fbref.com/es/partidos/a8988680/Real-Betis-Sevilla-Noviembre-6-2022-La-Liga\n",
      "Processing link 130: https://fbref.com/es/partidos/fcff5859/Rayo-Vallecano-Real-Madrid-Noviembre-7-2022-La-Liga\n",
      "Processing link 131: https://fbref.com/es/partidos/ebaebf9c/Elche-Girona-Noviembre-8-2022-La-Liga\n",
      "Processing link 132: https://fbref.com/es/partidos/daafdb0b/Athletic-Club-Valladolid-Noviembre-8-2022-La-Liga\n",
      "Processing link 133: https://fbref.com/es/partidos/1eecb0cd/Osasuna-Barcelona-Noviembre-8-2022-La-Liga\n",
      "Processing link 134: https://fbref.com/es/partidos/28bef8bc/Almeria-Getafe-Noviembre-9-2022-La-Liga\n",
      "Processing link 135: https://fbref.com/es/partidos/f24d40c6/Sevilla-Real-Sociedad-Noviembre-9-2022-La-Liga\n",
      "Processing link 136: https://fbref.com/es/partidos/bb7701fa/Espanyol-Villarreal-Noviembre-9-2022-La-Liga\n",
      "Processing link 137: https://fbref.com/es/partidos/23d327b5/Mallorca-Atletico-Madrid-Noviembre-9-2022-La-Liga\n",
      "Processing link 138: https://fbref.com/es/partidos/80851b68/Rayo-Vallecano-Celta-Vigo-Noviembre-10-2022-La-Liga\n",
      "Processing link 139: https://fbref.com/es/partidos/daf1e1e7/Valencia-Real-Betis-Noviembre-10-2022-La-Liga\n",
      "Processing link 140: https://fbref.com/es/partidos/8413c8fa/Real-Madrid-Cadiz-Noviembre-10-2022-La-Liga\n",
      "Processing link 141: https://fbref.com/es/partidos/f1fddbae/Girona-Rayo-Vallecano-Diciembre-29-2022-La-Liga\n",
      "Processing link 142: https://fbref.com/es/partidos/348f39ff/Real-Betis-Athletic-Club-Diciembre-29-2022-La-Liga\n",
      "Processing link 143: https://fbref.com/es/partidos/8fb6eaaa/Atletico-Madrid-Elche-Diciembre-29-2022-La-Liga\n",
      "Processing link 144: https://fbref.com/es/partidos/c5637fb1/Getafe-Mallorca-Diciembre-30-2022-La-Liga\n",
      "Processing link 145: https://fbref.com/es/partidos/2f696974/Cadiz-Almeria-Diciembre-30-2022-La-Liga\n",
      "Processing link 146: https://fbref.com/es/partidos/6c96832f/Celta-Vigo-Sevilla-Diciembre-30-2022-La-Liga\n",
      "Processing link 147: https://fbref.com/es/partidos/a2d45f55/Valladolid-Real-Madrid-Diciembre-30-2022-La-Liga\n",
      "Processing link 148: https://fbref.com/es/partidos/2af3934b/Barcelona-Espanyol-Diciembre-31-2022-La-Liga\n",
      "Processing link 149: https://fbref.com/es/partidos/87d24f61/Real-Sociedad-Osasuna-Diciembre-31-2022-La-Liga\n",
      "Processing link 150: https://fbref.com/es/partidos/a3257da8/Villarreal-Valencia-Diciembre-31-2022-La-Liga\n",
      "Processing link 151: https://fbref.com/es/partidos/c2084c72/Elche-Celta-Vigo-Enero-6-2023-La-Liga\n",
      "Processing link 152: https://fbref.com/es/partidos/ee927bcc/Valencia-Cadiz-Enero-6-2023-La-Liga\n",
      "Processing link 153: https://fbref.com/es/partidos/477d4cdf/Villarreal-Real-Madrid-Enero-7-2023-La-Liga\n",
      "Processing link 154: https://fbref.com/es/partidos/6b820d45/Mallorca-Valladolid-Enero-7-2023-La-Liga\n",
      "Processing link 155: https://fbref.com/es/partidos/87fea3c7/Espanyol-Girona-Enero-7-2023-La-Liga\n",
      "Processing link 156: https://fbref.com/es/partidos/10b27265/Almeria-Real-Sociedad-Enero-8-2023-La-Liga\n",
      "Processing link 157: https://fbref.com/es/partidos/9ba59fd7/Rayo-Vallecano-Real-Betis-Enero-8-2023-La-Liga\n",
      "Processing link 158: https://fbref.com/es/partidos/b1dca05d/Sevilla-Getafe-Enero-8-2023-La-Liga\n",
      "Processing link 159: https://fbref.com/es/partidos/3169fc9b/Atletico-Madrid-Barcelona-Enero-8-2023-La-Liga\n",
      "Processing link 160: https://fbref.com/es/partidos/67f4644f/Athletic-Club-Osasuna-Enero-9-2023-La-Liga\n",
      "Processing link 161: https://fbref.com/es/partidos/8257d737/Celta-Vigo-Villarreal-Enero-13-2023-La-Liga\n",
      "Processing link 162: https://fbref.com/es/partidos/61f4e6c3/Valladolid-Rayo-Vallecano-Enero-14-2023-La-Liga\n",
      "Processing link 163: https://fbref.com/es/partidos/65182979/Girona-Sevilla-Enero-14-2023-La-Liga\n",
      "Processing link 164: https://fbref.com/es/partidos/cd2e3313/Osasuna-Mallorca-Enero-14-2023-La-Liga\n",
      "Processing link 165: https://fbref.com/es/partidos/53243b91/Real-Sociedad-Athletic-Club-Enero-14-2023-La-Liga\n",
      "Processing link 166: https://fbref.com/es/partidos/d5dc8a2c/Getafe-Espanyol-Enero-15-2023-La-Liga\n",
      "Processing link 167: https://fbref.com/es/partidos/aa527e49/Almeria-Atletico-Madrid-Enero-15-2023-La-Liga\n",
      "Processing link 168: https://fbref.com/es/partidos/43237dc2/Cadiz-Elche-Enero-16-2023-La-Liga\n",
      "Processing link 169: https://fbref.com/es/partidos/53d34361/Mallorca-Celta-Vigo-Enero-20-2023-La-Liga\n",
      "Processing link 170: https://fbref.com/es/partidos/6b5ac953/Rayo-Vallecano-Real-Sociedad-Enero-21-2023-La-Liga\n",
      "Processing link 171: https://fbref.com/es/partidos/377ddbd2/Espanyol-Real-Betis-Enero-21-2023-La-Liga\n",
      "Processing link 172: https://fbref.com/es/partidos/8b8d6b96/Atletico-Madrid-Valladolid-Enero-21-2023-La-Liga\n",
      "Processing link 173: https://fbref.com/es/partidos/318144c8/Sevilla-Cadiz-Enero-21-2023-La-Liga\n",
      "Processing link 174: https://fbref.com/es/partidos/f3666d93/Villarreal-Girona-Enero-22-2023-La-Liga\n",
      "Processing link 175: https://fbref.com/es/partidos/274b9a9c/Elche-Osasuna-Enero-22-2023-La-Liga\n",
      "Processing link 176: https://fbref.com/es/partidos/09f83bbc/Barcelona-Getafe-Enero-22-2023-La-Liga\n",
      "Processing link 177: https://fbref.com/es/partidos/ad94dd60/Athletic-Club-Real-Madrid-Enero-22-2023-La-Liga\n",
      "Processing link 178: https://fbref.com/es/partidos/b944484e/Valencia-Almeria-Enero-23-2023-La-Liga\n",
      "Processing link 179: https://fbref.com/es/partidos/58ddf563/Almeria-Espanyol-Enero-27-2023-La-Liga\n",
      "Processing link 180: https://fbref.com/es/partidos/f80c04f0/Cadiz-Mallorca-Enero-28-2023-La-Liga\n",
      "Processing link 181: https://fbref.com/es/partidos/05df662a/Girona-Barcelona-Enero-28-2023-La-Liga\n",
      "Processing link 182: https://fbref.com/es/partidos/bb7eb70e/Sevilla-Elche-Enero-28-2023-La-Liga\n",
      "Processing link 183: https://fbref.com/es/partidos/2532526d/Getafe-Real-Betis-Enero-28-2023-La-Liga\n",
      "Processing link 184: https://fbref.com/es/partidos/7ca28cbe/Valladolid-Valencia-Enero-29-2023-La-Liga\n",
      "Processing link 185: https://fbref.com/es/partidos/7b74b970/Osasuna-Atletico-Madrid-Enero-29-2023-La-Liga\n",
      "Processing link 186: https://fbref.com/es/partidos/897e2175/Celta-Vigo-Athletic-Club-Enero-29-2023-La-Liga\n",
      "Processing link 187: https://fbref.com/es/partidos/e75285fb/Real-Madrid-Real-Sociedad-Enero-29-2023-La-Liga\n",
      "Processing link 188: https://fbref.com/es/partidos/0681349c/Villarreal-Rayo-Vallecano-Enero-30-2023-La-Liga\n",
      "Processing link 189: https://fbref.com/es/partidos/1826e512/Real-Betis-Barcelona-Febrero-1-2023-La-Liga\n",
      "Processing link 190: https://fbref.com/es/partidos/c8355bdd/Real-Madrid-Valencia-Febrero-2-2023-La-Liga\n",
      "Processing link 191: https://fbref.com/es/partidos/4ad25809/Athletic-Club-Cadiz-Febrero-3-2023-La-Liga\n",
      "Processing link 192: https://fbref.com/es/partidos/0913c358/Espanyol-Osasuna-Febrero-4-2023-La-Liga\n",
      "Processing link 193: https://fbref.com/es/partidos/bbd97201/Elche-Villarreal-Febrero-4-2023-La-Liga\n",
      "Processing link 194: https://fbref.com/es/partidos/d98b5875/Atletico-Madrid-Getafe-Febrero-4-2023-La-Liga\n",
      "Processing link 195: https://fbref.com/es/partidos/21392431/Real-Betis-Celta-Vigo-Febrero-4-2023-La-Liga\n",
      "Processing link 196: https://fbref.com/es/partidos/a0914b2e/Mallorca-Real-Madrid-Febrero-5-2023-La-Liga\n",
      "Processing link 197: https://fbref.com/es/partidos/7b4e5dae/Girona-Valencia-Febrero-5-2023-La-Liga\n",
      "Processing link 198: https://fbref.com/es/partidos/3eac51cc/Real-Sociedad-Valladolid-Febrero-5-2023-La-Liga\n",
      "Processing link 199: https://fbref.com/es/partidos/1ccc0d2c/Barcelona-Sevilla-Febrero-5-2023-La-Liga\n",
      "Processing link 200: https://fbref.com/es/partidos/49ebcc28/Rayo-Vallecano-Almeria-Febrero-6-2023-La-Liga\n",
      "Processing link 201: https://fbref.com/es/partidos/dfda9563/Cadiz-Girona-Febrero-10-2023-La-Liga\n",
      "Processing link 202: https://fbref.com/es/partidos/6bb56f15/Almeria-Real-Betis-Febrero-11-2023-La-Liga\n",
      "Processing link 203: https://fbref.com/es/partidos/0792ae6b/Sevilla-Mallorca-Febrero-11-2023-La-Liga\n",
      "Processing link 204: https://fbref.com/es/partidos/26d50111/Valencia-Athletic-Club-Febrero-11-2023-La-Liga\n",
      "Processing link 205: https://fbref.com/es/partidos/8d4f770b/Getafe-Rayo-Vallecano-Febrero-12-2023-La-Liga\n",
      "Processing link 206: https://fbref.com/es/partidos/a34eae3f/Celta-Vigo-Atletico-Madrid-Febrero-12-2023-La-Liga\n",
      "Processing link 207: https://fbref.com/es/partidos/315c78f1/Valladolid-Osasuna-Febrero-12-2023-La-Liga\n",
      "Processing link 208: https://fbref.com/es/partidos/44e57939/Villarreal-Barcelona-Febrero-12-2023-La-Liga\n",
      "Processing link 209: https://fbref.com/es/partidos/7ed0a343/Espanyol-Real-Sociedad-Febrero-13-2023-La-Liga\n",
      "Processing link 210: https://fbref.com/es/partidos/aa81febc/Real-Madrid-Elche-Febrero-15-2023-La-Liga\n",
      "Processing link 211: https://fbref.com/es/partidos/6dd225f0/Girona-Almeria-Febrero-17-2023-La-Liga\n",
      "Processing link 212: https://fbref.com/es/partidos/312c107a/Real-Sociedad-Celta-Vigo-Febrero-18-2023-La-Liga\n",
      "Processing link 213: https://fbref.com/es/partidos/b5b65432/Real-Betis-Valladolid-Febrero-18-2023-La-Liga\n",
      "Processing link 214: https://fbref.com/es/partidos/abe1a0be/Mallorca-Villarreal-Febrero-18-2023-La-Liga\n",
      "Processing link 215: https://fbref.com/es/partidos/41878242/Osasuna-Real-Madrid-Febrero-18-2023-La-Liga\n",
      "Processing link 216: https://fbref.com/es/partidos/a94a07e1/Elche-Espanyol-Febrero-19-2023-La-Liga\n",
      "Processing link 217: https://fbref.com/es/partidos/bf5f27cd/Rayo-Vallecano-Sevilla-Febrero-19-2023-La-Liga\n",
      "Processing link 218: https://fbref.com/es/partidos/bc5d03d2/Atletico-Madrid-Athletic-Club-Febrero-19-2023-La-Liga\n",
      "Processing link 219: https://fbref.com/es/partidos/c3d1d09b/Barcelona-Cadiz-Febrero-19-2023-La-Liga\n",
      "Processing link 220: https://fbref.com/es/partidos/2d3fc14f/Getafe-Valencia-Febrero-20-2023-La-Liga\n",
      "Processing link 221: https://fbref.com/es/partidos/d13590ac/Elche-Real-Betis-Febrero-24-2023-La-Liga\n",
      "Processing link 222: https://fbref.com/es/partidos/446b1577/Espanyol-Mallorca-Febrero-25-2023-La-Liga\n",
      "Processing link 223: https://fbref.com/es/partidos/1e086908/Cadiz-Rayo-Vallecano-Febrero-25-2023-La-Liga\n",
      "Processing link 224: https://fbref.com/es/partidos/b51377f8/El-Derbi-Madrileno-Real-Madrid-Atletico-Madrid-Febrero-25-2023-La-Liga\n",
      "Processing link 225: https://fbref.com/es/partidos/fe69c87b/Valencia-Real-Sociedad-Febrero-25-2023-La-Liga\n",
      "Processing link 226: https://fbref.com/es/partidos/484db82d/Athletic-Club-Girona-Febrero-26-2023-La-Liga\n",
      "Processing link 227: https://fbref.com/es/partidos/5b7029e3/Celta-Vigo-Valladolid-Febrero-26-2023-La-Liga\n",
      "Processing link 228: https://fbref.com/es/partidos/47134469/Almeria-Barcelona-Febrero-26-2023-La-Liga\n",
      "Processing link 229: https://fbref.com/es/partidos/19bec97a/Sevilla-Osasuna-Febrero-26-2023-La-Liga\n",
      "Processing link 230: https://fbref.com/es/partidos/17268fc9/Villarreal-Getafe-Febrero-27-2023-La-Liga\n",
      "Processing link 231: https://fbref.com/es/partidos/d76a9b5c/Real-Sociedad-Cadiz-Marzo-3-2023-La-Liga\n",
      "Processing link 232: https://fbref.com/es/partidos/81393487/Getafe-Girona-Marzo-4-2023-La-Liga\n",
      "Processing link 233: https://fbref.com/es/partidos/366a3ab1/Almeria-Villarreal-Marzo-4-2023-La-Liga\n",
      "Processing link 234: https://fbref.com/es/partidos/14214742/Mallorca-Elche-Marzo-4-2023-La-Liga\n",
      "Processing link 235: https://fbref.com/es/partidos/7bfcaa51/Atletico-Madrid-Sevilla-Marzo-4-2023-La-Liga\n",
      "Processing link 236: https://fbref.com/es/partidos/f4163c1c/Valladolid-Espanyol-Marzo-5-2023-La-Liga\n",
      "Processing link 237: https://fbref.com/es/partidos/3dc648e6/Barcelona-Valencia-Marzo-5-2023-La-Liga\n",
      "Processing link 238: https://fbref.com/es/partidos/47a1d3f2/Rayo-Vallecano-Athletic-Club-Marzo-5-2023-La-Liga\n",
      "Processing link 239: https://fbref.com/es/partidos/971ff4d2/Real-Betis-Real-Madrid-Marzo-5-2023-La-Liga\n"
     ]
    }
   ],
   "source": [
    "run_full_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to see web situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta recibida: 200\n"
     ]
    }
   ],
   "source": [
    "'''# URL que estás intentando acceder\n",
    "url = \"https://fbref.com/es/partidos/33737218/Almeria-Real-Madrid-Agosto-19-2023-La-Liga\"\n",
    "\n",
    "# Número máximo de intentos\n",
    "max_retries = 5\n",
    "\n",
    "# Tiempo de espera entre intentos (en segundos)\n",
    "wait_time = 10\n",
    "\n",
    "# Intentar acceder a la página\n",
    "for attempt in range(max_retries):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Si la respuesta es 403, esperar antes de reintentar\n",
    "    if response.status_code == 403:\n",
    "        print(f\"Acceso prohibido. Esperando {wait_time} segundos antes de reintentar...\")\n",
    "        time.sleep(wait_time)\n",
    "    else:\n",
    "        print(f\"Respuesta recibida: {response.status_code}\")\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to input data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated row with id 351 in columns ['home_Players', 'home_PlayersAge', 'home_PlayersMinutes', 'home_PlayersGoals', 'home_PlayersShots', 'home_PlayersShotsOnTarget', 'home_PlayersCompletedPasses', 'home_PlayersAttemptedPasses', 'home_Players%CompletedPasses', 'home_PlayersDistancePasses', 'home_PlayersDistanceProgression', 'home_PlayersShortPasses', 'home_PlayersAttemptedShortPasses', 'home_Players%ShortCompletedPasses', 'home_PlayersMediumPasses', 'home_PlayersAttemptedMediumPasses', 'home_Players%MediumCompletedPasses', 'home_PlayersLongPasses', 'home_PlayersAttemptedLongPasses', 'home_Players%LongCompletedPasses', 'home_PlayersAssistance', 'home_PlayersExpectedGoalsAssistance', 'home_PlayersExpectedAssistance', 'home_PlayersKeyPasses', 'home_PlayersLast1/3Passes', 'home_PlayersGoalAreaPasses', 'home_PlayersGoalAreaCrosses', 'home_PlayersGoalPasses', 'home_PlayersLiveBallPasses', 'home_PlayersDeadBallPasses', 'home_PlayersFreeKick', 'home_PlayersSidePasses', 'home_PlayersCrosses', 'home_PlayersStrongcrosses', 'home_PlayersCorner', 'home_PlayersCornerIn', 'home_PlayersCornerOut', 'home_PlayersCornerRect', 'home_PlayersOffsidePasses', 'home_PlayersPassesBlocked', 'home_PlayersTackles', 'home_PlayersSuccessfulTackles', 'home_PlayersTacklesInDefense', 'home_PlayersTacklesInMedium', 'home_PlayersTacklesInAttack', 'home_PlayersDribblerTackles', 'home_PlayersAttemptedDribblerTackles', 'home_Players%DribblerTacklesCompleted', 'home_PlayersDribblerTacklesNonCompleted', 'home_PlayersBallsBlocked', 'home_PlayersShotsBlocked', 'home_PlayersInterceptions', 'home_PlayersTackles+Interceptions', 'home_PlayersClearances', 'home_PlayersMistakesRivalShots', 'home_PlayersTouches', 'home_PlayersOwnPenaltyAreaTouches', 'home_PlayersTouchesInDefense', 'home_PlayersTouchesInMedium', 'home_PlayersTouchesInAttack', 'home_PlayersAwayPenaltyAreaTouches', 'home_PlayersLiveBallTouches', 'home_PlayersAttemptedDribbles', 'home_PlayersDribblesCompleted', 'home_Players%DribblesCompleted', 'home_PlayersBallCarries', 'home_PlayersDistanceCarried', 'home_PlayersForwardDistanceCarried', 'home_PlayersForwardCarries', 'home_PlayersCarriesInAttack', 'home_PlayersAwayPenaltyAreaCarries', 'home_PlayersLostControlCarries', 'home_PlayersLostCarries', 'home_PlayersPassesReception', 'home_PlayersAttackPassesReception', 'home_PlayersYellowCards', 'home_PlayersRedCards', 'home_PlayersSecondYellowCards', 'home_PlayersFouls', 'home_PlayersOffside', 'home_PlayersPenalties', 'home_PlayersPenaltiesConceded', 'home_PlayersLostBallRecoveries', 'home_PlayersAerialsWon', 'home_PlayersAerialsLost', 'home_Players%AerialsWon', 'away_Players', 'away_PlayersAge', 'away_PlayersMinutes', 'away_PlayersGoals', 'away_PlayersShots', 'away_PlayersShotsOnTarget', 'away_PlayersCompletedPasses', 'away_PlayersAttemptedPasses', 'away_Players%CompletedPasses', 'away_PlayersDistancePasses', 'away_PlayersDistanceProgression', 'away_PlayersShortPasses', 'away_PlayersAttemptedShortPasses', 'away_Players%ShortCompletedPasses', 'away_PlayersMediumPasses', 'away_PlayersAttemptedMediumPasses', 'away_Players%MediumCompletedPasses', 'away_PlayersLongPasses', 'away_PlayersAttemptedLongPasses', 'away_Players%LongCompletedPasses', 'away_PlayersAssistance', 'away_PlayersExpectedGoalsAssistance', 'away_PlayersExpectedAssistance', 'away_PlayersKeyPasses', 'away_PlayersLast1/3Passes', 'away_PlayersGoalAreaPasses', 'away_PlayersGoalAreaCrosses', 'away_PlayersGoalPasses', 'away_PlayersLiveBallPasses', 'away_PlayersDeadBallPasses', 'away_PlayersFreeKick', 'away_PlayersSidePasses', 'away_PlayersCrosses', 'away_PlayersStrongcrosses', 'away_PlayersCorner', 'away_PlayersCornerIn', 'away_PlayersCornerOut', 'away_PlayersCornerRect', 'away_PlayersOffsidePasses', 'away_PlayersPassesBlocked', 'away_PlayersTackles', 'away_PlayersSuccessfulTackles', 'away_PlayersTacklesInDefense', 'away_PlayersTacklesInMedium', 'away_PlayersTacklesInAttack', 'away_PlayersDribblerTackles', 'away_PlayersAttemptedDribblerTackles', 'away_Players%DribblerTacklesCompleted', 'away_PlayersDribblerTacklesNonCompleted', 'away_PlayersBallsBlocked', 'away_PlayersShotsBlocked', 'away_PlayersInterceptions', 'away_PlayersTackles+Interceptions', 'away_PlayersClearances', 'away_PlayersMistakesRivalShots', 'away_PlayersTouches', 'away_PlayersOwnPenaltyAreaTouches', 'away_PlayersTouchesInDefense', 'away_PlayersTouchesInMedium', 'away_PlayersTouchesInAttack', 'away_PlayersAwayPenaltyAreaTouches', 'away_PlayersLiveBallTouches', 'away_PlayersAttemptedDribbles', 'away_PlayersDribblesCompleted', 'away_Players%DribblesCompleted', 'away_PlayersBallCarries', 'away_PlayersDistanceCarried', 'away_PlayersForwardDistanceCarried', 'away_PlayersForwardCarries', 'away_PlayersCarriesInAttack', 'away_PlayersAwayPenaltyAreaCarries', 'away_PlayersLostControlCarries', 'away_PlayersLostCarries', 'away_PlayersPassesReception', 'away_PlayersAttackPassesReception', 'away_PlayersYellowCards', 'away_PlayersRedCards', 'away_PlayersSecondYellowCards', 'away_PlayersFouls', 'away_PlayersOffside', 'away_PlayersPenalties', 'away_PlayersPenaltiesConceded', 'away_PlayersLostBallRecoveries', 'away_PlayersAerialsWon', 'away_PlayersAerialsLost', 'away_Players%AerialsWon'] with values ['16.0', '27.188', '990.0', '1.0', '10.0', '4.0', '371.0', '506.0', '73.3', '6341.0', '2310.0', '187.0', '217.0', '86.2', '141.0', '181.0', '77.9', '36.0', '80.0', '45.0', '0.0', '0.2', '0.5', '4.0', '24.0', '6.0', '1.0', '27.0', '445.0', '60.0', '13.0', '5.0', '14.0', '37.0', '2.0', '1.0', '0.0', '0.0', '1.0', '6.0', '16.0', '9.0', '9.0', '4.0', '3.0', '7.0', '11.0', '63.6', '4.0', '8.0', '2.0', '6.0', '24.0', '16.0', '0.0', '606.0', '41.0', '149.0', '301.0', '158.0', '18.0', '606.0', '10.0', '4.0', '40.0', '369.0', '1829.0', '683.0', '14.0', '13.0', '2.0', '13.0', '14.0', '362.0', '27.0', '0.0', '0.0', '0.0', '12.0', '9.0', '0.0', '0.0', '46.0', '22.0', '17.0', '56.4', '16.0', '29.125', '990.0', '1.0', '10.0', '4.0', '337.0', '458.0', '73.6', '5876.0', '2229.0', '163.0', '189.0', '86.2', '137.0', '166.0', '82.5', '30.0', '83.0', '36.1', '0.0', '0.3', '0.3', '5.0', '18.0', '6.0', '3.0', '33.0', '405.0', '50.0', '12.0', '1.0', '16.0', '25.0', '4.0', '2.0', '2.0', '0.0', '3.0', '6.0', '19.0', '11.0', '9.0', '9.0', '1.0', '5.0', '9.0', '55.6', '4.0', '6.0', '1.0', '5.0', '28.0', '39.0', '0.0', '584.0', '87.0', '234.0', '254.0', '97.0', '16.0', '584.0', '12.0', '4.0', '33.33', '314.0', '1666.0', '650.0', '8.0', '10.0', '0.0', '16.0', '9.0', '337.0', '13.0', '1.0', '0.0', '0.0', '11.0', '11.0', '0.0', '0.0', '42.0', '17.0', '22.0', '43.6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.188' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '990.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '371.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '506.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '73.3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6341.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2310.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '187.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '217.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '86.2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '141.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '181.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '77.9' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '36.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '80.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '45.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '24.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '445.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '60.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '14.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '37.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '7.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '63.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '8.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '24.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '606.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '41.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '149.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '301.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '158.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '18.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '606.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '40.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '369.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1829.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '683.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '14.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '14.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '362.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '12.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '46.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '22.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '17.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '56.4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '29.125' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '990.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '337.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '458.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '73.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5876.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2229.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '163.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '189.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '86.2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '137.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '166.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '82.5' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '83.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '36.1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '18.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '33.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '405.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '50.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '12.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '25.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '19.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '55.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '28.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '39.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '584.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '87.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '234.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '254.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '97.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '584.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '12.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '33.33' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '314.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1666.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '650.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '8.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '337.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '42.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '17.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '22.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '43.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n"
     ]
    }
   ],
   "source": [
    "'''# Leer el archivo CSV\n",
    "df = pd.read_csv('matches_2023-2024.csv')\n",
    "\n",
    "# Especifica el valor de la columna 'id' que quieres buscar\n",
    "target_id = 351\n",
    "\n",
    "# Encuentra la fila correspondiente al valor de 'id'\n",
    "row_index = df[df['id'] == target_id].index\n",
    "\n",
    "if not row_index.empty:\n",
    "    # Toma el índice de la fila encontrada\n",
    "    row_index = row_index[0]\n",
    "\n",
    "    # Especifica las columnas que quieres modificar y los nuevos valores\n",
    "    columns_to_modify = [\n",
    "        'home_Players', 'home_PlayersAge', 'home_PlayersMinutes', 'home_PlayersGoals', 'home_PlayersShots', \n",
    "        'home_PlayersShotsOnTarget', 'home_PlayersCompletedPasses', 'home_PlayersAttemptedPasses', \n",
    "        'home_Players%CompletedPasses', 'home_PlayersDistancePasses', 'home_PlayersDistanceProgression', \n",
    "        'home_PlayersShortPasses', 'home_PlayersAttemptedShortPasses', 'home_Players%ShortCompletedPasses', \n",
    "        'home_PlayersMediumPasses', 'home_PlayersAttemptedMediumPasses', 'home_Players%MediumCompletedPasses', \n",
    "        'home_PlayersLongPasses', 'home_PlayersAttemptedLongPasses', 'home_Players%LongCompletedPasses', \n",
    "        'home_PlayersAssistance', 'home_PlayersExpectedGoalsAssistance', 'home_PlayersExpectedAssistance', \n",
    "        'home_PlayersKeyPasses', 'home_PlayersLast1/3Passes', 'home_PlayersGoalAreaPasses', 'home_PlayersGoalAreaCrosses', \n",
    "        'home_PlayersGoalPasses', 'home_PlayersLiveBallPasses', 'home_PlayersDeadBallPasses', 'home_PlayersFreeKick', \n",
    "        'home_PlayersSidePasses', 'home_PlayersCrosses', 'home_PlayersStrongcrosses', 'home_PlayersCorner', \n",
    "        'home_PlayersCornerIn', 'home_PlayersCornerOut', 'home_PlayersCornerRect', 'home_PlayersOffsidePasses', \n",
    "        'home_PlayersPassesBlocked', 'home_PlayersTackles', 'home_PlayersSuccessfulTackles', 'home_PlayersTacklesInDefense', \n",
    "        'home_PlayersTacklesInMedium', 'home_PlayersTacklesInAttack', 'home_PlayersDribblerTackles', \n",
    "        'home_PlayersAttemptedDribblerTackles', 'home_Players%DribblerTacklesCompleted', 'home_PlayersDribblerTacklesNonCompleted', \n",
    "        'home_PlayersBallsBlocked', 'home_PlayersShotsBlocked', 'home_PlayersInterceptions', 'home_PlayersTackles+Interceptions', \n",
    "        'home_PlayersClearances', 'home_PlayersMistakesRivalShots', 'home_PlayersTouches', 'home_PlayersOwnPenaltyAreaTouches', \n",
    "        'home_PlayersTouchesInDefense', 'home_PlayersTouchesInMedium', 'home_PlayersTouchesInAttack', \n",
    "        'home_PlayersAwayPenaltyAreaTouches', 'home_PlayersLiveBallTouches', 'home_PlayersAttemptedDribbles', \n",
    "        'home_PlayersDribblesCompleted', 'home_Players%DribblesCompleted', 'home_PlayersBallCarries', \n",
    "        'home_PlayersDistanceCarried', 'home_PlayersForwardDistanceCarried', 'home_PlayersForwardCarries', \n",
    "        'home_PlayersCarriesInAttack', 'home_PlayersAwayPenaltyAreaCarries', 'home_PlayersLostControlCarries', \n",
    "        'home_PlayersLostCarries', 'home_PlayersPassesReception', 'home_PlayersAttackPassesReception', \n",
    "        'home_PlayersYellowCards', 'home_PlayersRedCards', 'home_PlayersSecondYellowCards', 'home_PlayersFouls', \n",
    "        'home_PlayersOffside', 'home_PlayersPenalties', 'home_PlayersPenaltiesConceded', 'home_PlayersLostBallRecoveries', \n",
    "        'home_PlayersAerialsWon', 'home_PlayersAerialsLost', 'home_Players%AerialsWon', 'away_Players', 'away_PlayersAge', \n",
    "        'away_PlayersMinutes', 'away_PlayersGoals', 'away_PlayersShots', 'away_PlayersShotsOnTarget', \n",
    "        'away_PlayersCompletedPasses', 'away_PlayersAttemptedPasses', 'away_Players%CompletedPasses', \n",
    "        'away_PlayersDistancePasses', 'away_PlayersDistanceProgression', 'away_PlayersShortPasses', \n",
    "        'away_PlayersAttemptedShortPasses', 'away_Players%ShortCompletedPasses', 'away_PlayersMediumPasses', \n",
    "        'away_PlayersAttemptedMediumPasses', 'away_Players%MediumCompletedPasses', 'away_PlayersLongPasses', \n",
    "        'away_PlayersAttemptedLongPasses', 'away_Players%LongCompletedPasses', 'away_PlayersAssistance', \n",
    "        'away_PlayersExpectedGoalsAssistance', 'away_PlayersExpectedAssistance', 'away_PlayersKeyPasses', \n",
    "        'away_PlayersLast1/3Passes', 'away_PlayersGoalAreaPasses', 'away_PlayersGoalAreaCrosses', 'away_PlayersGoalPasses', \n",
    "        'away_PlayersLiveBallPasses', 'away_PlayersDeadBallPasses', 'away_PlayersFreeKick', 'away_PlayersSidePasses', \n",
    "        'away_PlayersCrosses', 'away_PlayersStrongcrosses', 'away_PlayersCorner', 'away_PlayersCornerIn', \n",
    "        'away_PlayersCornerOut', 'away_PlayersCornerRect', 'away_PlayersOffsidePasses', 'away_PlayersPassesBlocked', \n",
    "        'away_PlayersTackles', 'away_PlayersSuccessfulTackles', 'away_PlayersTacklesInDefense', 'away_PlayersTacklesInMedium', \n",
    "        'away_PlayersTacklesInAttack', 'away_PlayersDribblerTackles', 'away_PlayersAttemptedDribblerTackles', \n",
    "        'away_Players%DribblerTacklesCompleted', 'away_PlayersDribblerTacklesNonCompleted', 'away_PlayersBallsBlocked', \n",
    "        'away_PlayersShotsBlocked', 'away_PlayersInterceptions', 'away_PlayersTackles+Interceptions', 'away_PlayersClearances', \n",
    "        'away_PlayersMistakesRivalShots', 'away_PlayersTouches', 'away_PlayersOwnPenaltyAreaTouches', \n",
    "        'away_PlayersTouchesInDefense', 'away_PlayersTouchesInMedium', 'away_PlayersTouchesInAttack', \n",
    "        'away_PlayersAwayPenaltyAreaTouches', 'away_PlayersLiveBallTouches', 'away_PlayersAttemptedDribbles', \n",
    "        'away_PlayersDribblesCompleted', 'away_Players%DribblesCompleted', 'away_PlayersBallCarries', \n",
    "        'away_PlayersDistanceCarried', 'away_PlayersForwardDistanceCarried', 'away_PlayersForwardCarries', \n",
    "        'away_PlayersCarriesInAttack', 'away_PlayersAwayPenaltyAreaCarries', 'away_PlayersLostControlCarries', \n",
    "        'away_PlayersLostCarries', 'away_PlayersPassesReception', 'away_PlayersAttackPassesReception', 'away_PlayersYellowCards', \n",
    "        'away_PlayersRedCards', 'away_PlayersSecondYellowCards', 'away_PlayersFouls', 'away_PlayersOffside', 'away_PlayersPenalties', \n",
    "        'away_PlayersPenaltiesConceded', 'away_PlayersLostBallRecoveries', 'away_PlayersAerialsWon', 'away_PlayersAerialsLost', \n",
    "        'away_Players%AerialsWon'\n",
    "    ]\n",
    "\n",
    "    new_values = [\n",
    "        '16.0','27.188','990.0','1.0','10.0','4.0','371.0','506.0','73.3','6341.0','2310.0','187.0','217.0','86.2','141.0','181.0','77.9','36.0','80.0','45.0','0.0','0.2','0.5','4.0','24.0','6.0','1.0','27.0','445.0','60.0','13.0','5.0','14.0','37.0','2.0','1.0','0.0','0.0','1.0','6.0','16.0','9.0','9.0','4.0','3.0','7.0','11.0','63.6','4.0','8.0','2.0','6.0','24.0','16.0','0.0','606.0','41.0','149.0','301.0','158.0','18.0','606.0','10.0','4.0','40.0','369.0','1829.0','683.0','14.0','13.0','2.0','13.0','14.0','362.0','27.0','0.0','0.0','0.0','12.0','9.0','0.0','0.0','46.0','22.0','17.0','56.4',\n",
    "        '16.0','29.125','990.0','1.0','10.0','4.0','337.0','458.0','73.6','5876.0','2229.0','163.0','189.0','86.2','137.0','166.0','82.5','30.0','83.0','36.1','0.0','0.3','0.3','5.0','18.0','6.0','3.0','33.0','405.0','50.0','12.0','1.0','16.0','25.0','4.0','2.0','2.0','0.0','3.0','6.0','19.0','11.0','9.0','9.0','1.0','5.0','9.0','55.6','4.0','6.0','1.0','5.0','28.0','39.0','0.0','584.0','87.0','234.0','254.0','97.0','16.0','584.0','12.0','4.0','33.33','314.0','1666.0','650.0','8.0','10.0','0.0','16.0','9.0','337.0','13.0','1.0','0.0','0.0','11.0','11.0','0.0','0.0','42.0','17.0','22.0','43.6'\n",
    "\n",
    "    ]  # Nuevos valores\n",
    "\n",
    "    # Modificar los valores en la fila especificada\n",
    "    for col, new_val in zip(columns_to_modify, new_values):\n",
    "        df.at[row_index, col] = new_val\n",
    "\n",
    "    # Guardar los cambios en el archivo CSV\n",
    "    df.to_csv('matches_2023-2024.csv', index=False)\n",
    "\n",
    "    print(f\"Updated row with id {target_id} in columns {columns_to_modify} with values {new_values}\")\n",
    "else:\n",
    "    print(f\"No row found with id {target_id}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api-python-bet-project-c88tlEpI-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
