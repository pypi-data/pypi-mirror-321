{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatizing new matches downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import requests\n",
    "from io import StringIO\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining match data from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match_data:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the class with the given URL.\n",
    "        \n",
    "        Args:\n",
    "            url (str): The URL to scrape match data from.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.links = []  # List to store match links\n",
    "        self.gameweeks = []  # List to store gameweek data\n",
    "    \n",
    "    def get_links(self):\n",
    "        \"\"\"\n",
    "        Get the match report links from the provided URL.\n",
    "        \n",
    "        This function scrapes the provided URL for match report links and stores them in the 'links' list.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the match report links.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)  # Send HTTP request to the URL\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')  # Parse the HTML content\n",
    "\n",
    "        # Find all cells containing match report links\n",
    "        report_cells = soup.find_all('td', {'data-stat': 'match_report'})\n",
    "\n",
    "        # Loop through each cell to extract the match links\n",
    "        for idx, cell in enumerate(report_cells):\n",
    "            link = cell.find('a')  # Find the anchor tag in the cell\n",
    "            if link:\n",
    "                url = link['href']  # Extract the link URL\n",
    "                self.links.append(f'https://fbref.com{url}')  # Append the full URL to the links list\n",
    "\n",
    "            # Stop after extracting a certain number of links (e.g., 5)\n",
    "            #if len(self.links) >= 30:\n",
    "            #    break\n",
    "            \n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        # Save the links to a DataFrame\n",
    "        df_links = pd.DataFrame(self.links, columns=['link'])\n",
    "\n",
    "        return df_links  # Return the cleaned DataFrame of links\n",
    "\n",
    "    def get_gameweek(self):\n",
    "        \"\"\"\n",
    "        Get the gameweek data from the provided URL.\n",
    "        \n",
    "        This function scrapes the provided URL for gameweek data and stores it in the 'gameweeks' list.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the gameweek data.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)  # Send HTTP request to the URL\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')  # Parse the HTML content\n",
    "\n",
    "        # Find all cells containing gameweek data\n",
    "        gameweek_cells = soup.find_all('th', {'data-stat': 'gameweek'})\n",
    "\n",
    "        # Loop through each cell to extract the gameweek values\n",
    "        for idx, cell in enumerate(gameweek_cells):\n",
    "            gameweek_value = cell.text.strip() if cell else 'N/A'  # Extract and clean the gameweek value\n",
    "\n",
    "            # Skip the 'Sem.' or empty values\n",
    "            if gameweek_value in ['Sem.', '']:\n",
    "                continue  # Skip this iteration and move to the next cell\n",
    "\n",
    "            self.gameweeks.append(gameweek_value)  # Append the value to the gameweeks list\n",
    "\n",
    "            # Stop after extracting a certain number of valid gameweeks (e.g., 5)\n",
    "            #if len(self.gameweeks) >= 30:\n",
    "            #    break\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        # Create a DataFrame from the gameweeks list\n",
    "        df_gameweeks = pd.DataFrame(self.gameweeks, columns=['gameweek'])\n",
    "\n",
    "        # Remove rows where the gameweek is 'Sem.' or empty\n",
    "        df_gameweeks = df_gameweeks[~df_gameweeks['gameweek'].isin(['Sem.', ''])]\n",
    "\n",
    "        return df_gameweeks  # Return the cleaned DataFrame of gameweeks\n",
    "\n",
    "    def create_matches_csv(self):\n",
    "        \"\"\"\n",
    "        Create a CSV file with match data, combining gameweek and match information.\n",
    "        \n",
    "        This function combines match details (e.g., teams, date, time) and gameweek data into a single DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing match details and gameweek data.\n",
    "        \"\"\"\n",
    "        # Create a DataFrame with empty values for the match data\n",
    "        df = pd.DataFrame({\n",
    "            'id': pd.Series([None] * len(self.links)),  # Create a new column with unique IDs for each match\n",
    "            'date_of_match': pd.Series([None] * len(self.links)),  \n",
    "            'hour_of_the_match': pd.Series([None] * len(self.links)),  \n",
    "            'home_team_name': pd.Series([None] * len(self.links)),  \n",
    "            'away_team_name': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'home_trainer': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'away_trainer': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'stadium': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'attendance': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'referee': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'var': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'home_team_lineup': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'away_team_lineup': pd.Series([None] * len(self.links), dtype='object'),\n",
    "            'possession_home': pd.Series([None] * len(self.links), dtype='object')\n",
    "        })\n",
    "\n",
    "        # Ensure that the 'date_of_match' column is converted to datetime format\n",
    "        df['date_of_match'] = pd.to_datetime(df['date_of_match'], format='%Y-%m-%d', errors='coerce') \n",
    "        # Ensure that the 'hour_of_the_match' column is converted to string format\n",
    "        df['hour_of_the_match'] = df['hour_of_the_match'].astype(str)\n",
    "\n",
    "        # Ensure that other columns are of the correct data type (string)\n",
    "        df['home_team_name'] = df['home_team_name'].astype(object)\n",
    "        df['away_team_name'] = df['away_team_name'].astype(str)\n",
    "        df['home_trainer'] = df['home_trainer'].astype(str)\n",
    "        df['away_trainer'] = df['away_trainer'].astype(str)\n",
    "        df['stadium'] = df['stadium'].astype(str)\n",
    "        df['attendance'] = df['attendance'].astype(str)\n",
    "        df['referee'] = df['referee'].astype(str)\n",
    "        df['var'] = df['var'].astype(str)\n",
    "        df['home_team_lineup'] = df['home_team_lineup'].astype(str)\n",
    "        df['away_team_lineup'] = df['away_team_lineup'].astype(str)\n",
    "        df['possession_home'] = df['possession_home'].astype(str)\n",
    "\n",
    "        # Get the links data\n",
    "        links = self.get_links()\n",
    "\n",
    "        # Get the gameweek data\n",
    "        gameweeks = self.get_gameweek()\n",
    "\n",
    "        # Create a DataFrame from the gameweek data and links data\n",
    "        df_gameweeks = pd.DataFrame(gameweeks, columns=['gameweek'])\n",
    "        df_links = pd.DataFrame(links, columns=['link'])\n",
    "\n",
    "        df_final = pd.concat([gameweeks, df], axis=1)\n",
    "        df_final = pd.concat([df_final, df_links], axis=1)\n",
    "\n",
    "        # Assign the final DataFrame to the class attribute with the new name\n",
    "        self.df_final = df_final  \n",
    "\n",
    "        return self.df_final  # Return the DataFrame to be used later\n",
    "\n",
    "    def get_statistics(self):\n",
    "        \"\"\"\n",
    "        Get match statistics from the links and save them to a CSV file.\n",
    "        \n",
    "        This function extracts detailed statistics (e.g., team lineups, referee, attendance) from the match links.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing match statistics.\n",
    "        \"\"\"\n",
    "        # Directly use the self.df DataFrame that contains the match and link data\n",
    "        links = self.df_final['link'].tolist()  \n",
    "\n",
    "        id = 0\n",
    "\n",
    "        # Loop through each match link and extract the statistics\n",
    "        for idx, link in enumerate(links):\n",
    "            try:\n",
    "                print(f\"Processing link {idx + 1}: {link}\")\n",
    "                headers = {\n",
    "                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "                    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "                    \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "                    \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "                    \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "                    \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "                    \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "                }\n",
    "                response = requests.get(link, headers=headers)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Initialize default values for match statistics\n",
    "                match_date = \"Unknown\"\n",
    "                match_time = \"Unknown\"\n",
    "                home_team_name = \"Unknown\"\n",
    "                away_team_name = \"Unknown\"\n",
    "                home_trainer = \"Unknown\"\n",
    "                away_trainer = \"Unknown\"\n",
    "                stadium = \"Unknown\"\n",
    "                attendance = \"Unknown\"\n",
    "                referee = \"Unknown\"\n",
    "                var = \"Unknown\"\n",
    "                home_team_lineup = \"Unknown\"\n",
    "                away_team_lineup = \"Unknown\"\n",
    "\n",
    "                # ID for each match\n",
    "                id += 1\n",
    "                self.df_final.at[idx, 'id'] = id\n",
    "\n",
    "                # Extract match date and time\n",
    "                date_element = soup.find('span', {'class': 'venuetime'})\n",
    "                if date_element:\n",
    "                    match_date = date_element.get('data-venue-date', \"Unknown\")\n",
    "                    match_time = date_element.get('data-venue-time', \"Unknown\")\n",
    "                self.df_final.at[idx, 'date_of_match'] = match_date\n",
    "                self.df_final.at[idx, 'hour_of_the_match'] = match_time\n",
    "\n",
    "                # Extract team names\n",
    "                teams_elements = soup.find_all('span', class_='teamandlogo')\n",
    "                if len(teams_elements) >= 2:\n",
    "                    home_team_name = teams_elements[0].text.strip()\n",
    "                    away_team_name = teams_elements[1].text.strip()\n",
    "                self.df_final.at[idx, 'home_team_name'] = home_team_name\n",
    "                self.df_final.at[idx, 'away_team_name'] = away_team_name\n",
    "\n",
    "                # Extract trainers (coaches) names\n",
    "                trainers_elements = soup.find_all('div', class_='datapoint')\n",
    "                trainer_count = 0\n",
    "                for trainer_element in trainers_elements:\n",
    "                    if 'Director Técnico' in trainer_element.text:\n",
    "                        trainer_name = trainer_element.text.split(':')[-1].strip()\n",
    "                        if trainer_count == 0:\n",
    "                            home_trainer = trainer_name\n",
    "                            trainer_count += 1\n",
    "                        elif trainer_count == 1:\n",
    "                            away_trainer = trainer_name\n",
    "                            trainer_count += 1\n",
    "                self.df_final.at[idx, 'home_trainer'] = home_trainer\n",
    "                self.df_final.at[idx, 'away_trainer'] = away_trainer\n",
    "\n",
    "                # Extract stadium information\n",
    "                stadium_element = soup.find('div', class_='scorebox_meta')\n",
    "                if stadium_element:\n",
    "                    stadium_info = stadium_element.find('strong', string=\"Sedes\")\n",
    "                    if stadium_info:\n",
    "                        stadium = stadium_info.find_next('small').find_next('small').text.strip()\n",
    "                self.df_final.at[idx, 'stadium'] = stadium\n",
    "\n",
    "                # Extract attendance information\n",
    "                attendance_element = soup.find('div', class_='scorebox_meta')\n",
    "                if attendance_element:\n",
    "                    attendance_info = attendance_element.find('strong', string=\"Asistencia\")\n",
    "                    if attendance_info:\n",
    "                        attendance = attendance_info.find_next('small').find_next('small').text.strip()\n",
    "                        try:\n",
    "                            attendance = int(attendance.replace(',', '').replace('.', ''))\n",
    "                        except ValueError:\n",
    "                            attendance = None\n",
    "                self.df_final.at[idx, 'attendance'] = attendance\n",
    "\n",
    "                # Extract referee information\n",
    "                referee_element = soup.find('div', class_='scorebox_meta')\n",
    "                if referee_element:\n",
    "                    referee_info = referee_element.find_next('strong', string=\"Autoridades\")\n",
    "                    if referee_info:\n",
    "                        referee_span = referee_info.find_next('small').find_next('small').find('span', style=\"display:inline-block\")\n",
    "                        if referee_span:\n",
    "                            referee = referee_span.text.strip()\n",
    "                self.df_final.at[idx, 'referee'] = referee\n",
    "\n",
    "                # Extract VAR information\n",
    "                var_element = soup.find('div', class_='scorebox_meta')\n",
    "                if var_element:\n",
    "                    var_info = var_element.find_next('strong', string=\"Autoridades\")\n",
    "                    if var_info:\n",
    "                        var_span = var_info.find_next('small').find_next('small').find_next('span').find_next('span').find_next('span').find_next('span').find_next('span')\n",
    "                        if var_span:\n",
    "                            var = var_span.text.strip()\n",
    "                self.df_final.at[idx, 'var'] = var\n",
    "\n",
    "                # Extract team lineups\n",
    "                lineup_elements = soup.find_all('th', string=lambda text: text and '(' in text and ')' in text)\n",
    "                if len(lineup_elements) >= 1:\n",
    "                    home_match = re.search(r'\\((.*?)\\)', lineup_elements[0].text)\n",
    "                    if home_match:\n",
    "                        home_team_lineup = home_match.group(1)\n",
    "                if len(lineup_elements) >= 2:\n",
    "                    away_match = re.search(r'\\((.*?)\\)', lineup_elements[1].text)\n",
    "                    if away_match:\n",
    "                        away_team_lineup = away_match.group(1)\n",
    "                self.df_final.at[idx, 'home_team_lineup'] = home_team_lineup\n",
    "                self.df_final.at[idx, 'away_team_lineup'] = away_team_lineup\n",
    "\n",
    "                # Remove rows that are completely empty\n",
    "                self.df_final = self.df_final.dropna(how='all')\n",
    "\n",
    "                time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing link {link}: {e}\")\n",
    "                continue\n",
    "\n",
    "        self.df_matches = self.df_final \n",
    "        return self.df_matches\n",
    "\n",
    "    def save_to_csv(self, season):\n",
    "        \"\"\"\n",
    "        Save the processed data into a CSV file, with the season included in the filename.\n",
    "        \n",
    "        Args:\n",
    "            season (str): The season to be included in the filename.\n",
    "        \"\"\"\n",
    "        # Define the filename with the season\n",
    "        filename = f'matches_{season}.csv'\n",
    "\n",
    "        # Save the DataFrame to a CSV file in the parent directory\n",
    "        self.df_matches.to_csv(filename, index=False)\n",
    "\n",
    "        # Print confirmation message with the file path\n",
    "        print(f\"File saved as {filename}\")\n",
    "\n",
    "    def run(self, url):\n",
    "        \"\"\"\n",
    "        Execute the full process: get links, get gameweeks, get statistics, and save to CSV files for both teams.\n",
    "        \n",
    "        Args:\n",
    "            url (str): The URL to start scraping the data from.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting matches data...\")\n",
    "\n",
    "        # Step 1: Extract the season from the URL\n",
    "        season_match = re.search(r'(\\d{4})-(\\d{4})', url)\n",
    "        if season_match:\n",
    "            season = season_match.group(0)\n",
    "        else:\n",
    "            season = 'unknown_season'  # Default value if the season cannot be extracted\n",
    "\n",
    "        # Step 2: Get all the links to the match pages from the provided URL\n",
    "\n",
    "        # Step 3: Get the gameweek data from the provided URL\n",
    "\n",
    "        # Step 4: Create a CSV file with match details, such as teams, dates, and other match-related information\n",
    "        self.create_matches_csv()\n",
    "\n",
    "        # Step 5: Retrieve statistics for each match, such as goals, assists, and other relevant data\n",
    "        df_matches = self.get_statistics()\n",
    "\n",
    "        # Step 6: Save the processed data into a CSV file with the season name in the filename\n",
    "        self.save_to_csv(season)\n",
    "\n",
    "        print(f\"Collecting matches data process completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining players and keeper data from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Players_data:\n",
    "    def __init__(self, url, gameweek):\n",
    "        \"\"\"\n",
    "        Initializes the MultiTableExtractor with a URL and gameweek.\n",
    "        - url: URL of the page to scrape.\n",
    "        - gameweek: The gameweek number to associate with the data.\n",
    "        \"\"\"\n",
    "        self.url = url  # Store the URL to scrape\n",
    "        self.gameweek = gameweek  # Store the gameweek number\n",
    "        self.soup = None  # Initialize BeautifulSoup object as None\n",
    "        self.teams_data = {}  # Dictionary to store team information\n",
    "\n",
    "    def fetch_page(self):\n",
    "        \"\"\"\n",
    "        Fetches the web page content from the provided URL and initializes BeautifulSoup.\n",
    "        Adds a delay to prevent overloading the server.\n",
    "        \"\"\"\n",
    "        # Send a GET request to the URL\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Error accessing the page: {response.status_code}\")\n",
    "\n",
    "        # Parse the page content using BeautifulSoup\n",
    "        self.soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def extract_teams_ids(self):\n",
    "        \"\"\"\n",
    "        Extracts the IDs and names of the home and away teams using team logos.\n",
    "        Raises an exception if less than two team logos are found.\n",
    "        \"\"\"\n",
    "        self.fetch_page()  # Fetch the web page content\n",
    "\n",
    "        # Find all team logos in the page (identified by the 'teamlogo' class)\n",
    "        team_imgs = self.soup.find_all('img', class_='teamlogo', src=True)\n",
    "\n",
    "        # Check if at least two team logos are found\n",
    "        if len(team_imgs) >= 2:\n",
    "            # Extract team IDs and names from the logos\n",
    "            self.teams_data = {\n",
    "                \"home\": {\n",
    "                    \"id\": team_imgs[0]['src'].split('/')[-1].split('.')[0],  # Extract ID from the image URL\n",
    "                    \"name\": team_imgs[0]['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\"),  # Extract team name from the alt attribute\n",
    "                },\n",
    "                \"away\": {\n",
    "                    \"id\": team_imgs[1]['src'].split('/')[-1].split('.')[0],\n",
    "                    \"name\": team_imgs[1]['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\"),  \n",
    "                },\n",
    "            }\n",
    "        else:\n",
    "            # Raise an error if less than two team logos are found\n",
    "            raise Exception(\"Not enough team logos found.\")\n",
    "\n",
    "    def extract_players_table(self, team_type, table_type, header_offset, columns_to_drop):\n",
    "        \"\"\"\n",
    "        Extracts a specific player statistics table for the given team and table type.\n",
    "        - team_type: \"home\" or \"away\".\n",
    "        - table_type: Type of the table (e.g., \"summary\", \"passing\").\n",
    "        - header_offset: Number of header columns to skip.\n",
    "        - columns_to_drop: List of columns to drop from the table.\n",
    "        \"\"\"\n",
    "        # Get the team ID based on the team type (home or away)\n",
    "        team_id = self.teams_data[team_type][\"id\"]\n",
    "\n",
    "        # Construct the CSS selector for the specific table\n",
    "        players_table_selector = f\"#div_stats_{team_id}_{table_type}\"\n",
    "\n",
    "        # Select the table element using the constructed selector\n",
    "        table = self.soup.select_one(players_table_selector)\n",
    "\n",
    "        # Check if the table exists\n",
    "        if not table:\n",
    "            raise Exception(f\"Payers table {table_type} not found for team {team_type}.\")\n",
    "\n",
    "        # Extract headers from the table, skipping the specified number of columns\n",
    "        headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")][header_offset:]\n",
    "\n",
    "        # Extract rows of data from the table body\n",
    "        rows = [\n",
    "            [cell.text.strip() for cell in row.find_all([\"td\", \"th\"])]\n",
    "            for row in table.find(\"tbody\").find_all(\"tr\")\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame from the extracted rows and headers\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        # Drop unnecessary columns specified in the columns_to_drop list\n",
    "        df = df.loc[:, ~df.columns.isin(columns_to_drop)]\n",
    "\n",
    "        return df\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def process_players_data(self, team_type):\n",
    "        \"\"\"\n",
    "        Processes all player statistics tables for a specific team (home or away).\n",
    "        Combines data from multiple table types into a dictionary of DataFrames.\n",
    "        \"\"\"\n",
    "        # Define columns to drop for each table type\n",
    "        columns_to_drop = {\n",
    "            \"summary\": ['Ass', 'TP', 'TPint', 'TA', 'TR', 'Toques', 'Tkl', 'Int', 'Bloqueos', 'xG', 'npxG', 'xAG', 'ACT', 'ACG', 'Cmp', 'Int.', '% Cmp', 'PrgP', 'Transportes', 'PrgC', 'Att', 'Succ'],\n",
    "            \"passing\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín'],\n",
    "            \"passing_types\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín', 'Int.', 'Cmp'],\n",
    "            \"defense\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín'],\n",
    "            \"possession\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín', 'Tkld', 'Tkld%'],\n",
    "            \"misc\": ['Jugador', 'núm.', 'País', 'Posc', 'Edad', 'Mín', 'Pcz', 'PA', 'Int', 'TklG', 'GC'],\n",
    "        }\n",
    "\n",
    "        # Initialize an empty dictionary to store DataFrames for each table type\n",
    "        tables = {}\n",
    "\n",
    "        # Loop through each table type and extract its data\n",
    "        for table_type, header_offset in [\n",
    "            (\"summary\", 7), (\"passing\", 9), (\"passing_types\", 4),\n",
    "            (\"defense\", 5), (\"possession\", 5), (\"misc\", 3)\n",
    "        ]:\n",
    "            tables[table_type] = self.extract_players_table(\n",
    "                team_type, table_type, header_offset, columns_to_drop.get(table_type, [])\n",
    "            )\n",
    "\n",
    "        return tables\n",
    "\n",
    "    def save_players_tables(self, match, season):\n",
    "        \"\"\"\n",
    "        Processes and saves player statistics tables for both home and away teams.\n",
    "        Combines data from all table types and writes the final table to a CSV file.\n",
    "        \"\"\"\n",
    "        # Extract IDs and names of the teams\n",
    "        self.extract_teams_ids()\n",
    "\n",
    "        # Process data for both home and away teams\n",
    "        for team_type in [\"home\", \"away\"]:\n",
    "            # Get the team name\n",
    "            team_name = self.teams_data[team_type][\"name\"]\n",
    "\n",
    "            # Extract and process all player statistics tables for the team\n",
    "            team_tables = self.process_players_data(team_type)\n",
    "\n",
    "            # Combine all extracted tables into a single DataFrame\n",
    "            final_table = pd.concat(team_tables.values(), axis=1)\n",
    "\n",
    "            # Define the new column names for the dataset with the team_type prefix\n",
    "            new_columns = [\n",
    "                f\"{team_type}_Players\", f\"{team_type}_Number\", f\"{team_type}_Nationality\", f\"{team_type}_Position\", \n",
    "                f\"{team_type}_PlayersAge\", f\"{team_type}_PlayersMinutes\", f\"{team_type}_PlayersGoals\", \n",
    "                f\"{team_type}_PlayersShots\", f\"{team_type}_PlayersShotsOnTarget\", f\"{team_type}_PlayersCompletedPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedPasses\", f\"{team_type}_Players%CompletedPasses\", \n",
    "                f\"{team_type}_PlayersDistancePasses\", f\"{team_type}_PlayersDistanceProgression\", \n",
    "                f\"{team_type}_PlayersShortPasses\", f\"{team_type}_PlayersAttemptedShortPasses\", \n",
    "                f\"{team_type}_Players%ShortCompletedPasses\", f\"{team_type}_PlayersMediumPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\", f\"{team_type}_Players%MediumCompletedPasses\", \n",
    "                f\"{team_type}_PlayersLongPasses\", f\"{team_type}_PlayersAttemptedLongPasses\", \n",
    "                f\"{team_type}_Players%LongCompletedPasses\", f\"{team_type}_PlayersAssistance\", \n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\", f\"{team_type}_PlayersExpectedAssistance\", \n",
    "                f\"{team_type}_PlayersKeyPasses\", f\"{team_type}_PlayersLast1/3Passes\", f\"{team_type}_PlayersGoalAreaPasses\", \n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\", f\"{team_type}_PlayersGoalPasses\", f\"{team_type}_PlayersLiveBallPasses\", \n",
    "                f\"{team_type}_PlayersDeadBallPasses\", f\"{team_type}_PlayersFreeKick\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersSidePasses\", f\"{team_type}_PlayersCrosses\", f\"{team_type}_PlayersStrongcrosses\", \n",
    "                f\"{team_type}_PlayersCorner\", f\"{team_type}_PlayersCornerIn\", f\"{team_type}_PlayersCornerOut\", \n",
    "                f\"{team_type}_PlayersCornerRect\", f\"{team_type}_PlayersOffsidePasses\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersTackles\", f\"{team_type}_PlayersSuccessfulTackles\", f\"{team_type}_PlayersTacklesInDefense\", \n",
    "                f\"{team_type}_PlayersTacklesInMedium\", f\"{team_type}_PlayersTacklesInAttack\", f\"{team_type}_PlayersDribblerTackles\", \n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\", f\"{team_type}_Players%DribblerTacklesCompleted\", \n",
    "                f\"{team_type}_PlayersDribblerTacklesNonCompleted\", f\"{team_type}_PlayersBallsBlocked\", \n",
    "                f\"{team_type}_PlayersShotsBlocked\", f\"{team_type}_PlayersPassesBlocked\", f\"{team_type}_PlayersInterceptions\", \n",
    "                f\"{team_type}_PlayersTackles+Interceptions\", f\"{team_type}_PlayersClearances\", f\"{team_type}_PlayersMistakesRivalShots\", \n",
    "                f\"{team_type}_PlayersTouches\", f\"{team_type}_PlayersOwnPenaltyAreaTouches\", f\"{team_type}_PlayersTouchesInDefense\", \n",
    "                f\"{team_type}_PlayersTouchesInMedium\", f\"{team_type}_PlayersTouchesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\", f\"{team_type}_PlayersLiveBallTouches\", \n",
    "                f\"{team_type}_PlayersAttemptedDribbles\", f\"{team_type}_PlayersDribblesCompleted\", \n",
    "                f\"{team_type}_Players%DribblesCompleted\", f\"{team_type}_PlayersBallCarries\", f\"{team_type}_PlayersDistanceCarried\", \n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\", f\"{team_type}_PlayersForwardCarries\", \n",
    "                f\"{team_type}_PlayersCarriesInAttack\", f\"{team_type}_PlayersAwayPenaltyAreaCarries\", \n",
    "                f\"{team_type}_PlayersLostControlCarries\", f\"{team_type}_PlayersLostCarries\", f\"{team_type}_PlayersPassesReception\", \n",
    "                f\"{team_type}_PlayersAttackPassesReception\", f\"{team_type}_PlayersYellowCards\", f\"{team_type}_PlayersRedCards\", \n",
    "                f\"{team_type}_PlayersSecondYellowCards\", f\"{team_type}_PlayersFouls\", f\"{team_type}_PlayersOffside\", \n",
    "                f\"{team_type}_PlayersPenalties\", f\"{team_type}_PlayersPenaltiesConceded\", f\"{team_type}_PlayersLostBallRecoveries\", \n",
    "                f\"{team_type}_PlayersAerialsWon\", f\"{team_type}_PlayersAerialsLost\", f\"{team_type}_Players%AerialsWon\"\n",
    "            ]\n",
    "\n",
    "            # Rename the columns of the DataFrame\n",
    "            final_table.columns = new_columns\n",
    "\n",
    "            # Convert the 'Age' column to integer by extracting the first two characters\n",
    "            final_table[f'{team_type}_PlayersAge'] = final_table[f'{team_type}_PlayersAge'].apply(\n",
    "                lambda x: int(x[:2]) if isinstance(x, str) else 0\n",
    "            )\n",
    "\n",
    "            # Define columns to calculate the mean\n",
    "            columns_to_mean = [\n",
    "                f\"{team_type}_PlayersAge\", f\"{team_type}_Players%CompletedPasses\", \n",
    "                f\"{team_type}_Players%ShortCompletedPasses\", f\"{team_type}_Players%MediumCompletedPasses\", \n",
    "                f\"{team_type}_Players%LongCompletedPasses\", f\"{team_type}_Players%DribblerTacklesCompleted\", \n",
    "                f\"{team_type}_Players%DribblesCompleted\", f\"{team_type}_Players%AerialsWon\"\n",
    "            ]\n",
    "\n",
    "            # Define columns to calculate the sum\n",
    "            columns_to_sum = [\n",
    "                f\"{team_type}_PlayersMinutes\", f\"{team_type}_PlayersGoals\", f\"{team_type}_PlayersShots\", \n",
    "                f\"{team_type}_PlayersShotsOnTarget\", f\"{team_type}_PlayersCompletedPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedPasses\", f\"{team_type}_PlayersDistancePasses\", \n",
    "                f\"{team_type}_PlayersDistanceProgression\", f\"{team_type}_PlayersShortPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedShortPasses\", f\"{team_type}_PlayersMediumPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedLongPasses\", f\"{team_type}_PlayersAssistance\", \n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\", f\"{team_type}_PlayersExpectedAssistance\", \n",
    "                f\"{team_type}_PlayersKeyPasses\", f\"{team_type}_PlayersLast1/3Passes\", f\"{team_type}_PlayersGoalAreaPasses\", \n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\", f\"{team_type}_PlayersGoalPasses\", f\"{team_type}_PlayersLiveBallPasses\", \n",
    "                f\"{team_type}_PlayersDeadBallPasses\", f\"{team_type}_PlayersFreeKick\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersSidePasses\", f\"{team_type}_PlayersCrosses\", f\"{team_type}_PlayersStrongcrosses\", \n",
    "                f\"{team_type}_PlayersCorner\", f\"{team_type}_PlayersCornerIn\", f\"{team_type}_PlayersCornerOut\", \n",
    "                f\"{team_type}_PlayersCornerRect\", f\"{team_type}_PlayersOffsidePasses\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersTackles\", f\"{team_type}_PlayersSuccessfulTackles\", f\"{team_type}_PlayersTacklesInDefense\", \n",
    "                f\"{team_type}_PlayersTacklesInMedium\", f\"{team_type}_PlayersTacklesInAttack\", f\"{team_type}_PlayersDribblerTackles\", \n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\", f\"{team_type}_PlayersDribblerTacklesNonCompleted\", \n",
    "                f\"{team_type}_PlayersBallsBlocked\", f\"{team_type}_PlayersShotsBlocked\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersInterceptions\", f\"{team_type}_PlayersTackles+Interceptions\", f\"{team_type}_PlayersClearances\", \n",
    "                f\"{team_type}_PlayersMistakesRivalShots\", f\"{team_type}_PlayersTouches\", f\"{team_type}_PlayersOwnPenaltyAreaTouches\", \n",
    "                f\"{team_type}_PlayersTouchesInDefense\", f\"{team_type}_PlayersTouchesInMedium\", f\"{team_type}_PlayersTouchesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\", f\"{team_type}_PlayersLiveBallTouches\", f\"{team_type}_PlayersAttemptedDribbles\", \n",
    "                f\"{team_type}_PlayersDribblesCompleted\", f\"{team_type}_PlayersBallCarries\", f\"{team_type}_PlayersDistanceCarried\", \n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\", f\"{team_type}_PlayersForwardCarries\", f\"{team_type}_PlayersCarriesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaCarries\", f\"{team_type}_PlayersLostControlCarries\", f\"{team_type}_PlayersLostCarries\", \n",
    "                f\"{team_type}_PlayersPassesReception\", f\"{team_type}_PlayersAttackPassesReception\", f\"{team_type}_PlayersYellowCards\", \n",
    "                f\"{team_type}_PlayersRedCards\", f\"{team_type}_PlayersSecondYellowCards\", f\"{team_type}_PlayersFouls\", \n",
    "                f\"{team_type}_PlayersOffside\", f\"{team_type}_PlayersPenalties\", f\"{team_type}_PlayersPenaltiesConceded\", \n",
    "                f\"{team_type}_PlayersLostBallRecoveries\", f\"{team_type}_PlayersAerialsWon\", f\"{team_type}_PlayersAerialsLost\"\n",
    "            ]\n",
    "\n",
    "            # Convert the mean columns to numeric\n",
    "            for col in columns_to_mean:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Convert the sum columns to numeric\n",
    "            for col in columns_to_sum:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Calculate the mean and sum for specified columns\n",
    "            mean_values = final_table[columns_to_mean].mean()\n",
    "            sum_values = final_table[columns_to_sum].sum()\n",
    "\n",
    "            # Create a new row for totals with placeholder values\n",
    "            total_row = {col: '-' for col in final_table.columns}\n",
    "\n",
    "            # Populate the total row with mean values\n",
    "            for col, mean in mean_values.items():\n",
    "                total_row[col] = mean\n",
    "\n",
    "            # Populate the total row with sum values\n",
    "            for col, total in sum_values.items():\n",
    "                total_row[col] = total\n",
    "\n",
    "            # Add the number of rows (lines) to the first column of the total row\n",
    "            num_lines = len(final_table)\n",
    "            total_row[final_table.columns[0]] = num_lines\n",
    "\n",
    "            # Check if the 'id' column exists, if not, create it with NaN values\n",
    "            if 'id' not in final_table.columns:\n",
    "                final_table['id'] = np.nan  # Create the column with NaN values\n",
    "\n",
    "            # Add the match ID to the total row\n",
    "            total_row['id'] = match\n",
    "\n",
    "            # Append the total row to the DataFrame\n",
    "            final_table.loc[len(final_table)] = total_row\n",
    "\n",
    "            # Save the combined table to a CSV file\n",
    "            #output_filename = f\"{self.gameweek}_{match}_{team_name}_{team_type}_players_table.csv\"\n",
    "            #final_table.to_csv(output_filename, index=False)\n",
    "\n",
    "            # Define the columns to append to the existing CSV\n",
    "            columns_to_append = [\n",
    "                f\"{team_type}_Players\", \n",
    "                f\"{team_type}_PlayersAge\", f\"{team_type}_PlayersMinutes\", f\"{team_type}_PlayersGoals\", \n",
    "                f\"{team_type}_PlayersShots\", f\"{team_type}_PlayersShotsOnTarget\", f\"{team_type}_PlayersCompletedPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedPasses\", f\"{team_type}_Players%CompletedPasses\", \n",
    "                f\"{team_type}_PlayersDistancePasses\", f\"{team_type}_PlayersDistanceProgression\", \n",
    "                f\"{team_type}_PlayersShortPasses\", f\"{team_type}_PlayersAttemptedShortPasses\", \n",
    "                f\"{team_type}_Players%ShortCompletedPasses\", f\"{team_type}_PlayersMediumPasses\", \n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\", f\"{team_type}_Players%MediumCompletedPasses\", \n",
    "                f\"{team_type}_PlayersLongPasses\", f\"{team_type}_PlayersAttemptedLongPasses\", \n",
    "                f\"{team_type}_Players%LongCompletedPasses\", f\"{team_type}_PlayersAssistance\", \n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\", f\"{team_type}_PlayersExpectedAssistance\", \n",
    "                f\"{team_type}_PlayersKeyPasses\", f\"{team_type}_PlayersLast1/3Passes\", f\"{team_type}_PlayersGoalAreaPasses\", \n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\", f\"{team_type}_PlayersGoalPasses\", f\"{team_type}_PlayersLiveBallPasses\", \n",
    "                f\"{team_type}_PlayersDeadBallPasses\", f\"{team_type}_PlayersFreeKick\", f\"{team_type}_PlayersLongPasses\", \n",
    "                f\"{team_type}_PlayersSidePasses\", f\"{team_type}_PlayersCrosses\", f\"{team_type}_PlayersStrongcrosses\", \n",
    "                f\"{team_type}_PlayersCorner\", f\"{team_type}_PlayersCornerIn\", f\"{team_type}_PlayersCornerOut\", \n",
    "                f\"{team_type}_PlayersCornerRect\", f\"{team_type}_PlayersOffsidePasses\", f\"{team_type}_PlayersPassesBlocked\", \n",
    "                f\"{team_type}_PlayersTackles\", f\"{team_type}_PlayersSuccessfulTackles\", f\"{team_type}_PlayersTacklesInDefense\", \n",
    "                f\"{team_type}_PlayersTacklesInMedium\", f\"{team_type}_PlayersTacklesInAttack\", f\"{team_type}_PlayersDribblerTackles\", \n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\", f\"{team_type}_Players%DribblerTacklesCompleted\", \n",
    "                f\"{team_type}_PlayersDribblerTacklesNonCompleted\", f\"{team_type}_PlayersBallsBlocked\", \n",
    "                f\"{team_type}_PlayersShotsBlocked\", f\"{team_type}_PlayersPassesBlocked\", f\"{team_type}_PlayersInterceptions\", \n",
    "                f\"{team_type}_PlayersTackles+Interceptions\", f\"{team_type}_PlayersClearances\", f\"{team_type}_PlayersMistakesRivalShots\", \n",
    "                f\"{team_type}_PlayersTouches\", f\"{team_type}_PlayersOwnPenaltyAreaTouches\", f\"{team_type}_PlayersTouchesInDefense\", \n",
    "                f\"{team_type}_PlayersTouchesInMedium\", f\"{team_type}_PlayersTouchesInAttack\", \n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\", f\"{team_type}_PlayersLiveBallTouches\", \n",
    "                f\"{team_type}_PlayersAttemptedDribbles\", f\"{team_type}_PlayersDribblesCompleted\", \n",
    "                f\"{team_type}_Players%DribblesCompleted\", f\"{team_type}_PlayersBallCarries\", f\"{team_type}_PlayersDistanceCarried\", \n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\", f\"{team_type}_PlayersForwardCarries\", \n",
    "                f\"{team_type}_PlayersCarriesInAttack\", f\"{team_type}_PlayersAwayPenaltyAreaCarries\", \n",
    "                f\"{team_type}_PlayersLostControlCarries\", f\"{team_type}_PlayersLostCarries\", f\"{team_type}_PlayersPassesReception\", \n",
    "                f\"{team_type}_PlayersAttackPassesReception\", f\"{team_type}_PlayersYellowCards\", f\"{team_type}_PlayersRedCards\", \n",
    "                f\"{team_type}_PlayersSecondYellowCards\", f\"{team_type}_PlayersFouls\", f\"{team_type}_PlayersOffside\", \n",
    "                f\"{team_type}_PlayersPenalties\", f\"{team_type}_PlayersPenaltiesConceded\", f\"{team_type}_PlayersLostBallRecoveries\", \n",
    "                f\"{team_type}_PlayersAerialsWon\", f\"{team_type}_PlayersAerialsLost\", f\"{team_type}_Players%AerialsWon\"\n",
    "            ]\n",
    "\n",
    "            # Extract the last row from final_table (this contains the sums and means)\n",
    "            last_row = final_table.iloc[-1][columns_to_append]\n",
    "\n",
    "            #Define the filename for the current season\n",
    "            filename = f\"matches_{season}.csv\"\n",
    "\n",
    "            # Load the existing CSV file from the parent directory\n",
    "            existing_df = pd.read_csv(filename)\n",
    "\n",
    "            # Get the ID from the last row of final_table\n",
    "            last_row_id = final_table.iloc[-1]['id']\n",
    "\n",
    "            # Find the row in the existing CSV based on the ID\n",
    "            row_index = existing_df[existing_df['id'] == last_row_id].index\n",
    "\n",
    "            # Check if the row exists\n",
    "            if row_index.empty:\n",
    "                raise ValueError(f\"Error: No row with ID {last_row_id} found in {filename}\")\n",
    "\n",
    "            # Check if the columns exist in the existing CSV, if not, create them after the existing columns\n",
    "            for column in columns_to_append:\n",
    "                if column not in existing_df.columns:\n",
    "                    existing_df[column] = pd.NA  # Create the column with missing values\n",
    "\n",
    "            # Ensure the new columns are placed after the existing columns\n",
    "            existing_columns = existing_df.columns.tolist()\n",
    "            new_columns = [column for column in columns_to_append if column not in existing_columns]\n",
    "            existing_df = existing_df[existing_columns + new_columns]\n",
    "\n",
    "            # Update the row with the new data from last_row\n",
    "            for column, value in last_row.items():\n",
    "                existing_df.at[row_index[0], column] = value\n",
    "\n",
    "            # Save the updated DataFrame back to the CSV\n",
    "            existing_df.to_csv(filename, index=False)\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "    \n",
    "    def extract_keeper_table(self, team_type, header_offset):\n",
    "        \"\"\"\n",
    "        Extracts a specific keeper statistics table for the given team.\n",
    "        - team_type: \"home\" or \"away\".\n",
    "        - header_offset: Number of header columns to skip.\n",
    "        \"\"\"\n",
    "        # Get the team ID based on the team type (home or away)\n",
    "        team_id = self.teams_data[team_type][\"id\"]\n",
    "\n",
    "        # Construct the CSS selector for the specific table\n",
    "        keeper_table_selector = f\"#keeper_stats_{team_id}\"\n",
    "\n",
    "        # Select the table element using the constructed selector\n",
    "        table = self.soup.select_one(keeper_table_selector)\n",
    "\n",
    "        # Check if the table exists\n",
    "        if not table:\n",
    "            raise Exception(f\"Keeper table not found for team {team_type}.\")\n",
    "\n",
    "        # Extract headers from the table, skipping the specified number of columns\n",
    "        headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")][header_offset:]\n",
    "\n",
    "        # Extract rows of data from the table body\n",
    "        rows = [\n",
    "            [cell.text.strip() for cell in row.find_all([\"td\", \"th\"])]\n",
    "            for row in table.find(\"tbody\").find_all(\"tr\")\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame from the extracted rows and headers\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        return df\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def process_keeper_data(self, team_type):\n",
    "        \"\"\"\n",
    "        Processes all keeper statistics tables for a specific team (home or away).\n",
    "        Combines data into a dictionary of DataFrames.\n",
    "        \"\"\"\n",
    "        # Extract data from the keeper statistics table\n",
    "        table = self.extract_keeper_table(\n",
    "                team_type, header_offset=7)\n",
    "\n",
    "        return table\n",
    "\n",
    "    def save_keeper_tables(self, match, season):\n",
    "        \"\"\"\n",
    "        Processes and saves keeper statistics table for both home and away teams.\n",
    "        Writes the final table to a CSV file.\n",
    "        \"\"\"\n",
    "        # Extract IDs and names of the teams\n",
    "        self.extract_teams_ids()\n",
    "\n",
    "        # Process data for both home and away teams\n",
    "        for team_type in [\"home\", \"away\"]:\n",
    "            # Get the team name\n",
    "            team_name = self.teams_data[team_type][\"name\"]\n",
    "\n",
    "            # Extract and process all keeper statistics tables for the team\n",
    "            final_table = self.process_keeper_data(team_type)\n",
    "\n",
    "            # Define the new column names for the dataset\n",
    "            new_columns = [\n",
    "                f\"{team_type}_KeepersKeepers\", f\"{team_type}_KeepersNationality\", f\"{team_type}_KeepersAge\", \n",
    "                f\"{team_type}_KeepersMinutes\", f\"{team_type}_KeepersShotsOnTargetAgainst\", \n",
    "                f\"{team_type}_KeepersGoalsAgainst\", f\"{team_type}_KeepersSaved\", \n",
    "                f\"{team_type}_Keepers%Saved\", f\"{team_type}_KeepersxG\", f\"{team_type}_KeepersPassesLaunched\", \n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\", f\"{team_type}_Keepers%CompletedPassesLaunched\", \n",
    "                f\"{team_type}_KeepersPasses\", f\"{team_type}_KeepersAttemptedPasses\", \n",
    "                f\"{team_type}_Keepers%CompletedPasses\", f\"{team_type}_KeepersPassesDistance\", \n",
    "                f\"{team_type}_KeepersAttemptedKicks\", f\"{team_type}_Keepers%Kicks\", \n",
    "                f\"{team_type}_KeepersKicksDistance\", f\"{team_type}_KeepersCrosses\", \n",
    "                f\"{team_type}_KeepersCrossesStopped\", f\"{team_type}_Keepers%CrossesStopped\", \n",
    "                f\"{team_type}_KeepersActionsOutsideArea\", f\"{team_type}_KeepersDistanceActionsArea\"\n",
    "            ]\n",
    "\n",
    "            # Rename the columns of the DataFrame\n",
    "            final_table.columns = new_columns\n",
    "\n",
    "            # Convert the 'Age' column to integer by extracting the first two characters\n",
    "            final_table[f'{team_type}_KeepersAge'] = final_table[f'{team_type}_KeepersAge'].apply(\n",
    "                lambda x: int(x[:2]) if isinstance(x, str) else 0\n",
    "            )\n",
    "\n",
    "            # Define columns to calculate the mean\n",
    "            columns_to_mean = [\n",
    "                f\"{team_type}_KeepersAge\", f\"{team_type}_Keepers%Saved\", \n",
    "                f\"{team_type}_Keepers%CompletedPassesLaunched\", f\"{team_type}_Keepers%CompletedPasses\", \n",
    "                f\"{team_type}_KeepersPassesDistance\", f\"{team_type}_Keepers%Kicks\", \n",
    "                f\"{team_type}_KeepersKicksDistance\", f\"{team_type}_Keepers%CrossesStopped\", \n",
    "                f\"{team_type}_KeepersDistanceActionsArea\"\n",
    "            ]\n",
    "\n",
    "            # Define columns to calculate the sum\n",
    "            columns_to_sum = [\n",
    "                f\"{team_type}_KeepersKeepers\", f\"{team_type}_KeepersMinutes\", \n",
    "                f\"{team_type}_KeepersShotsOnTargetAgainst\", f\"{team_type}_KeepersGoalsAgainst\", \n",
    "                f\"{team_type}_KeepersSaved\", f\"{team_type}_KeepersxG\", f\"{team_type}_KeepersPassesLaunched\", \n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\", f\"{team_type}_KeepersPasses\", \n",
    "                f\"{team_type}_KeepersAttemptedPasses\", f\"{team_type}_KeepersAttemptedKicks\", \n",
    "                f\"{team_type}_KeepersCrosses\", f\"{team_type}_KeepersCrossesStopped\", \n",
    "                f\"{team_type}_KeepersActionsOutsideArea\"\n",
    "            ]\n",
    "\n",
    "            # Convert the mean columns to numeric\n",
    "            for col in columns_to_mean:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Convert the sum columns to numeric\n",
    "            for col in columns_to_sum:\n",
    "                final_table[col] = final_table[col].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Calculate the mean and sum for specified columns\n",
    "            mean_values = final_table[columns_to_mean].mean()\n",
    "            sum_values = final_table[columns_to_sum].sum()\n",
    "\n",
    "            # Create a new row for totals with placeholder values\n",
    "            total_row = {col: '-' for col in final_table.columns}\n",
    "\n",
    "            # Populate the total row with mean values\n",
    "            for col, mean in mean_values.items():\n",
    "                total_row[col] = mean\n",
    "\n",
    "            # Populate the total row with sum values\n",
    "            for col, total in sum_values.items():\n",
    "                total_row[col] = total\n",
    "\n",
    "            # Add the number of rows (lines) to the first column of the total row\n",
    "            num_lines = len(final_table)\n",
    "            total_row[final_table.columns[0]] = num_lines\n",
    "\n",
    "            # Check if the 'id' column exists, if not, create it with NaN values\n",
    "            if 'id' not in final_table.columns:\n",
    "                final_table['id'] = np.nan  # Create the column with NaN values\n",
    "\n",
    "            # Add the match ID to the total row\n",
    "            total_row['id'] = match\n",
    "\n",
    "            # Append the total row to the DataFrame\n",
    "            final_table.loc[len(final_table)] = total_row\n",
    "\n",
    "            # Save the combined table to a CSV file\n",
    "            #output_filename = f\"{self.gameweek}_{match}_{team_name}_{team_type}_keeper_table.csv\"\n",
    "            #final_table.to_csv(output_filename, index=False)\n",
    "\n",
    "            # Define the columns to append to the existing CSV\n",
    "            columns_to_append = [\n",
    "                f\"{team_type}_KeepersKeepers\", f\"{team_type}_KeepersMinutes\",\n",
    "                f\"{team_type}_KeepersShotsOnTargetAgainst\", f\"{team_type}_KeepersGoalsAgainst\", f\"{team_type}_KeepersSaved\", \n",
    "                f\"{team_type}_Keepers%Saved\", f\"{team_type}_KeepersxG\", f\"{team_type}_KeepersPassesLaunched\", \n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\", f\"{team_type}_Keepers%CompletedPassesLaunched\", \n",
    "                f\"{team_type}_KeepersPasses\", f\"{team_type}_KeepersAttemptedPasses\", f\"{team_type}_Keepers%CompletedPasses\", \n",
    "                f\"{team_type}_KeepersPassesDistance\", f\"{team_type}_KeepersAttemptedKicks\", f\"{team_type}_Keepers%Kicks\", \n",
    "                f\"{team_type}_KeepersKicksDistance\", f\"{team_type}_KeepersCrosses\", f\"{team_type}_KeepersCrossesStopped\", \n",
    "                f\"{team_type}_Keepers%CrossesStopped\", f\"{team_type}_KeepersActionsOutsideArea\", f\"{team_type}_KeepersDistanceActionsArea\"\n",
    "            ]\n",
    "\n",
    "            # Extract the last row from final_table (this contains the sums and means)\n",
    "            last_row = final_table.iloc[-1][columns_to_append]\n",
    "\n",
    "            #Define the filename for the current season\n",
    "            filename = f\"matches_{season}.csv\"\n",
    "\n",
    "            # Load the existing CSV file from the parent directory\n",
    "            existing_df = pd.read_csv(filename)\n",
    "\n",
    "            # Get the ID from the last row of final_table\n",
    "            last_row_id = final_table.iloc[-1]['id']\n",
    "\n",
    "            # Find the row in the existing CSV based on the ID\n",
    "            row_index = existing_df[existing_df['id'] == last_row_id].index\n",
    "\n",
    "            # Check if the row exists\n",
    "            if row_index.empty:\n",
    "                raise ValueError(f\"Error: No row with ID {last_row_id} found in {filename}\")\n",
    "\n",
    "            # Check if the columns exist in the existing CSV, if not, create them after the existing columns\n",
    "            for column in columns_to_append:\n",
    "                if column not in existing_df.columns:\n",
    "                    existing_df[column] = pd.NA  # Create the column with missing values\n",
    "\n",
    "            # Ensure the new columns are placed after the existing columns\n",
    "            existing_columns = existing_df.columns.tolist()\n",
    "            new_columns = [column for column in columns_to_append if column not in existing_columns]\n",
    "            existing_df = existing_df[existing_columns + new_columns]\n",
    "\n",
    "            # Update the row with the new data from last_row\n",
    "            for column, value in last_row.items():\n",
    "                existing_df.at[row_index[0], column] = value\n",
    "\n",
    "            # Save the updated DataFrame back to the CSV\n",
    "            existing_df.to_csv(filename, index=False)\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "    def run(self, url, links_file, gameweeks_file):\n",
    "        \"\"\"\n",
    "        Processes multiple gameweek URLs by reading from a file of links and gameweeks.\n",
    "        For each URL, extracts and saves player and keeper statistics tables.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting players data...\")\n",
    "\n",
    "        #Extract the season from the URL\n",
    "        season_match = re.search(r'(\\d{4})-(\\d{4})', url)\n",
    "        if season_match:\n",
    "            season = season_match.group(0)\n",
    "        else:\n",
    "            season = 'unknown_season'  # Default value if the season cannot be extracted\n",
    "            \n",
    "        # Read the links and gameweeks from CSV files\n",
    "        links_df = pd.read_csv(links_file)\n",
    "        gameweeks_df = pd.read_csv(gameweeks_file)\n",
    "\n",
    "        # Initialize match as an integer\n",
    "        match = 1  # Start match numbering from 100\n",
    "\n",
    "        # Loop through each link and its corresponding gameweek starting from index 99 (100th link)\n",
    "        for index in range(0, len(links_df)):  # Adjust starting index to 99 (Python indexing starts at 0)\n",
    "            link = links_df.iloc[index]['link']\n",
    "            gameweek = gameweeks_df.iloc[index]['gameweek']\n",
    "\n",
    "            print(f\"Processing link {index + 1}: {link}\")\n",
    "\n",
    "            # Create an extractor for the current URL and gameweek\n",
    "            extractor = Players_data(link, gameweek)\n",
    "\n",
    "            # Save the extracted players tables for the current URL\n",
    "            extractor.save_players_tables(match, season)\n",
    "\n",
    "            # Save the extracted keepers tables for the current URL\n",
    "            extractor.save_keeper_tables(match, season)\n",
    "\n",
    "            # Increment the match counter\n",
    "            match += 1\n",
    "\n",
    "            time.sleep(6)\n",
    "\n",
    "        print(f\"Collecting players data process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining time data from the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match_events:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the extractor with the URL of the match page.\n",
    "        This sets up the URL, initializes placeholders for parsed HTML content,\n",
    "        and lists to store events for both teams.\n",
    "        \"\"\"\n",
    "        self.url = url  # URL of the match page\n",
    "        self.soup = None  # Placeholder for the parsed HTML content\n",
    "        self.events_team_a = []  # List to store events for Team A\n",
    "        self.events_team_b = []  # List to store events for Team B\n",
    "\n",
    "    def fetch_html(self):\n",
    "        \"\"\"\n",
    "        Fetch the HTML content from the given URL.\n",
    "        This method makes an HTTP GET request to the URL and parses the HTML if the request is successful.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\"  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            self.soup = BeautifulSoup(response.text, 'html.parser')  # Parse the HTML content\n",
    "        else:\n",
    "            raise Exception(f\"Failed to fetch HTML content. Status code: {response.status_code}\")\n",
    "\n",
    "    def parse_events(self):\n",
    "        \"\"\"\n",
    "        Extract match events from the HTML content for both teams.\n",
    "        This method locates the event container in the HTML and extracts relevant data for both teams.\n",
    "        \"\"\"\n",
    "        # Ensure that the HTML content has been loaded\n",
    "        if not self.soup:\n",
    "            raise Exception(\"HTML content not loaded. Call 'fetch_html()' first.\")\n",
    "        \n",
    "        # Locate the main container that holds all the events\n",
    "        events_wrap = self.soup.find('div', id='events_wrap')\n",
    "        if not events_wrap:\n",
    "            raise Exception(\"Event container not found in the HTML.\")\n",
    "\n",
    "        # Parse events for Team A\n",
    "        for event in events_wrap.find_all('div', class_='event a'):  # Look for events with class 'event a'\n",
    "            minute = event.find('small').text.strip() if event.find('small') else None  # Get the minute of the event\n",
    "            event_icon = event.find('div', class_='event_icon')\n",
    "            event_type = event_icon['class'][1] if event_icon else None  # Get the type of event (e.g., goal, yellow card)\n",
    "            player_tag = event.find('a')\n",
    "            player = player_tag.text.strip() if player_tag else None  # Get the player involved in the event\n",
    "            team_logo = event.find('img', class_='teamlogo')\n",
    "            team = team_logo['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\") if team_logo else None  # Get the team name\n",
    "\n",
    "            # Append the extracted details to the Team A events list\n",
    "            self.events_team_a.append({\n",
    "                'Minute': minute,\n",
    "                'EventType': event_type,\n",
    "                'Player': player,\n",
    "                'Team': team\n",
    "            })\n",
    "\n",
    "        # Parse events for Team B\n",
    "        for event in events_wrap.find_all('div', class_='event b'):  # Look for events with class 'event b'\n",
    "            minute = event.find('small').text.strip() if event.find('small') else None  # Get the minute of the event\n",
    "            event_icon = event.find('div', class_='event_icon')\n",
    "            event_type = event_icon['class'][1] if event_icon else None  # Get the type of event (e.g., goal, yellow card)\n",
    "            player_tag = event.find('a')\n",
    "            player = player_tag.text.strip() if player_tag else None  # Get the player involved in the event\n",
    "            team_logo = event.find('img', class_='teamlogo')\n",
    "            team = team_logo['alt'].replace(\" Club Crest\", \"\").replace(\" \", \"_\") if team_logo else None  # Get the team name\n",
    "\n",
    "            # Append the extracted details to the Team B events list\n",
    "            self.events_team_b.append({\n",
    "                'Minute': minute,\n",
    "                'EventType': event_type,\n",
    "                'Player': player,\n",
    "                'Team': team\n",
    "            })\n",
    "\n",
    "    def save_to_csv(self, match, gameweek):\n",
    "        \"\"\"\n",
    "        Save the extracted events for both Team A and Team B to separate CSV files.\n",
    "        This method ensures that events are saved only after they have been parsed.\n",
    "        \"\"\"\n",
    "        if not self.events_team_a:\n",
    "            raise Exception(\"No events for Team A to save. Make sure to call 'parse_events()' first.\")\n",
    "        if not self.events_team_b:\n",
    "            raise Exception(\"No events for Team B to save. Make sure to call 'parse_events()' first.\")\n",
    "        \n",
    "        # Convert the events for Team A and Team B to DataFrames\n",
    "        events_team_a_df = pd.DataFrame(self.events_team_a)\n",
    "        events_team_b_df = pd.DataFrame(self.events_team_b)\n",
    "\n",
    "        # Get the team names for the output filenames\n",
    "        team_name_a = self.events_team_a[0]['Team']\n",
    "        team_name_b = self.events_team_b[0]['Team']\n",
    "\n",
    "        # Define output filenames for the CSV files\n",
    "        output_filename_a = f\"{gameweek}_{match}_{team_name_a}_events.csv\"\n",
    "        output_filename_b = f\"{gameweek}_{match}_{team_name_b}_events.csv\"\n",
    "        \n",
    "        # Save the extracted events to CSV files for both teams\n",
    "        events_team_a_df.to_csv(output_filename_a, index=False)\n",
    "        events_team_b_df.to_csv(output_filename_b, index=False)\n",
    "\n",
    "    def run(self, links_file, gameweeks_file):\n",
    "        \"\"\"\n",
    "        Execute the full process: fetch HTML, parse events, and save to CSV files for both teams.\n",
    "        This method orchestrates the entire extraction process by reading the necessary input files,\n",
    "        fetching the HTML content, parsing events, and saving the results to CSV files.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting events data...\")\n",
    "\n",
    "        # Read the links and gameweeks from CSV files\n",
    "        links_df = pd.read_csv(links_file)\n",
    "        gameweeks_df = pd.read_csv(gameweeks_file)\n",
    "\n",
    "        # Initialize match as an integer\n",
    "        match = 1\n",
    "\n",
    "        # Loop through each link and its corresponding gameweek\n",
    "        for index, link in enumerate(links_df['link']):\n",
    "            gameweek = gameweeks_df.iloc[index]['gameweek']\n",
    "\n",
    "            print(f\"Processing link {index + 1}: {link}\")\n",
    "\n",
    "            # Create an extractor for the current URL and gameweek\n",
    "            extractor = Match_events(link)\n",
    "\n",
    "            # Fetch the HTML content for the match page\n",
    "            extractor.fetch_html()\n",
    "\n",
    "            # Parse the events for both teams\n",
    "            extractor.parse_events()\n",
    "\n",
    "            # Save the extracted events to CSV files for both teams\n",
    "            extractor.save_to_csv(match, gameweek)\n",
    "\n",
    "            # Increment the match counter\n",
    "            match += 1\n",
    "\n",
    "            time.sleep(6)\n",
    "\n",
    "        print(f\"Collecting events data process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_process():\n",
    "    \"\"\"\n",
    "    Runs the full data extraction process for a given league URL. \n",
    "    It involves extracting match data, player statistics, and match events.\n",
    "    \"\"\"\n",
    "    # Define the league URL (La Liga for the 2023-2024 season)\n",
    "    league_url = 'https://fbref.com/es/comps/12/2023-2024/horario/Marcadores-y-partidos-de-2023-2024-La-Liga'\n",
    "    \n",
    "    # First class: Extract match data from the league URL\n",
    "    # Create an instance of Match_data and run the extraction process\n",
    "    Match_data_extractor = Match_data(league_url)\n",
    "    Match_data_extractor.run(league_url)\n",
    "    \n",
    "    # Second class: Extract player data for each match\n",
    "    # Extract the season from the URL using a regular expression\n",
    "    season_match = re.search(r'(\\d{4})-(\\d{4})', league_url)\n",
    "    if season_match:\n",
    "        season = season_match.group(0)  # Get the season\n",
    "    else:\n",
    "        season = 'unknown_season'  # Default value if the season cannot be extracted\n",
    "\n",
    "    #Define the filename for the current season\n",
    "    filename = f\"matches_{season}.csv\"\n",
    "\n",
    "    # Load the existing CSV file from the parent directory\n",
    "    data = pd.read_csv(filename)\n",
    "    \n",
    "    # Define file paths for temporary CSV files containing links and gameweeks\n",
    "    links_file = 'links_temp.csv'\n",
    "    gameweeks_file = 'gameweeks_temp.csv'\n",
    "\n",
    "    # Save only the 'link' column from the match data to the links file\n",
    "    data[['link']].to_csv(links_file, index=False)\n",
    "    \n",
    "    # Save only the 'gameweek' column from the match data to the gameweeks file\n",
    "    data[['gameweek']].to_csv(gameweeks_file, index=False)\n",
    "\n",
    "    # Call the function to extract player data using the links and gameweeks files\n",
    "    Players_data_extractor = Players_data(league_url, None)\n",
    "    Players_data_extractor.run(league_url, links_file, gameweeks_file)\n",
    "    \n",
    "    # Third class: Extract match events data\n",
    "    # Create an instance of Match_events and run the extraction process\n",
    "    Match_events_extractor = Match_events(league_url)\n",
    "    Match_events_extractor.run(links_file, filename)\n",
    "\n",
    "    # Clean up by removing the temporary CSV files after the process is complete\n",
    "    os.remove(links_file)\n",
    "    os.remove(gameweeks_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting collecting players data...\n",
      "Processing link 351: https://fbref.com/es/partidos/e3feee7a/Osasuna-Mallorca-Mayo-14-2024-La-Liga\n",
      "Collecting players data process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "run_full_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to see web situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta recibida: 504\n"
     ]
    }
   ],
   "source": [
    "'''# URL que estás intentando acceder\n",
    "url = \"https://fbref.com/es/partidos/33737218/Almeria-Real-Madrid-Agosto-19-2023-La-Liga\"\n",
    "\n",
    "# Número máximo de intentos\n",
    "max_retries = 5\n",
    "\n",
    "# Tiempo de espera entre intentos (en segundos)\n",
    "wait_time = 10\n",
    "\n",
    "# Intentar acceder a la página\n",
    "for attempt in range(max_retries):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Si la respuesta es 403, esperar antes de reintentar\n",
    "    if response.status_code == 403:\n",
    "        print(f\"Acceso prohibido. Esperando {wait_time} segundos antes de reintentar...\")\n",
    "        time.sleep(wait_time)\n",
    "    else:\n",
    "        print(f\"Respuesta recibida: {response.status_code}\")\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to input data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated row with id 351 in columns ['home_Players', 'home_PlayersAge', 'home_PlayersMinutes', 'home_PlayersGoals', 'home_PlayersShots', 'home_PlayersShotsOnTarget', 'home_PlayersCompletedPasses', 'home_PlayersAttemptedPasses', 'home_Players%CompletedPasses', 'home_PlayersDistancePasses', 'home_PlayersDistanceProgression', 'home_PlayersShortPasses', 'home_PlayersAttemptedShortPasses', 'home_Players%ShortCompletedPasses', 'home_PlayersMediumPasses', 'home_PlayersAttemptedMediumPasses', 'home_Players%MediumCompletedPasses', 'home_PlayersLongPasses', 'home_PlayersAttemptedLongPasses', 'home_Players%LongCompletedPasses', 'home_PlayersAssistance', 'home_PlayersExpectedGoalsAssistance', 'home_PlayersExpectedAssistance', 'home_PlayersKeyPasses', 'home_PlayersLast1/3Passes', 'home_PlayersGoalAreaPasses', 'home_PlayersGoalAreaCrosses', 'home_PlayersGoalPasses', 'home_PlayersLiveBallPasses', 'home_PlayersDeadBallPasses', 'home_PlayersFreeKick', 'home_PlayersSidePasses', 'home_PlayersCrosses', 'home_PlayersStrongcrosses', 'home_PlayersCorner', 'home_PlayersCornerIn', 'home_PlayersCornerOut', 'home_PlayersCornerRect', 'home_PlayersOffsidePasses', 'home_PlayersPassesBlocked', 'home_PlayersTackles', 'home_PlayersSuccessfulTackles', 'home_PlayersTacklesInDefense', 'home_PlayersTacklesInMedium', 'home_PlayersTacklesInAttack', 'home_PlayersDribblerTackles', 'home_PlayersAttemptedDribblerTackles', 'home_Players%DribblerTacklesCompleted', 'home_PlayersDribblerTacklesNonCompleted', 'home_PlayersBallsBlocked', 'home_PlayersShotsBlocked', 'home_PlayersInterceptions', 'home_PlayersTackles+Interceptions', 'home_PlayersClearances', 'home_PlayersMistakesRivalShots', 'home_PlayersTouches', 'home_PlayersOwnPenaltyAreaTouches', 'home_PlayersTouchesInDefense', 'home_PlayersTouchesInMedium', 'home_PlayersTouchesInAttack', 'home_PlayersAwayPenaltyAreaTouches', 'home_PlayersLiveBallTouches', 'home_PlayersAttemptedDribbles', 'home_PlayersDribblesCompleted', 'home_Players%DribblesCompleted', 'home_PlayersBallCarries', 'home_PlayersDistanceCarried', 'home_PlayersForwardDistanceCarried', 'home_PlayersForwardCarries', 'home_PlayersCarriesInAttack', 'home_PlayersAwayPenaltyAreaCarries', 'home_PlayersLostControlCarries', 'home_PlayersLostCarries', 'home_PlayersPassesReception', 'home_PlayersAttackPassesReception', 'home_PlayersYellowCards', 'home_PlayersRedCards', 'home_PlayersSecondYellowCards', 'home_PlayersFouls', 'home_PlayersOffside', 'home_PlayersPenalties', 'home_PlayersPenaltiesConceded', 'home_PlayersLostBallRecoveries', 'home_PlayersAerialsWon', 'home_PlayersAerialsLost', 'home_Players%AerialsWon', 'away_Players', 'away_PlayersAge', 'away_PlayersMinutes', 'away_PlayersGoals', 'away_PlayersShots', 'away_PlayersShotsOnTarget', 'away_PlayersCompletedPasses', 'away_PlayersAttemptedPasses', 'away_Players%CompletedPasses', 'away_PlayersDistancePasses', 'away_PlayersDistanceProgression', 'away_PlayersShortPasses', 'away_PlayersAttemptedShortPasses', 'away_Players%ShortCompletedPasses', 'away_PlayersMediumPasses', 'away_PlayersAttemptedMediumPasses', 'away_Players%MediumCompletedPasses', 'away_PlayersLongPasses', 'away_PlayersAttemptedLongPasses', 'away_Players%LongCompletedPasses', 'away_PlayersAssistance', 'away_PlayersExpectedGoalsAssistance', 'away_PlayersExpectedAssistance', 'away_PlayersKeyPasses', 'away_PlayersLast1/3Passes', 'away_PlayersGoalAreaPasses', 'away_PlayersGoalAreaCrosses', 'away_PlayersGoalPasses', 'away_PlayersLiveBallPasses', 'away_PlayersDeadBallPasses', 'away_PlayersFreeKick', 'away_PlayersSidePasses', 'away_PlayersCrosses', 'away_PlayersStrongcrosses', 'away_PlayersCorner', 'away_PlayersCornerIn', 'away_PlayersCornerOut', 'away_PlayersCornerRect', 'away_PlayersOffsidePasses', 'away_PlayersPassesBlocked', 'away_PlayersTackles', 'away_PlayersSuccessfulTackles', 'away_PlayersTacklesInDefense', 'away_PlayersTacklesInMedium', 'away_PlayersTacklesInAttack', 'away_PlayersDribblerTackles', 'away_PlayersAttemptedDribblerTackles', 'away_Players%DribblerTacklesCompleted', 'away_PlayersDribblerTacklesNonCompleted', 'away_PlayersBallsBlocked', 'away_PlayersShotsBlocked', 'away_PlayersInterceptions', 'away_PlayersTackles+Interceptions', 'away_PlayersClearances', 'away_PlayersMistakesRivalShots', 'away_PlayersTouches', 'away_PlayersOwnPenaltyAreaTouches', 'away_PlayersTouchesInDefense', 'away_PlayersTouchesInMedium', 'away_PlayersTouchesInAttack', 'away_PlayersAwayPenaltyAreaTouches', 'away_PlayersLiveBallTouches', 'away_PlayersAttemptedDribbles', 'away_PlayersDribblesCompleted', 'away_Players%DribblesCompleted', 'away_PlayersBallCarries', 'away_PlayersDistanceCarried', 'away_PlayersForwardDistanceCarried', 'away_PlayersForwardCarries', 'away_PlayersCarriesInAttack', 'away_PlayersAwayPenaltyAreaCarries', 'away_PlayersLostControlCarries', 'away_PlayersLostCarries', 'away_PlayersPassesReception', 'away_PlayersAttackPassesReception', 'away_PlayersYellowCards', 'away_PlayersRedCards', 'away_PlayersSecondYellowCards', 'away_PlayersFouls', 'away_PlayersOffside', 'away_PlayersPenalties', 'away_PlayersPenaltiesConceded', 'away_PlayersLostBallRecoveries', 'away_PlayersAerialsWon', 'away_PlayersAerialsLost', 'away_Players%AerialsWon'] with values ['16.0', '27.188', '990.0', '1.0', '10.0', '4.0', '371.0', '506.0', '73.3', '6341.0', '2310.0', '187.0', '217.0', '86.2', '141.0', '181.0', '77.9', '36.0', '80.0', '45.0', '0.0', '0.2', '0.5', '4.0', '24.0', '6.0', '1.0', '27.0', '445.0', '60.0', '13.0', '5.0', '14.0', '37.0', '2.0', '1.0', '0.0', '0.0', '1.0', '6.0', '16.0', '9.0', '9.0', '4.0', '3.0', '7.0', '11.0', '63.6', '4.0', '8.0', '2.0', '6.0', '24.0', '16.0', '0.0', '606.0', '41.0', '149.0', '301.0', '158.0', '18.0', '606.0', '10.0', '4.0', '40.0', '369.0', '1829.0', '683.0', '14.0', '13.0', '2.0', '13.0', '14.0', '362.0', '27.0', '0.0', '0.0', '0.0', '12.0', '9.0', '0.0', '0.0', '46.0', '22.0', '17.0', '56.4', '16.0', '29.125', '990.0', '1.0', '10.0', '4.0', '337.0', '458.0', '73.6', '5876.0', '2229.0', '163.0', '189.0', '86.2', '137.0', '166.0', '82.5', '30.0', '83.0', '36.1', '0.0', '0.3', '0.3', '5.0', '18.0', '6.0', '3.0', '33.0', '405.0', '50.0', '12.0', '1.0', '16.0', '25.0', '4.0', '2.0', '2.0', '0.0', '3.0', '6.0', '19.0', '11.0', '9.0', '9.0', '1.0', '5.0', '9.0', '55.6', '4.0', '6.0', '1.0', '5.0', '28.0', '39.0', '0.0', '584.0', '87.0', '234.0', '254.0', '97.0', '16.0', '584.0', '12.0', '4.0', '33.33', '314.0', '1666.0', '650.0', '8.0', '10.0', '0.0', '16.0', '9.0', '337.0', '13.0', '1.0', '0.0', '0.0', '11.0', '11.0', '0.0', '0.0', '42.0', '17.0', '22.0', '43.6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.188' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '990.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '371.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '506.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '73.3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6341.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2310.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '187.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '217.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '86.2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '141.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '181.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '77.9' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '36.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '80.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '45.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '24.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '445.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '60.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '14.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '37.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '7.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '63.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '8.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '24.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '606.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '41.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '149.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '301.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '158.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '18.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '606.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '40.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '369.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1829.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '683.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '14.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '14.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '362.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '27.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '12.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '46.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '22.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '17.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '56.4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '29.125' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '990.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '337.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '458.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '73.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5876.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2229.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '163.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '189.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '86.2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '137.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '166.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '82.5' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '30.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '83.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '36.1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '18.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '33.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '405.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '50.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '12.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '25.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '19.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '55.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '28.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '39.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '584.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '87.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '234.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '254.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '97.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '584.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '12.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '33.33' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '314.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1666.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '650.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '8.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '16.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '9.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '337.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '42.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '17.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '22.0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n",
      "C:\\Users\\julio\\AppData\\Local\\Temp\\ipykernel_268\\297697393.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '43.6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, col] = new_val\n"
     ]
    }
   ],
   "source": [
    "'''# Leer el archivo CSV\n",
    "df = pd.read_csv('matches_2023-2024.csv')\n",
    "\n",
    "# Especifica el valor de la columna 'id' que quieres buscar\n",
    "target_id = 351\n",
    "\n",
    "# Encuentra la fila correspondiente al valor de 'id'\n",
    "row_index = df[df['id'] == target_id].index\n",
    "\n",
    "if not row_index.empty:\n",
    "    # Toma el índice de la fila encontrada\n",
    "    row_index = row_index[0]\n",
    "\n",
    "    # Especifica las columnas que quieres modificar y los nuevos valores\n",
    "    columns_to_modify = [\n",
    "        'home_Players', 'home_PlayersAge', 'home_PlayersMinutes', 'home_PlayersGoals', 'home_PlayersShots', \n",
    "        'home_PlayersShotsOnTarget', 'home_PlayersCompletedPasses', 'home_PlayersAttemptedPasses', \n",
    "        'home_Players%CompletedPasses', 'home_PlayersDistancePasses', 'home_PlayersDistanceProgression', \n",
    "        'home_PlayersShortPasses', 'home_PlayersAttemptedShortPasses', 'home_Players%ShortCompletedPasses', \n",
    "        'home_PlayersMediumPasses', 'home_PlayersAttemptedMediumPasses', 'home_Players%MediumCompletedPasses', \n",
    "        'home_PlayersLongPasses', 'home_PlayersAttemptedLongPasses', 'home_Players%LongCompletedPasses', \n",
    "        'home_PlayersAssistance', 'home_PlayersExpectedGoalsAssistance', 'home_PlayersExpectedAssistance', \n",
    "        'home_PlayersKeyPasses', 'home_PlayersLast1/3Passes', 'home_PlayersGoalAreaPasses', 'home_PlayersGoalAreaCrosses', \n",
    "        'home_PlayersGoalPasses', 'home_PlayersLiveBallPasses', 'home_PlayersDeadBallPasses', 'home_PlayersFreeKick', \n",
    "        'home_PlayersSidePasses', 'home_PlayersCrosses', 'home_PlayersStrongcrosses', 'home_PlayersCorner', \n",
    "        'home_PlayersCornerIn', 'home_PlayersCornerOut', 'home_PlayersCornerRect', 'home_PlayersOffsidePasses', \n",
    "        'home_PlayersPassesBlocked', 'home_PlayersTackles', 'home_PlayersSuccessfulTackles', 'home_PlayersTacklesInDefense', \n",
    "        'home_PlayersTacklesInMedium', 'home_PlayersTacklesInAttack', 'home_PlayersDribblerTackles', \n",
    "        'home_PlayersAttemptedDribblerTackles', 'home_Players%DribblerTacklesCompleted', 'home_PlayersDribblerTacklesNonCompleted', \n",
    "        'home_PlayersBallsBlocked', 'home_PlayersShotsBlocked', 'home_PlayersInterceptions', 'home_PlayersTackles+Interceptions', \n",
    "        'home_PlayersClearances', 'home_PlayersMistakesRivalShots', 'home_PlayersTouches', 'home_PlayersOwnPenaltyAreaTouches', \n",
    "        'home_PlayersTouchesInDefense', 'home_PlayersTouchesInMedium', 'home_PlayersTouchesInAttack', \n",
    "        'home_PlayersAwayPenaltyAreaTouches', 'home_PlayersLiveBallTouches', 'home_PlayersAttemptedDribbles', \n",
    "        'home_PlayersDribblesCompleted', 'home_Players%DribblesCompleted', 'home_PlayersBallCarries', \n",
    "        'home_PlayersDistanceCarried', 'home_PlayersForwardDistanceCarried', 'home_PlayersForwardCarries', \n",
    "        'home_PlayersCarriesInAttack', 'home_PlayersAwayPenaltyAreaCarries', 'home_PlayersLostControlCarries', \n",
    "        'home_PlayersLostCarries', 'home_PlayersPassesReception', 'home_PlayersAttackPassesReception', \n",
    "        'home_PlayersYellowCards', 'home_PlayersRedCards', 'home_PlayersSecondYellowCards', 'home_PlayersFouls', \n",
    "        'home_PlayersOffside', 'home_PlayersPenalties', 'home_PlayersPenaltiesConceded', 'home_PlayersLostBallRecoveries', \n",
    "        'home_PlayersAerialsWon', 'home_PlayersAerialsLost', 'home_Players%AerialsWon', 'away_Players', 'away_PlayersAge', \n",
    "        'away_PlayersMinutes', 'away_PlayersGoals', 'away_PlayersShots', 'away_PlayersShotsOnTarget', \n",
    "        'away_PlayersCompletedPasses', 'away_PlayersAttemptedPasses', 'away_Players%CompletedPasses', \n",
    "        'away_PlayersDistancePasses', 'away_PlayersDistanceProgression', 'away_PlayersShortPasses', \n",
    "        'away_PlayersAttemptedShortPasses', 'away_Players%ShortCompletedPasses', 'away_PlayersMediumPasses', \n",
    "        'away_PlayersAttemptedMediumPasses', 'away_Players%MediumCompletedPasses', 'away_PlayersLongPasses', \n",
    "        'away_PlayersAttemptedLongPasses', 'away_Players%LongCompletedPasses', 'away_PlayersAssistance', \n",
    "        'away_PlayersExpectedGoalsAssistance', 'away_PlayersExpectedAssistance', 'away_PlayersKeyPasses', \n",
    "        'away_PlayersLast1/3Passes', 'away_PlayersGoalAreaPasses', 'away_PlayersGoalAreaCrosses', 'away_PlayersGoalPasses', \n",
    "        'away_PlayersLiveBallPasses', 'away_PlayersDeadBallPasses', 'away_PlayersFreeKick', 'away_PlayersSidePasses', \n",
    "        'away_PlayersCrosses', 'away_PlayersStrongcrosses', 'away_PlayersCorner', 'away_PlayersCornerIn', \n",
    "        'away_PlayersCornerOut', 'away_PlayersCornerRect', 'away_PlayersOffsidePasses', 'away_PlayersPassesBlocked', \n",
    "        'away_PlayersTackles', 'away_PlayersSuccessfulTackles', 'away_PlayersTacklesInDefense', 'away_PlayersTacklesInMedium', \n",
    "        'away_PlayersTacklesInAttack', 'away_PlayersDribblerTackles', 'away_PlayersAttemptedDribblerTackles', \n",
    "        'away_Players%DribblerTacklesCompleted', 'away_PlayersDribblerTacklesNonCompleted', 'away_PlayersBallsBlocked', \n",
    "        'away_PlayersShotsBlocked', 'away_PlayersInterceptions', 'away_PlayersTackles+Interceptions', 'away_PlayersClearances', \n",
    "        'away_PlayersMistakesRivalShots', 'away_PlayersTouches', 'away_PlayersOwnPenaltyAreaTouches', \n",
    "        'away_PlayersTouchesInDefense', 'away_PlayersTouchesInMedium', 'away_PlayersTouchesInAttack', \n",
    "        'away_PlayersAwayPenaltyAreaTouches', 'away_PlayersLiveBallTouches', 'away_PlayersAttemptedDribbles', \n",
    "        'away_PlayersDribblesCompleted', 'away_Players%DribblesCompleted', 'away_PlayersBallCarries', \n",
    "        'away_PlayersDistanceCarried', 'away_PlayersForwardDistanceCarried', 'away_PlayersForwardCarries', \n",
    "        'away_PlayersCarriesInAttack', 'away_PlayersAwayPenaltyAreaCarries', 'away_PlayersLostControlCarries', \n",
    "        'away_PlayersLostCarries', 'away_PlayersPassesReception', 'away_PlayersAttackPassesReception', 'away_PlayersYellowCards', \n",
    "        'away_PlayersRedCards', 'away_PlayersSecondYellowCards', 'away_PlayersFouls', 'away_PlayersOffside', 'away_PlayersPenalties', \n",
    "        'away_PlayersPenaltiesConceded', 'away_PlayersLostBallRecoveries', 'away_PlayersAerialsWon', 'away_PlayersAerialsLost', \n",
    "        'away_Players%AerialsWon'\n",
    "    ]\n",
    "\n",
    "    new_values = [\n",
    "        '16.0','27.188','990.0','1.0','10.0','4.0','371.0','506.0','73.3','6341.0','2310.0','187.0','217.0','86.2','141.0','181.0','77.9','36.0','80.0','45.0','0.0','0.2','0.5','4.0','24.0','6.0','1.0','27.0','445.0','60.0','13.0','5.0','14.0','37.0','2.0','1.0','0.0','0.0','1.0','6.0','16.0','9.0','9.0','4.0','3.0','7.0','11.0','63.6','4.0','8.0','2.0','6.0','24.0','16.0','0.0','606.0','41.0','149.0','301.0','158.0','18.0','606.0','10.0','4.0','40.0','369.0','1829.0','683.0','14.0','13.0','2.0','13.0','14.0','362.0','27.0','0.0','0.0','0.0','12.0','9.0','0.0','0.0','46.0','22.0','17.0','56.4',\n",
    "        '16.0','29.125','990.0','1.0','10.0','4.0','337.0','458.0','73.6','5876.0','2229.0','163.0','189.0','86.2','137.0','166.0','82.5','30.0','83.0','36.1','0.0','0.3','0.3','5.0','18.0','6.0','3.0','33.0','405.0','50.0','12.0','1.0','16.0','25.0','4.0','2.0','2.0','0.0','3.0','6.0','19.0','11.0','9.0','9.0','1.0','5.0','9.0','55.6','4.0','6.0','1.0','5.0','28.0','39.0','0.0','584.0','87.0','234.0','254.0','97.0','16.0','584.0','12.0','4.0','33.33','314.0','1666.0','650.0','8.0','10.0','0.0','16.0','9.0','337.0','13.0','1.0','0.0','0.0','11.0','11.0','0.0','0.0','42.0','17.0','22.0','43.6'\n",
    "\n",
    "    ]  # Nuevos valores\n",
    "\n",
    "    # Modificar los valores en la fila especificada\n",
    "    for col, new_val in zip(columns_to_modify, new_values):\n",
    "        df.at[row_index, col] = new_val\n",
    "\n",
    "    # Guardar los cambios en el archivo CSV\n",
    "    df.to_csv('matches_2023-2024.csv', index=False)\n",
    "\n",
    "    print(f\"Updated row with id {target_id} in columns {columns_to_modify} with values {new_values}\")\n",
    "else:\n",
    "    print(f\"No row found with id {target_id}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api-python-bet-project-c88tlEpI-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
