{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and evaluate Annolid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is modified from https://voxel51.com/docs/fiftyone/tutorials/evaluate_detections.html\n",
    "#!pip install fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "from torchvision.transforms import functional as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from annolid.inference.predict import Segmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory containing the source images\n",
    "data_path = \"/path/to/my_coco_dataset/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the COCO labels JSON file\n",
    "labels_path = \"/path/to/my_coco_dataset/valid/annotations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor = Segmentor(\"/path/to/my_coco_dataset\",\n",
    "        \"/path/to/model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    data_path=data_path,\n",
    "    labels_path=labels_path,\n",
    "    label_types=\"segmentations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample.ground_truth.detections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random subset of 100 samples to add predictions to\n",
    "predictions_view = dataset.take(100, seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class list\n",
    "classes = dataset.default_classes[1:]\n",
    "\n",
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(predictions_view):\n",
    "        # Load image\n",
    "        image = Image.open(sample.filepath)\n",
    "        _image = cv2.imread(sample.filepath)\n",
    "        image = func.to_tensor(image).to(device)\n",
    "        c, h, w = image.shape\n",
    "\n",
    "        # Perform inference\n",
    "        preds = segmentor.predictor(_image)\n",
    "        instances = preds[\"instances\"]\n",
    "        boxes = instances.pred_boxes.tensor.numpy()\n",
    "        boxes = boxes.tolist()\n",
    "        scores = instances.scores.tolist()\n",
    "        labels = instances.pred_classes.tolist()\n",
    "        has_mask = instances.has(\"pred_masks\")\n",
    "\n",
    "        if has_mask:\n",
    "            rles = [\n",
    "                mask_util.encode(\n",
    "                    np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n",
    "                for mask in instances.pred_masks\n",
    "            ]\n",
    "            for rle in rles:\n",
    "                rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
    "\n",
    "        # Convert detections to FiftyOne format\n",
    "        detections = []\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Convert to [top-left-x, top-left-y, width, height]\n",
    "            # in relative coordinates in [0, 1] x [0, 1]\n",
    "            x1, y1, x2, y2 = box\n",
    "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "\n",
    "            detections.append(\n",
    "                fo.Detection(\n",
    "                    label=classes[label],\n",
    "                    bounding_box=rel_box,\n",
    "                    confidence=score,\n",
    "                    masks=rles\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save predictions to dataset\n",
    "        sample[\"mask_rcnn\"] = fo.Detections(detections=detections)\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = predictions_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.15\n",
    "high_conf_view = predictions_view.filter_labels(\"mask_rcnn\", F(\"confidence\") > 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    \"mask_rcnn\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "classes_all = sorted(counts, key=counts.get, reverse=True)\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=[\"RightInteract\"])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = high_conf_view.sort_by(\"eval_fp\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.freeze()  # screenshot the active App for sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag all highly confident false positives as \"possibly-missing\"\n",
    "(\n",
    "    high_conf_view\n",
    "        .filter_labels(\"mask_rcnn\", F(\"eval\") == \"fp\")\n",
    "        .select_fields(\"mask_rcnn\")\n",
    "        .tag_labels(\"possibly-missing\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all labels with the `possibly-missing` tag in CVAT format\n",
    "(\n",
    "    dataset\n",
    "        .select_labels(tags=[\"possibly-missing\"])\n",
    "        .export(\"~/Downloads/possoible-missing-dataset\", fo.types.COCODetectionDataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metadata so we can reference image height/width in our view\n",
    "dataset.compute_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create an expression that will match objects whose bounding boxes have\n",
    "# area less than 32^2 pixels\n",
    "#\n",
    "# Bounding box format is [top-left-x, top-left-y, width, height]\n",
    "# with relative coordinates in [0, 1], so we multiply by image\n",
    "# dimensions to get pixel area\n",
    "#\n",
    "bbox_area = (\n",
    "    F(\"$metadata.width\") * F(\"bounding_box\")[2] *\n",
    "    F(\"$metadata.height\") * F(\"bounding_box\")[3]\n",
    ")\n",
    "small_boxes = bbox_area < 32 ** 2\n",
    "\n",
    "# Create a view that contains only small (and high confidence) predictions\n",
    "small_boxes_view = high_conf_view.filter_labels(\"mask_rcnn\", small_boxes)\n",
    "\n",
    "session.view = small_boxes_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view that contains only small GT and predicted boxes\n",
    "small_boxes_eval_view = (\n",
    "    high_conf_view\n",
    "    .filter_labels(\"ground_truth\", small_boxes)\n",
    "    .filter_labels(\"mask_rcnn\", small_boxes)\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "small_boxes_results = small_boxes_eval_view.evaluate_detections(\n",
    "    \"mask_rcnn\",\n",
    "    gt_field=\"ground_truth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the 10 most common small object classes\n",
    "small_counts = small_boxes_eval_view.count_values(\"ground_truth.detections.label\")\n",
    "classes_top10_small = sorted(small_counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 small object classes\n",
    "small_boxes_results.print_report(classes=classes_top10_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ceed': conda)",
   "language": "python",
   "name": "python37664bitceedcondad8db7ad605d4406b82b8fbc4f6abf972"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
