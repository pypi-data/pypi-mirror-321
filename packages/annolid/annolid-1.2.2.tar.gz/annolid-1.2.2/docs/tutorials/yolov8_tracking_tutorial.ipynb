{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/healthonrails/annolid/blob/main/docs/tutorials/yolov8_tracking_tutorial.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "# Annolid on YOLOv8\n",
        "This notebook show examples for how to upload a custom dataset, train a new model based on the dataset, and inference on provided videos.\n"
      ],
      "metadata": {
        "id": "yRdBY3VMA42Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIGuIpRFAo18"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taGCP-gCgqX8"
      },
      "source": [
        "!git clone --recurse-submodules https://github.com/healthonrails/yolov8_tracking.git  # clone repo\n",
        "%cd /content/yolov8_tracking\n",
        "%pip install pycocotools\n",
        "%pip install ultralytics\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "%pip install thop                  # install dependencies\n",
        "%pip install sentry_sdk\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from google.colab import files\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download FastSAM code and weights.\n",
        "https://github.com/CASIA-IVA-Lab/FastSAM"
      ],
      "metadata": {
        "id": "4kG6m57hUJ5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CASIA-IVA-Lab/FastSAM.git"
      ],
      "metadata": {
        "id": "-kEuhpplT-pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/spaces/An-619/FastSAM/resolve/main/checkpoints/FastSAM.pt"
      ],
      "metadata": {
        "id": "zz38tS88UHh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r FastSAM/requirements.txt\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "9zP9QKG5U6aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict your video on a pretrained segmentation model"
      ],
      "metadata": {
        "id": "Rkfm8h4V7706"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pycocotools import mask as mask_util"
      ],
      "metadata": {
        "id": "VqBgtg3R_MU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/R2202_02-10-2023_000100275.png')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
      ],
      "metadata": {
        "id": "9fmNnKIDUcfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_h = image.shape[0]\n",
        "original_w = image.shape[1]\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "ZiV8Oe4PUlVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python FastSAM/Inference.py  --model_path FastSAM.pt --img_path /content/R2202_02-10-2023_000100275.png --device 0"
      ],
      "metadata": {
        "id": "j7U9ruWCUv4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/yolov8_tracking/output/R2202_02-10-2023_000100275.png')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "5XSJ9_8pUyYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = '/content/birds_dance_bbc.mp4'  #@param predict on a video"
      ],
      "metadata": {
        "id": "z8M97iJyWz4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the video file\n",
        "video = cv2.VideoCapture(source)\n",
        "# Get the video width and height\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "print(f'Video width: {width}')\n",
        "print(f'Video height: {height}')\n",
        "\n",
        "# Release the video\n",
        "video.release()"
      ],
      "metadata": {
        "id": "hLPirA-kW6_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def numpy_mask_to_rle(np_mask):\n",
        "    np_mask = cv2.resize(np_mask, (width, height))\n",
        "    np_mask = (np_mask * 255).astype(np.uint8)\n",
        "    rle_encoding = mask_util.encode(np.asfortranarray(np_mask))\n",
        "    return rle_encoding"
      ],
      "metadata": {
        "id": "4FtPcQj1Hyxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.yolo.utils.ops import scale_boxes, scale_image\n",
        "# Load a model\n",
        "model_name = 'yolov8n-seg.pt' #@param ['YOLOv8l-seg','yolov8n-seg.pt','yolov8x-seg.pt',\"/content/yolov8_tracking/FastSAM.pt\"]\n",
        "model = YOLO(model_name)  # load an official model\n",
        "class_names = model.names # 80 coco class names\n",
        "# Predict with the model\n",
        "\n",
        "results = model(source, stream=True)  # generator of Results objects\n",
        "frame_number = 0\n",
        "tracking_id = 0\n",
        "tracking_results = []\n",
        "for r in results:\n",
        "    out_dict = {}\n",
        "    if r:\n",
        "      boxes = r.boxes.cpu().numpy()  # Boxes object for bbox outputs\n",
        "      masks = r.masks.cpu().numpy()  # Masks object for segmenation masks outputs\n",
        "      for i in range(boxes.shape[0]):\n",
        "        np_mask = masks.data[i,:,:]\n",
        "        bbox = boxes[i,:]\n",
        "        box = bbox.xyxy[0]\n",
        "        classes = bbox.cls\n",
        "        scores = bbox.conf\n",
        "        rles = numpy_mask_to_rle(np_mask)\n",
        "        out_dict['frame_number'] = frame_number\n",
        "        out_dict['x1'] = box[0]\n",
        "        out_dict['y1'] = box[1]\n",
        "        out_dict['x2'] = box[2]\n",
        "        out_dict['y2'] = box[3]\n",
        "        out_dict['instance_name'] = class_names[int(classes[0])]\n",
        "        out_dict['class_score'] = scores[0]\n",
        "        out_dict['segmentation'] = rles\n",
        "        out_dict['tracking_id'] = tracking_id\n",
        "        tracking_results.append(out_dict)\n",
        "        out_dict = {}\n",
        "    else:\n",
        "        out_dict['frame_number'] = frame_number\n",
        "        out_dict['x1'] = None\n",
        "        out_dict['y1'] = None\n",
        "        out_dict['x2'] = None\n",
        "        out_dict['y2'] = None\n",
        "        out_dict['instance_name'] = None\n",
        "        out_dict['class_score'] = None\n",
        "        out_dict['segmentation'] = None\n",
        "        out_dict['tracking_id'] = None\n",
        "        tracking_results.append(out_dict)\n",
        "        out_dict = {}\n",
        "    if frame_number % 1000 == 0:\n",
        "      print(frame_number,bbox.conf[0],int(bbox.cls[0]), bbox.xyxy[0],\n",
        "              numpy_mask_to_rle(np_mask)\n",
        "              )\n",
        "    frame_number += 1\n"
      ],
      "metadata": {
        "id": "sbry9ADE8EJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(tracking_results)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-oXXwE5HOJOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "tracking_csv = f\"{source.split('.')[0]}_tracking_results.csv\"\n",
        "df.to_csv(tracking_csv)\n",
        "files.download(tracking_csv)"
      ],
      "metadata": {
        "id": "oUwAhp6uSE6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload and train on your custom dataset"
      ],
      "metadata": {
        "id": "-4ha4wOBpq1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload = files.upload()\n",
        "dataset =  list(upload.keys())[0]"
      ],
      "metadata": {
        "id": "YLv8dBr-99Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/datasets/test_mouse.zip -d /content/datasets/\n",
        "!unzip $dataset -d /content/datasets"
      ],
      "metadata": {
        "id": "FyQwu_Va-O-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the data.yaml file and change the train, val, and test absolute paths"
      ],
      "metadata": {
        "id": "BXNmDTYbJ_b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find data.yaml file\n",
        "import glob\n",
        "data_ymals = glob.glob('/content/datasets/*/data.yaml')\n",
        "print(\"The data.yaml file is located at: \", data_ymals)\n",
        "dataset_dir = os.path.dirname(data_ymals[0])\n",
        "print(\"The dataset directory is located at :\", dataset_dir)"
      ],
      "metadata": {
        "id": "G9cGSeuFHSH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function first searches for a data.yaml file in the specified root directory and its subdirectories. If the file is found, it reads its contents and replaces any lines that match the old_line argument with the new_line argument. It then saves the modified file and prints a message confirming the replacement. If the file is not found, it raises a ValueError."
      ],
      "metadata": {
        "id": "fM6j0z7TL2t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def replace_yaml_lines(root_dir, old_line, new_line):\n",
        "    # Find data.yaml file\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        if 'data.yaml' in files:\n",
        "            yaml_path = os.path.join(root, 'data.yaml')\n",
        "            break\n",
        "    else:\n",
        "        raise ValueError('No data.yaml file found in root directory or subdirectories')\n",
        "\n",
        "    # Replace specified lines\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        for line in lines:\n",
        "            if old_line in line:\n",
        "                line = new_line + '\\n'\n",
        "            f.write(line)\n",
        "\n",
        "    print(f'Replaced {old_line} with {new_line} in {yaml_path}')\n"
      ],
      "metadata": {
        "id": "zo9HgTNlFwjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_yaml_lines(dataset_dir, 'train: ../train/images', f'train: {dataset_dir}/train/images')\n",
        "replace_yaml_lines(dataset_dir, 'val: ../val/images', f'val: {dataset_dir}/val/images')\n",
        "replace_yaml_lines(dataset_dir, 'test: ../test/images', f'test: {dataset_dir}/val/images')"
      ],
      "metadata": {
        "id": "5Osl7WanGW7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a new model based on the custom new dataset\n"
      ],
      "metadata": {
        "id": "GIrPSu2AgRtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "#model = YOLO(\"yolov8n-seg.yaml\")  # build a new model from scratch\n",
        "# load a pretrained model (recommended for training)\n",
        "model_name = \"yolov8n-seg.pt\" #@param ['yolov8n-seg.pt','yolov8x-seg.pt','yolov8n.pt','yolov8x.pt']\n",
        "model = YOLO(model_name)\n",
        "data_yaml_file = data_ymals[0]\n",
        "num_epoches = 100 #@param\n",
        "# Train the model\n",
        "model.train(data=data_yaml_file, epochs=num_epoches)"
      ],
      "metadata": {
        "id": "rcrYk4lW931p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JQRVPMtA9Cr"
      },
      "source": [
        "# Download data\n",
        "\n",
        "Get test video from repo and extract the first 2 seconds of it or your can upload your video by click the file upload button under Files menu on the left"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Acf_nRZ7yS6"
      },
      "source": [
        "\n",
        "# upload your video or get the test video from the repo\n",
        "!wget -nc https://github.com/mikel-brostrom/yolov8_tracking/releases/download/v.2.0/test.avi\n",
        "# extract 3 seconds worth of video frames of it\n",
        "!yes | ffmpeg -ss 00:00:00 -i test.avi -t 00:00:01 -vf fps=30 out.avi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqIP5shr9HQd"
      },
      "source": [
        "## Run inference on video\n",
        "\n",
        "The ``cv2.imshow()`` and ``cv.imshow()`` functions from the [opencv-python](https://github.com/skvark/opencv-python) package are incompatible with Jupyter notebook; see https://github.com/jupyter/notebook/issues/3935.\n",
        "\n",
        "Hence we chose to save it to file in this notebook. Locally you can use the ``--show-vid`` flag in order visualize the tracking in real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yEraJfKhBku"
      },
      "source": [
        "video_file = '/content/directedsong_20221007_clip.mp4' #@param\n",
        "!python track.py --yolo-weights yolov8m-seg.pt --tracking-method ocsort --reid-weights osnet_x0_25_msmt17.pt --device 0 --source $video_file --save-vid --save-crop --save-txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and predict a video from YouTube"
      ],
      "metadata": {
        "id": "wmu3ScqlqhvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "id": "709TMkfuZKtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import os\n",
        "\n",
        "def downloadYouTube(videourl, path):\n",
        "\n",
        "    yt = YouTube(videourl)\n",
        "    yt = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    yt.download(path)\n",
        "\n",
        "downloadYouTube('https://youtu.be/W7QZnwKqopo', '/content')"
      ],
      "metadata": {
        "id": "K2GRU2nrZJyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_file = '/content/birds_dance_bbc.mp4' #@param\n",
        "model_name = 'yolov8x-seg.pt' #@param ['yolov8n-seg.pt','yolov8x-seg.pt','yolov8n.pt','yolov8x.pt']\n",
        "!python track.py --yolo-weights $model_name --tracking-method ocsort --reid-weights osnet_x0_25_msmt17.pt --device 0 --source $video_file --save-vid --save-txt --retina-masks\n"
      ],
      "metadata": {
        "id": "ghrzfpSbXkJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "##https://github.com/mikel-brostrom/yolov8_tracking/blob/master/track.py#L243\n",
        "## Write MOT compliant results to file with mask RLE\n",
        "# define the column names\n",
        "columns = ['Frame_ID', 'Object_ID', 'bbox_left', 'bbox_top', 'Width', 'Height', 'Confidence', 'Class_ID','Visibility_ratio','idx','segmentation']\n",
        "df = pd.read_csv(f'/content/yolov8_tracking/runs/track/exp/tracks/{os.path.basename(video_file).split(\".\")[0]}.txt',header=None,delimiter='\\t')"
      ],
      "metadata": {
        "id": "NcsLjzGL1a4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = columns\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kpSalRch1j-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Please replace the name of the animal being tracked with the appropriate species name, such as mouse, fish, vole, or other relevant species."
      ],
      "metadata": {
        "id": "q0BuGRB-YtQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = 'bird' #@param"
      ],
      "metadata": {
        "id": "c1u4hvPU6_wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annolid_columns = ['frame_number','x1','y1','x2','y2','instance_name','class_score','segmentation','tracking_id']"
      ],
      "metadata": {
        "id": "8fuHmo_Q7eFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['x1'] = df.bbox_left\n",
        "df['y1'] = df.bbox_top\n",
        "df['x2'] = df.bbox_left + df.Width\n",
        "df['y2'] = df.bbox_top + df.Height\n",
        "df['frame_number'] = df.Frame_ID\n",
        "df['instance_name'] = f\"{class_name}\"\n",
        "df['class_score'] = 1\n",
        "df['segmentation'] = df.segmentation\n",
        "df['tracking_id'] = df.Object_ID\n",
        "\n"
      ],
      "metadata": {
        "id": "Ld_aH7qe59a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_annolid = df[annolid_columns]\n",
        "df_annolid.head()"
      ],
      "metadata": {
        "id": "83VUeat177nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracking_csv_file = f'{video_file.split(\".\")[0]}_{model_name.split(\".\")[0]}_tracking_results.csv'\n",
        "df_annolid.to_csv(tracking_csv_file)\n",
        "files.download(tracking_csv_file)"
      ],
      "metadata": {
        "id": "z2M5BL5E8Vdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd-CFrVGBoEU"
      },
      "source": [
        "# Show results\n",
        "\n",
        "https://stackoverflow.com/questions/60977179/how-to-play-avi-file-in-google-colab\n",
        "\n",
        "https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-colab\n",
        "\n",
        "Compress the video file to a format supported by Google Colab (mpeg4 (native) -> h264 (libx264))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-4tlUaCBjDC"
      },
      "source": [
        "!ffmpeg -i /content/yolov8_tracking/runs/track/exp11/bird.mp4 -vf fps=30 -vcodec libx264 output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7XAlRteC9qI"
      },
      "source": [
        "Get the file content into data_url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ObuFb7dBwxK"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('output.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLvggIUZDC6R"
      },
      "source": [
        "Display it with HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyXr0xsZB897"
      },
      "source": [
        "HTML(\"\"\"\n",
        "<video controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference: https://github.com/mikel-brostrom/yolov8_tracking"
      ],
      "metadata": {
        "id": "JHQcY9mwWXc7"
      }
    }
  ]
}