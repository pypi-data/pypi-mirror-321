import pyperclip

questions = {
    "1. Модель перцептрона. Проблема линейно неразделимых множеств и ее решение. Логика построения многослойных ИНС. Линейные слои (Linear Layers) в PyTorch": {
        "markdown": "## Модель перцептрона \nОдин слой, выполняющий линейную комбинацию входных данных и применяющий активационную функцию\n## Проблема линейно неразделимых множеств\nПерцептрон не может решить задачу классификации, если классы не могут быть разделены гиперплоскостью (то есть линейно). Например, задача XOR.\n![[Pasted image 20250106104703.png]]\nДля решения проблемы линейной неразделимости используется **многослойный перцептрон (MLP)**, где несколько слоев позволяют моделировать нелинейные границы раздела, используя нелинейные активационные функции (например, ReLU).\n## Логика построения многослойных ИНС\nВ многослойных ИНС (искусственная нейронная сеть) входной слой передает данные через несколько скрытых слоев, каждый из которых применяет линейную трансформацию и активацию. На выходном слое производится итоговое предсказание.\n## Линейные слои (Linear Layers) в PyTorch\nЛинейный слой выполняет операцию y=x @ W.T+b, где W — матрица весов, b — смещение, x— входные данные, а y — выход. \nВ PyTorch линейный слой создается с помощью torch.nn.Linear(in_features, out_features), аналогичному операции torch.nn.functional.linear(input, weight, bias)\n\n```python\nimport torch\nfrom torch import nn\n  \nin_features = 10\nout_features = 2\n\nlinear_layer = nn.Linear(in_features=in_features, out_features=out_features)\n\nx = torch.randn(2, 10)\n  \n\ntorch.isclose(\n    torch.sum(linear_layer(x)),\n    torch.sum(x @ linear_layer.weight.T + linear_layer.bias)\n\n)\n```\n\n"
    },
    "2. Функции активации. Требования к функциям активации Популярные функции активации. Слои нелинейной активации (Non Linear Activations) в PyTorch": {
        "markdown": "## Функции активации\nФункции активации необходимы для того, чтобы нейронные сети могли моделировать нелинейные зависимости. Без них сеть будет эквивалентна линейной модели, что сильно ограничивает её возможности.\n## Требования к функциям активации\n1. **Нелинейность** — функция должна быть нелинейной, чтобы сеть могла решать сложные задачи.\n2. **Дифференцируемость** — функция должна быть **почти всюду** дифференцируемой, чтобы использовать градиентный спуск. (Например, чтобы ReLU была дифференцируема в точке 0 градиент устанавливают в 0)\n3. **Вычислительная эффективность** — функция должна быть вычислительно простой для быстрого обучения.\n## Популярные функции активации\n\n1. **Sigmoid**  \n   $$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $$  \n   Функция sigmoid сжимает входные данные в диапазон от 0 до 1. Она используется для задач классификации, но может страдать от проблемы исчезающего градиента.\n\n2. **Tanh**  \n   $$ \\tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $$  \n   Функция tanh сжимает входные данные в диапазон от -1 до 1. Она решает проблему исчезающих градиентов лучше, чем sigmoid, но всё ещё может её испытывать при больших значениях.\n\n3. **ReLU**  \n   $$ \\text{ReLU}(x) = \\max(0, x) $$  \n   Это наиболее популярная функция активации. Она проста и вычислительно эффективна, но может страдать от проблемы \"мертвых нейронов\", когда выход становится всегда нулевым для отрицательных значений.\n\n4. **Leaky ReLU**  \n   $$ \\text{Leaky ReLU}(x) = \\begin{cases} \n   x & \\text{если } x > 0 \\\\\n   \\alpha x & \\text{если } x \\leq 0 \n   \\end{cases} $$  \n   Модификация ReLU, которая позволяет некоторый маленький наклон для отрицательных значений. Это помогает избежать проблемы мёртвых нейронов.\n\n5. **ELU**  \n   $$ \\text{ELU}(x) = \\begin{cases} \n   x & \\text{если } x > 0 \\\\\n   \\alpha(e^x - 1) & \\text{если } x \\leq 0 \n   \\end{cases} $$  \n   Эта функция активации, как и Leaky ReLU, имеет малый наклон для отрицательных значений, но в отличие от Leaky ReLU она использует экспоненциальную функцию для отрицательных входов, что помогает сети быстрее сходиться.\n\n## Слои нелинейной активации в PyTorch\nВ PyTorch слои активации можно использовать через `torch.nn`:\n1. **ReLU**: `torch.nn.ReLU()`\n2. **Sigmoid**: `torch.nn.Sigmoid()`\n3. **Tanh**: `torch.nn.Tanh()`\n4. **Leaky ReLU**: `torch.nn.LeakyReLU()`\n5. **ELU**: `torch.nn.ELU()`\n\n## Fun fact\nВ последнее время изобрели такую штуку, как линейный слой + активация в 1 и тот же момент.\nПример: **GEGLU** (Gated Linear Unit with GELU), которая показала прирост в архитектуре трансформера\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass GEGLU(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(GEGLU, self).__init__()\n        self.linear1 = nn.Linear(input_dim, output_dim)\n        self.linear2 = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x):\n        return F.gelu(self.linear1(x)) * self.linear2(x)\n```\n"
    },
    "3. Глубокое обучение. «Вторая весна искусственного интеллекта» и ее причины": {
        "markdown": "## Глубокое обучение\nГлубокое обучение — это подмножество машинного обучения, которое использует нейронные сети с большим числом слоев для моделирования сложных зависимостей в данных.\n## «Вторая весна искусственного интеллекта»\n«Вторая весна искусственного интеллекта» (середина 2010-х годов) обозначает период возрождения интереса к искусственному интеллекту, когда достигнуты значительные успехи в применении глубоких нейронных сетей.\n## Причины возрождения\n1. **Доступность больших данных**: С увеличением объема данных, например, в области интернета вещей и социальных сетей, стало возможным обучение более мощных моделей.\n2. **Увеличение вычислительных мощностей**: Использование графических процессоров (GPU) значительно ускорило обучение нейронных сетей, что позволило работать с более сложными моделями.\n3. **Продвинутые алгоритмы**: Применение алгоритмов глубокого обучения, таких как сверточные нейронные сети (CNN), рекуррентные нейронные сети (RNN), внимание (Attention), стало стандартом в решении задач компьютерного зрения и обработки естественного языка.\n4. **Реальные достижения**: Прорывы в задачах распознавания объектов, перевода текста, создания изображений и других областях, которые стали возможными благодаря глубоким нейронным сетям."
    },
    "4. Проблема поиска градиента в общей логике обучения нейронной сети. Градиент функции многих переменных. Методы вычисления": {
        "markdown": "## Проблема поиска градиента\nВ обучении нейронных сетей основная задача — вычисление градиента функции потерь по всем параметрам модели. \nПроблемы могут возникать из-за большого количества параметров, высокой сложности функций и нестабильности (исчезающие или взрывающиеся градиенты).\n## Градиент функции многих переменных\nГрадиент функции многих переменных — это вектор частных производных. Для функции потерь L(w1, w2, ..., wn):\n\n$$\n\\nabla L = \\left( \\frac{\\partial L}{\\partial w_1}, \\frac{\\partial L}{\\partial w_2}, ..., \\frac{\\partial L}{\\partial w_n} \\right)\n$$\n\nГрадиент указывает направление наибольшего роста функции, а в обучении он используется в противоположном направлении для минимизации функции ошибки.\n## Методы вычисления\n1. **Обратное распространение ошибки (Backpropagation)**  \n   Использует правило цепочки для эффективного вычисления производных. Начинается с выходного слоя и идет обратно к входному, обновляя веса на каждом этапе.\n   [[Линейное отображение. Векторно-матричное дифференцирование.#^fafd8c|Подробный пример]]\n1. **Численный метод конечных разностей (Finite Difference)**  \n   Вычисляет приближение градиента с помощью разностей:\n   $$\n   \\frac{\\partial L}{\\partial w_i} \\approx \\frac{L(w + \\epsilon) - L(w)}{\\epsilon}\n   $$\n   Этот метод медленный и подвержен численной ошибке, но прост в реализации."
    },
    "5. Кросс-валидация. Выборки train, validation, test. Проблема переобучения. Ранняя остановка": {
        "markdown": "Кросс-валидация — это метод оценки модели, при котором данные разбиваются на несколько частей (**folds**). Модель обучается на одной части данных и тестируется на другой, чтобы получить устойчивую оценку качества. Этот метод помогает уменьшить влияние случайных факторов, связанных с конкретным разбиением данных.\n### Основные виды кросс-валидации\n#### 1. **k-fold кросс-валидация**\n- Данные делятся на $k$ равных частей (folds).\n- Обучение проводится $k$ раз:\n  - Каждый раз $k-1$ частей используются для обучения.\n  - Оставшаяся часть используется для тестирования.\n- Итоговая метрика — среднее значение метрики на всех $k$ итерациях.\n**Плюсы:**\n- Устойчивость оценки качества за счёт использования всех данных.\n- Универсальность для любых размеров данных.\n**Минусы:**\n- Требует $k$-кратного обучения, что увеличивает время расчёта.\n#### 2. **Leave-One-Out Cross-Validation (LOOCV)**\n- Специальный случай $k$-fold кросс-валидации, где $k = n$ (число примеров в выборке).\n- На каждой итерации:\n  - Один пример оставляется для тестирования.\n  - Остальные $n-1$ примеров используются для обучения.\n**Пример:**\nЕсли в наборе данных 100 наблюдений, то модель обучается 100 раз, каждый раз тестируя её на одном наблюдении.\n**Плюсы:**\n- Максимально эффективное использование данных, так как каждая точка используется для тестирования.\n- Подходит для небольших наборов данных.\n**Минусы:**\n- Очень затратен по времени для больших выборок, так как требует $n$-кратного обучения.\n#### 3. **Stratified k-fold**\n- Модификация $k$-fold, при которой разбиение данных производится с сохранением пропорций классов.\n- Используется для несбалансированных данных, где важно сохранять распределение классов в каждом fold.\n**Плюсы:**\n- Уменьшает риск переобучения на несбалансированных данных.\n#### 4. **Time Series Split**\n- Подходит для временных рядов, где порядок данных имеет значение.\n- Данные делятся на несколько итераций так, чтобы каждая следующая часть тестовых данных находилась позже обучающей.\n**Пример:**\n1. На первом шаге обучаем модель на первых 70% данных и тестируем на следующих 10%.\n2. На следующем шаге добавляем ещё 10% в обучающую выборку, а тестируем на следующих 10%.\n**Плюсы:**\n- Сохраняет временную последовательность.\n#### 5. **Shuffle-Split Cross-Validation**\n- Данные случайным образом разбиваются на обучающие и тестовые наборы заданное число раз.\n**Плюсы:**\n- Гибкость в отношении размера тестовой и обучающей выборки.\n- Полезен, если важен контроль над размерами подвыборок.\n**Минусы:**\n- Не подходит для временных рядов.\n### Сравнение методов\n| Метод                  | Итерации | Использование данных | Подходит для больших данных | Сложность |\n|-------------------------|----------|-----------------------|-----------------------------|-----------|\n| k-fold                 | k        | Все данные            | Да                          | Умеренная |\n| Leave-One-Out (LOOCV)  | n        | Все данные            | Нет                         | Высокая   |\n| Stratified k-fold      | k        | Все данные            | Да                          | Умеренная |\n| Time Series Split      | Зависит от набора | Частичное         | Да                          | Умеренная |\n| Shuffle-Split          | Настраиваемое     | Возможно частичное| Да                          | Низкая    |\n### Применение в Python\nБольшинство из видов кросс-валидации реализованы внутри пакета sklearn.model_selection\n## Выборки train, validation, test\n1. **Train**: используется для обучения модели.\n2. **Validation**: служит для подбора гиперпараметров и проверки качества модели в процессе обучения.\n3. **Test**: применяется для итоговой оценки модели на ранее невиданных данных.\nДанные должны быть разделены таким образом, чтобы тестовая выборка оставалась полностью изолированной во время обучения и настройки модели.\n## Проблема переобучения\nПереобучение возникает, когда модель слишком хорошо подстраивается под обучающую выборку, теряя способность обобщать на новых данных. Симптомы переобучения:\n- Высокая точность на обучающей выборке.\n- Низкая точность на валидационной или тестовой выборке.\n![[Pasted image 20250106113735.png]]\n## Ранняя остановка\nРанняя остановка — это метод предотвращения переобучения. \nВ процессе обучения, если ошибка (либо любая иная мера качества модели) на валидационной выборке перестает уменьшаться (или начинает расти) за какое-то количество (в формуле буква k) шагов, обучение прекращается. Это позволяет сохранить модель, которая лучше всего обобщает данные.\n\nФормально, если L — функция потерь на валидационной выборке, то обучение прекращается, когда:\n\n$$\nL_{\\text{val}}(t) < \\min \\{ L_{\\text{val}}(t-1), L_{\\text{val}}(t-2), \\dots, L_{\\text{val}}(t-k) \\}\n$$\n\nгде t — номер эпохи."
    },
    "6. Преобразование Softmax и функция потерь Cross Entropy loss": {
        "markdown": "## Преобразование Softmax\n\nSoftmax преобразует выходы модели в вероятности, распределенные по классам. Формула для класса i:\n\n$$\n\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n$$\n\nгде z_i — логит (выход сети) для класса i, n — общее количество классов. Сумма всех вероятностей равна 1.\n## Функция потерь Cross Entropy loss\nCross Entropy измеряет разницу между предсказанными вероятностями p и истинным распределением y. Формула:\n\n$$\nL = -\\sum_{i=1}^{n} y_i \\log(p_i)\n$$\n\nгде y_i — истинное значение (1 для правильного класса, 0 для остальных), p_i — вероятность, предсказанная для класса i.\nДля одного истинного класса y:\n\n$$\nL = -\\log(p_y)\n$$\n### Бинарный случай\nBinary Cross Entropy используется для задач бинарной классификации. Она измеряет разницу между предсказанным значением p и истинным значением y для каждой выборки. Формула: $$ L = - \\left( y \\log(p) + (1 - y) \\log(1 - p) \\right) $$\n## Связь между Softmax и Cross Entropy\nSoftmax используется для преобразования логитов в вероятности, а Cross Entropy применяет эти вероятности для оценки ошибки. \nЭто комбинация используется для обучения моделей для задачи классификации."
    },
    "7. Механизм обратного распространения ошибки. Принципиальная логика основного цикла обучения нейронной сети в PyTorch. Слои функций потерь (Loss Functions) в PyTorch": {
        "markdown": "## Механизм обратного распространения ошибки\nОбратное распространение ошибки (backpropagation) — это алгоритм вычисления градиентов для всех параметров нейронной сети. Он основан на применении правила цепочки для обновления весов. Основные шаги:\n1. Вычисление функции потерь L на основе предсказания модели y_pred и истинного значения y_true.\n2. Вычисление градиента функции потерь по параметрам модели с помощью правила цепочки (по значению для прохода дальше, по параметрам для обновления весов)\n3. Обновление параметров с использованием градиентного спуска:\n\n$$\nw = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}\n$$\n\nгде w — веса модели, η — скорость обучения.\nПодробный пример\n[[Линейное отображение. Векторно-матричное дифференцирование.#^fafd8c|Пример]]\n## Принципиальная логика основного цикла обучения нейронной сети в PyTorch\n1. **Прямой проход**: входные данные проходят через сеть, и вычисляется выход y_pred.\n2. **Вычисление потерь**: функция потерь оценивает разницу между y_pred и y_true.\n3. **Обратный проход**: выполняется backpropagation с вызовом loss.backward(), чтобы вычислить градиенты.\n4. **Обновление параметров**: оптимизатор обновляет веса, например, с помощью optimizer.step().\n5. **Очистка градиентов**: после обновления необходимо обнулить градиенты, используя optimizer.zero_grad().\nМогут быть добавлены любые иные дополнительные шаги, такие как scheduler для learning rate или подсчёт метрик\nПример цикла в PyTorch:\n\n```python\n...\nfor batch in data_loader:\n    optimizer.zero_grad()\n    y_pred = model(batch['input'])\n    loss = loss_fn(y_pred, batch['target'])\n    loss.backward()\n    optimizer.step()\n...\n```\n\n## Слои функций потерь в PyTorch\nФункции потерь используются для оптимизации модели, принимая предсказания и истинные значения. Их выбор зависит от типа задачи, например, классификация или регрессия.\nPyTorch предоставляет широкий набор функций потерь, которые используются для обучения моделей, оценивая разницу между предсказаниями и истинными значениями.\n## MSELoss\nИспользуется для регрессии. Формула:\n\n$$\nL = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred}_i} - y_{\\text{true}_i})^2\n$$\n\nПример в torch:\nloss_fn = torch.nn.MSELoss()\nloss = loss_fn(predictions, targets)\n\n## CrossEntropyLoss\nИспользуется для многоклассовой классификации, комбинируя softmax и cross entropy. Формула:\n\n$$\nL = -\\sum_{i=1}^{n} y_i \\log(p_i)\n$$\n\nПример в torch:\nloss_fn = torch.nn.CrossEntropyLoss()\nloss = loss_fn(predictions, targets)\n\n## BCELoss\nПрименяется для бинарной классификации. Формула:\n\n$$\nL = - \\left( y \\log(p) + (1 - y) \\log(1 - p) \\right)\n$$\n\nПример в torch:\nloss_fn = torch.nn.BCELoss()\nloss = loss_fn(predictions, targets)\n## SmoothL1Loss\nИспользуется для задач регрессии с шумными данными. Формула:\n\n$$\nL = \\begin{cases} \n0.5 (y_{\\text{pred}} - y_{\\text{true}})^2, & \\text{если } |y_{\\text{pred}} - y_{\\text{true}}| < 1 \\\\\n|y_{\\text{pred}} - y_{\\text{true}}| - 0.5, & \\text{иначе}\n\\end{cases}\n$$\n\nПример в torch:\nloss_fn = torch.nn.SmoothL1Loss()\nloss = loss_fn(predictions, targets)\n\n"
    },
    "8. Дифференцируемое программирование и реализация обратного распространения ошибки. Автоматическое дифференцирование в PyTorch. Пример и применение в обучении ИНС": {
        "markdown": "## Дифференцируемое программирование\nПодход, позволяющий интегрировать традиционное программирование с нейросетями, чтобы оптимизировать не только параметры модели, но и встроенные вычислительные операции. Основной механизм — автоматическое дифференцирование.\n## Реализация обратного распространения ошибки\nОбратное распространение ошибки использует градиенты функции потерь для обновления параметров:\n1. Вычисляется прямая проходка (forward pass) и значение функции потерь.\n2. Используются правила дифференцирования для вычисления градиентов параметров через цепное правило:\n$$\n\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial w}\n$$\nгде \\( L \\) — функция потерь, \\( w \\) — параметры.\n## Автоматическое дифференцирование в PyTorch\nPyTorch использует библиотеку `torch.autograd` для автоматического вычисления градиентов. При выполнении операций с тензорами создается вычислительный граф, позволяющий эффективно находить градиенты.\n\nВ общем случае все функции являются подклассом torch.autograd.Function и реализуют метод backward, который используется вычислительным графом для подсчёта градиентов\n```python\nimport torch\n\nclass MyFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input):\n        ctx.save_for_backward(input) # cохранение входа для последующего использования в backward\n        return input ** 2  # x^2\n\n    @staticmethod\n    def backward(ctx, grad_output):\n\t    # grad_output - градиенты более поздних функций\n\t    # grad_output * текущая_производная -> правило цепочки\n        input, = ctx.saved_tensors\n        grad_input = 2 * input * grad_output\n        return grad_input\n\n```\n## Конкретный пример\n# Инициализация переменных\n```python\nimport torch\n\nx = torch.tensor(2.0, requires_grad=True)\ny = x ** 2 + 3 * x + 5\n```\n# Обратное распространение\n```\ny.backward()\nprint(x.grad)  # Градиент dy/dx\n```\n## Пример и применение в обучении ИНС\nВ обучении нейронных сетей PyTorch использует автоматическое дифференцирование для оптимизации параметров.\n\nПример:\n```\nimport torch.nn as nn\nimport torch.optim as optim\n```\n\n# Пример модели\n```\nmodel = nn.Linear(1, 1)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n```\n# Прямой проход\n```\ninput = torch.tensor([[1.0]])\ntarget = torch.tensor([[2.0]])\noutput = model(input)\nloss = criterion(output, target)\n```\n# Обратное распространение и обновление параметров\n```\nloss.backward()\noptimizer.step()\n```\n## Применение\n1. Оптимизация параметров в нейронных сетях.\n2. Использование нестандартных вычислений в графах (например, нестандартные функции потерь).\n3. Интеграция традиционных алгоритмов с градиентными методами."
    },
    "9. Стохастический градиентный спуск. Батчи обучающей выборки": {
        "markdown": "## Стохастический градиентный спуск\n\nСтохастический градиентный спуск (SGD) — это метод оптимизации, который обновляет параметры модели на основе градиента функции потерь, вычисленного для одной или нескольких случайно выбранных выборок. \nЭто ускоряет обучение и снижает вычислительные затраты по сравнению с классическим градиентным спуском (использующим в каждой итерации весь датасет).\nОбновление весов для параметра w:\n\n$$\nw = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}\n$$\nгде:\n- w — параметр модели,\n- η — скорость обучения,\n- L — функция потерь.\n## Батчи обучающей выборки\n\n^1bc4f3\n\nБатчи — это небольшие подмножества обучающей выборки, используемые для вычисления градиента. Они позволяют балансировать между скоростью обучения и точностью градиента.\n1. **Полный градиентный спуск** (Batch Gradient Descent):\n   Использует всю обучающую выборку для одного обновления весов. Это медленно и вычислительно затратно.\n2. **Стохастический градиентный спуск** (Stochastic Gradient Descent):\n   Использует одну случайную выборку для обновления. Это быстро, но может быть нестабильным.\n3. **Мини-батч градиентный спуск** (Mini-Batch Gradient Descent):\n   Использует случайные батчи размера b, что стабилизирует обучение. Градиент рассчитывается как среднее:\n$$\n\\frac{1}{b} \\sum_{i=1}^{b} \\frac{\\partial L_i}{\\partial w}\n$$\n\nгде b — размер батча, L_i — функция потерь для i-го примера.\n![[Pasted image 20250106155400.png]]\n## Преимущества использования батчей\n1. Снижение вычислительных затрат по сравнению с полным градиентным спуском.\n2. Стабильность обучения по сравнению с использованием одной выборки.\n3. Возможность использовать аппаратное ускорение (GPU) для параллельной обработки батчей"
    },
    "10. Адаптивные методы градиентного спуска. Метод импульсов. Метод Нестерова": {
        "markdown": "## Адаптивные методы градиентного спуска\nАдаптивные методы изменяют скорость обучения для каждого параметра на основе прошлых градиентов. Это ускоряет сходимость и делает обучение более стабильным.\n### AdaGrad\nAdaGrad уменьшает шаг обучения для часто изменяющихся параметров и увеличивает для редко обновляемых:\n\n$$\nw = w - \\frac{\\eta}{\\sqrt{G + \\epsilon}} \\cdot \\frac{\\partial L}{\\partial w}\n$$\n\nгде G — сумма квадратов прошлых градиентов, ε — небольшое значение для избегания деления на ноль. (Больше градиент -> меньше learning rate)\n### RMSProp\nRMSProp улучшает AdaGrad, используя экспоненциальное сглаживание для суммы квадратов градиентов:\n\n$$\nG_t = \\beta G_{t-1} + (1 - \\beta) \\left( \\frac{\\partial L}{\\partial w} \\right)^2\n$$\n\n$$\nw = w - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\cdot \\frac{\\partial L}{\\partial w}\n$$\nгде β — коэффициент сглаживания, позволяет настраивать оптимизатор чтобы учитывать менее недавние изменения градиента, а не долгосрочные\n## Метод импульсов (Momentum)\nМетод импульсов ускоряет сходимость, добавляя накопление прошлых градиентов:\n\n$$\nv_t = \\gamma v_{t-1} + \\eta \\frac{\\partial L}{\\partial w}\n$$\n\n$$\nw = w - v_t\n$$\n\nгде γ — коэффициент импульса, v_t-1 добавляет \"инерцию\", помогая ускоряться вдоль направлений с постоянными градиентами. Это позволяет модели быстрее сходиться к минимуму, избегая колебаний. \n## Метод Нестерова\nМетод Нестерова, или ускоренный градиент Нестерова (Nesterov Accelerated Gradient, NAG), — это модификация градиентного спуска с моментом, направленная на ускорение сходимости и повышение стабильности обучения. За счёт дополнительного предсказательного шага вычислительно сложнее, так как содержит ещё одно предсказание\n**Основные формулы метода Нестерова:**\n1. **Предварительное обновление параметров:**\n   $$\n   \\tilde{\\theta}_t = \\theta_t + \\mu v_{t-1}\n   $$\n   где:\n   - $\\theta_t$ — параметры модели на итерации $t$,\n   - $\\mu$ — коэффициент моментума (обычно $0 \\leq \\mu < 1$),\n   - $v_{t-1}$ — скорость (накопленный градиент) на предыдущей итерации.\n2. **Вычисление градиента в предсказанной точке:**\n   $$\n   g_t = \\nabla f(\\tilde{\\theta}_t)\n   $$\n   где $f$ — функция потерь, $\\nabla f(\\tilde{\\theta}_t)$ — градиент функции потерь, вычисленный в точке $\\tilde{\\theta}_t$.\n3. **Обновление скорости:**\n   $$\n   v_t = \\mu v_{t-1} - \\eta g_t\n   $$\n   где:\n   - $\\eta$ — скорость обучения (learning rate),\n   - $g_t$ — градиент, вычисленный в предсказанной точке.\n4. **Обновление параметров модели:**\n   $$\n   \\theta_{t+1} = \\theta_t + v_t\n   $$\n \nТаким образом, метод Нестерова сначала предсказывает будущее положение параметров с учётом моментума, затем вычисляет градиент в этой предсказанной точке и обновляет параметры, что позволяет более эффективно двигаться в направлении минимума функции потерь.\n### Adam\nAdam объединяет идеи RMSProp и момента, учитывая как среднее значение градиентов (импульсы), так и их квадраты (частота обновления параметров):\n\n$$\nm_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\frac{\\partial L}{\\partial w}\n$$\n\n$$\nv_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\left( \\frac{\\partial L}{\\partial w} \\right)^2\n$$\n\n$$\nw = w - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\cdot \\hat{m}_t\n$$\n\nгде $\\hat{m}_t$ и $\\hat{v}_t$ — скорректированные значения моментов, комбинирует описанные подходы. Метод более универсален, из-за чего имеет 2 дополнительных гиперпараметра $\\beta_1$ и $\\beta_2$ для корректировки длительности влияния предыдущих \n\n## Вывод\nОптимизатор по своей сути ещё один гиперпараметр, выбираемые для обучения сети. В каждой задаче могут быть качественные различия между ними. AdamW (W - weighted, позволяет добавлять регуляризацию на веса модели) является сильным baselin'ом в подавляющем большинстве ситуаций.\n![[Pasted image 20250106160741.png]]\nВ настоящее время также существует множество оптимизаторов, показывающих себя когда-то лучше, чем AdamW.\nНапример:\n[Lion - Evo**L**ved S**i**gn M**o**me**n**tum](https://github.com/lucidrains/lion-pytorch)"
    },
    "11. Проблема инициализации весов при обучении ИНС. Инициализация Ксавье": {
        "markdown": "## Проблема инициализации весов\nПри обучении нейронных сетей некорректная инициализация весов может привести к следующим проблемам:\n1. **Исчезающие градиенты**:\n   При слишком маленьких начальных значениях весов градиенты становятся малы, что замедляет обучение.\n2. **Взрывающиеся градиенты**:\n   При слишком больших начальных значениях весов градиенты становятся большими, что приводит к нестабильности и невозможности сходимости.\n3. **Несбалансированное обучение**:\n   Если веса инициализируются одинаково (например, с нуля), все нейроны одного слоя будут обучаться одинаково, что снижает эффективность сети.\n## Инициализация Ксавье\nИнициализация Ксавье (или Glorot инициализация) решает проблему стабильного распределения значений через сеть. Она контролирует дисперсию активаций и градиентов, чтобы оставаться примерно одинаковой на всех слоях.\n### Идея\nВес w инициализируется случайным образом с распределением, зависящим от числа входов $n_{in}$ и выходов  $n_{out}$) для слоя:\n\n1. Для равномерного распределения:\n   $$\n   w \\sim U\\left[-\\frac{\\sqrt{6}}{\\sqrt{n_{\\text{in}} + n_{\\text{out}}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{\\text{in}} + n_{\\text{out}}}}\\right]\n   $$\n\n2. Для нормального распределения:\n   $$\n   w \\sim N\\left(0, \\frac{2}{n_{\\text{in}} + n_{\\text{out}}}\\right)\n   $$\n\n### Преимущества\n1. Сохраняет стабильные значения активаций и градиентов через слои.\n2. Улучшает скорость сходимости модели.\n3. Особенно эффективна для сети с функциями активации, такими как tanh или сигмоида.\n## Применение в PyTorch\nВ PyTorch инициализация Ксавье доступна через модуль `torch.nn.init`:\n\n```python\nimport torch\nimport torch.nn as nn\n\nlayer = nn.Linear(in_features, out_features)\ntorch.nn.init.xavier_uniform_(layer.weight)\n```\n\nИзначально nn.Linear инициализируется с помощью с использованием **Kaiming Uniform Initialization** с параметром a=$\\sqrt5$, что отлично подходит для таких функций активации, как ReLU\n```python\n...\n# один из методов nn.Linear, который используется при инициализации слоя\n def reset_parameters(self) -> None:\n        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n        # https://github.com/pytorch/pytorch/issues/57109\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n...​\n```\n"
    },
    "12. Переобучение модели и регуляризация. Принцип механизма Dropout. Слои регуляризации (Dropout Layers) в PyTorch": {
        "markdown": "## Переобучение модели\nПереобучение происходит, когда модель слишком хорошо запоминает обучающие данные, но плохо обобщает новые данные. Это приводит к огромной разнице в метриках на train и test наборах данных\n## Регуляризация\nРегуляризация уменьшает переобучение, добавляя ограничения на параметры при обучении модели. Основные методы:\n1. L1/L2-регуляризация (штрафы на большие значения весов).\n2. Dropout (отключение нейронов во время обучения).\n## Принцип механизма Dropout\nDropout случайным образом отключает определенные нейроны с вероятностью p во время обучения, что уменьшает зависимость между нейронами. Это улучшает обобщающую способность модели, так как нейроны стараются более универсально подходить к задаче.\nМатематически, на каждом шаге:\n$$\nh_i = z_i \\cdot a_i\n$$\nгде $$z_i \\sim Bernoulli(1 - p)$$,  a_i — активация нейрона, h_i  — итоговый выход.\n![[Pasted image 20250106170114.png]]\n## Слои регуляризации (Dropout Layers) в PyTorch\nDropout применяется как слой регуляризации в нейросетях. Во время тестирования он отключается автоматически.\n\nПример:\nimport torch.nn as nn\ndropout = nn.Dropout(p=0.5)\n\ninput_tensor = torch.randn(1, 10)\noutput_tensor = dropout(input_tensor)\n\n## Пример использования в модели\nimport torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.fc1 = nn.Linear(10, 50)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(50, 1)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = nn.ReLU()(x)\n        x = self.dropout(x)\n        return self.fc2(x)\n\n## train и eval режимы модели\nВ связи с тем, что поведение некоторых слоёв (dropout или batchnorm слои) меняется про тренировке и инференсе, модели реализуют несколько состояний.\nmodel.train() переводит модель в режим обучения (например, включается dropout)\nmodel.eval() отключает dropout или накопление статистик для batchnorm, что позволяет правильно оценивать производительность модели"
    },
    "13. Минибатчи – причина использования. Нормализация по мини-батчам. Слои нормализации (Normalization Layers) в PyTorch": {
        "markdown": "## Минибатчи – причина использования\nМинибатчи разбивают данные на небольшие группы для обработки:\n1. Снижают затраты памяти, позволяя обучать модель на больших наборах данных.\n2. Ускоряют обучение за счет обновления весов чаще, чем при использовании всего набора данных.\n3. Сглаживают процесс оптимизации, уменьшая вероятность застревания в локальных минимумов.\n[[9. Стохастический градиентный спуск. Батчи обучающей выборки.#^1bc4f3|Более подробно]]\n## Основные слои нормализации (Normalization Layers) в PyTorch\n| Характеристика           | Batch Normalization                                                       | Layer Normalization                                 | RMS Normalization                                                                      |\n| ------------------------ | ------------------------------------------------------------------------- | --------------------------------------------------- | -------------------------------------------------------------------------------------- |\n| **Область нормализации** | Нормализация по батчу (по столбцам)                                       | Нормализация по всем признакам объекта (по строкам) | Нормализация по корню среднеквадратичного значения всех признаков объекта (по строкам) |\n| **Статистики**           | Зависит от минибатча                                                      | Независима от минибатча                             | Независима от минибатча                                                                |\n| **Области применения**   | CNN (пространственные данные)                                             | RNN, Transformer (последовательности)               | Transformer, упрощенные нормализации                                                   |\n| **Проблемы**             | Зависимость от размера батча (большой для адекватного подсчёта статистик) | Не учитывает пространственную структуру батча       | Простота, из-за чего менее универсален                                                 |\n| **Обучаемые параметры**  | $\\gamma$ (масштаб) и $\\beta$ (смещение)                                   | $\\gamma$ (масштаб) и $\\beta$ (смещение)             | $\\gamma$ (масштаб)                                                                     |\n## Устройство Batch Normalization (нормализация по мини-батчам)\n\nBatch Normalization нормализует значения для каждого признака в рамках текущего мини-батча. Это помогает стабилизировать обучение, ускорить сходимость и улучшить обобщающую способность модели.\n\nФормула:\n\n$\\hat{x}_i = \\frac{x_i - \\mu_{\\text{batch}}}{\\sqrt{\\sigma^2_{\\text{batch}} + \\epsilon}}$\n\nгде $\\mu_{\\text{batch}}$ и $\\sigma^2_{\\text{batch}}$ вычисляются для каждого признака внутри текущего батча:\n\n$\\mu_{\\text{batch}} = \\frac{1}{N} \\sum_{j=1}^N x_j, \\quad \\sigma^2_{\\text{batch}} = \\frac{1}{N} \\sum_{j=1}^N (x_j - \\mu_{\\text{batch}})^2$\n\nгде $N$ — количество объектов в батче.\n### Обучаемые параметры\n\nBatch Normalization включает два обучаемых параметра: $\\gamma$ (масштаб) и $\\beta$ (сдвиг). После нормализации по формуле выше, нормализованные значения масштабируются и сдвигаются:\n$y_i = \\gamma \\hat{x}_i + \\beta$\nЭти параметры обучаются вместе с остальными весами модели, позволяя адаптировать нормализацию для оптимальной производительности.\n### Накапливаемые статистики\nВо время обучения Batch Normalization отслеживает:\n- **Среднее значение ($\\mu_{\\text{running}}$)**: скользящее среднее по всем мини-батчам.\n- **Дисперсия ($\\sigma^2_{\\text{running}}$)**: скользящее среднее дисперсий всех мини-батчей.\nЭти статистики используются на этапе инференса (прогнозирования), чтобы нормализация была стабильной даже при подаче отдельных примеров или данных, отличающихся от обучающего набора.\n$\\mu_{global} \\leftarrow \\alpha \\cdot \\mu_{global} + (1 - \\alpha) \\cdot \\mu_{batch}$\n$\\sigma^2_{global} \\leftarrow \\alpha \\cdot \\sigma^2_{global} + (1 - \\alpha) \\cdot \\sigma^2_{batch}$\nгде $\\alpha$ — коэффициент сглаживания.\n## Пример реализации BatchNorm в PyTorch\n\n```python\nimport torch.nn as nn\n\nbatch_norm = nn.BatchNorm1d(num_features=10)\n\ninput_tensor = torch.randn(8, 10)  # батч размером 8, 10 признаков\noutput_tensor = batch_norm(input_tensor)\n```\n## Устройство Layer Normalization\nLayer Normalization нормализует значения по всем признакам внутри одного объекта, вместо использования статистик батча. \n\nФормула:\n$$\n\\hat{x}_i = \\frac{x_i - \\mu_{layer}}{\\sqrt{\\sigma^2_{layer} + \\epsilon}}\n$$\nгде $\\mu_{layer}$ и $\\sigma^2_{layer}$ вычисляются для каждого объекта индивидуально:\n$$\n\\mu_{layer} = \\frac{1}{H} \\sum_{j=1}^H x_j, \\quad \\sigma^2_{layer} = \\frac{1}{H} \\sum_{j=1}^H (x_j - \\mu_{layer})^2\n$$\nгде H — количество признаков.\n\n### Обучаемые параметры\nLayer Normalization включает два обучаемых параметра: $\\gamma$ (масштаб) и $\\beta$ (сдвиг). После нормализации по формуле выше, нормализованные значения масштабируются и сдвигаются:\n$y_i = \\gamma \\hat{x}_i + \\beta$\nЭти параметры позволяют модели адаптировать нормализованные данные, чтобы восстановить необходимые масштабы и смещения (не обратное действие, а другое, удобное для обучения преобразование). Обучаемые параметры $\\gamma$ и $\\beta$ имеют ту же размерность, что и входные признаки, и оптимизируются вместе с остальными параметрами сети в процессе обучения.\n## Пример реализации LayerNorm в PyTorch\n```python\nimport torch.nn as nn\n\nlayer_norm = nn.LayerNorm(normalized_shape=10)\n\ninput_tensor = torch.randn(8, 10)  # батч размером 8, 10 признаков\noutput_tensor = layer_norm(input_tensor)\n```\n## Устройство RMS Normalization\n\nRMS Normalization (Root Mean Square Normalization) нормализует значения внутри одного объекта, используя корень среднего квадрата (Root Mean Square) вместо среднего и дисперсии. Это упрощает вычисления, сохраняя основные преимущества нормализации.\n\nФормула:\n$\\hat{x}_i = \\frac{x_i}{\\sqrt{\\text{RMS}^2 + \\epsilon}}$\nгде $\\text{RMS}$ (корень среднего квадрата) вычисляется для каждого объекта индивидуально:\n$\\text{RMS} = \\sqrt{\\frac{1}{H} \\sum_{j=1}^H x_j^2}$\nгде $H$ — количество признаков.\n### Обучаемые параметры\nRMS Normalization включает один обучаемый параметр: $\\gamma$ (масштаб). После нормализации по формуле выше нормализованные значения масштабируются:\n$y_i = \\gamma \\hat{x}_i$\nПараметр $\\gamma$ позволяет модели адаптировать масштаб нормализованных данных для лучшей производительности. В отличие от Layer Normalization, RMSNorm обычно не включает параметр сдвига ($\\beta$). Обучаемый параметр $\\gamma$ имеет ту же размерность, что и входные признаки, и оптимизируется вместе с остальными параметрами сети в процессе обучения.\n## Пример реализации RMSNorm в PyTorch\n```python\nimport torch.nn as nn\n\n\nrms_norm = nn.RMSNorm([8, 10])\n\ninput_tensor = torch.randn(8, 10)  # батч размером 8, 10 признаков\noutput_tensor = rms_norm(input_tensor)\n```"
    },
    "14. Многослойные сети. Граф потока вычислений. Класс nn.Module в PyTorch - назначение, основные поля и методы": {
        "markdown": "## Многослойные сети\nМногослойные нейронные сети состоят из нескольких слоев нейронов, где каждый слой передает результаты вычислений следующему. Основная идея — выучить сложные функции за счет композиции нелинейных преобразований.\n## Граф потока вычислений\nГраф потока вычислений описывает последовательность операций, выполняемых над входными данными. Узлы графа представляют операции, а рёбра — данные, передаваемые между ними. В PyTorch граф строится динамически во время выполнения программы, что позволяет использовать переменные, условия и циклы.\nПример:\n- Узлы: операции (свертка, ReLU, матричное умножение).\n- Рёбра: тензоры, передаваемые между узлами.\n## Класс nn.Module в PyTorch\n### Назначение\nКласс nn.Module является базовым для всех нейронных сетей в PyTorch. Он позволяет:\n1. Определять архитектуру модели.\n2. Управлять параметрами модели.\n3. Удобно организовывать слои и операции.\n### Основные поля\n1. **parameters**: возвращает все обучаемые параметры модели.\n2. **buffers**: хранит тензоры тензоры, которые не являются параметрами (например, статистики BatchNorm).\n3. **children**: возвращает дочерние модули (например, отдельные слои).\n### Основные методы\n1. **forward(self, input)**: определяет, как данные проходят через модель. Его нужно переопределять.\n2. **train(self, mode=True)**: переключает модель в режим обучения или тестирования.\n3. **eval(self)**: включает режим тестирования (например, отключает Dropout).\n4. **state_dict()**: возвращает параметры и буферы модели для сохранения.\n5. **load_state_dict(state_dict)**: загружает сохранённые параметры и буферы.\n6. **to(device)**: переводит модель на указанный девайс (CPU/GPU).\n### Пример использования\nimport torch\nimport torch.nn as nn\n\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(10, 20)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(20, 1)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        return self.fc2(x)\n# Создание и использование модели\nmodel = SimpleNN()\ninput_data = torch.randn(5, 10)  # 5 объектов, 10 признаков\noutput = model(input_data)\n"
    },
    "15. Специфика задач машинного обучения на изображениях. Принцип работы сверточных сетей. Преимущества сверточных сетей при решении этих задач": {
        "markdown": "## Специфика задач машинного обучения на изображениях\n- Задачи включают классификацию, сегментацию, детекцию объектов, генерацию изображений.\n- Особенность: высокая размерность данных, пространственные зависимости, разнообразие форматов.\n## Принцип работы сверточных сетей\n- Используют сверточные операции для извлечения признаков.\n- Применяются фильтры (ядра), которые сканируют изображение, создавая карты признаков.\n- Основные компоненты: сверточные слои, пулинговые слои (уменьшают размер), полносвязные слои (для классификации).\n- Обучение фильтров осуществляется методом градиентного спуска.\n![[Pasted image 20250106173723.png]]\nГлавным здесь является то, что при использовании свёрток мы даём нашей сети bias (изначальную установку) о пространственном взаимодействии пикселей внутри какого-либо квадрата (размера ядра свёртки)\n## Преимущества сверточных сетей при решении задач\n- Учитывают пространственную структуру изображения.\n- Сокращают количество параметров за счет использования фильтров.\n- Обеспечивают инвариантность к сдвигам, масштабам и другим трансформациям (за счёт последовательный комбинации свёрточных и пулинг слоёв).\n- Эффективны при обработке больших изображений.\n"
    },
    "16. Архитектура многослойной ИНС распознавания изображений на основе сверточных сетей. Сверточные слои (Convolution Layers) и сжимающие слои (Pooling Layers) в PyTorch": {
        "markdown": "## Архитектура многослойной ИНС для распознавания изображений\nСостоит из сверточных, сжимающих и полносвязных слоев. Основные этапы:\n1. Извлечение признаков через сверточные слои.\n2. Уменьшение размерности данных с помощью сжимающих (pooling) слоев.\n3. Принятие решения в полносвязных слоях.\n## Сверточные слои (Convolution Layers)\n- Выполняют свертку входных данных с ядром для выделения признаков.\n- Параметры: число каналов, размер ядра, шаг (stride), паддинг (padding).\n- Формула размерности выхода:\n$$\nO = \\frac{(W - K + 2P)}{S} + 1\n$$\nгде W — размер входа, K — размер ядра, P — паддинг, S — шаг.\n\nПример использования:\n```python\nimport torch\nimport torch.nn as nn\n\nconv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\noutput = conv_layer(torch.randn(1, 3, 64, 64))  # Входной тензор: батч, каналы, высота, ширина\n```\n\n![[Pasted image 20250106174018.png]]\n## Сжимающие слои (Pooling Layers)\n- Уменьшают размерность данных, сохраняя ключевые признаки.\n- Виды: max pooling (максимальное значение) и average pooling (среднее значение).\nПример использования:\n\n```python\npool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\npooled_output = pool_layer(output)\n```\n![[Pasted image 20250106174039.png]]"
    },
    "17. Приемы для глубокого обучения на небольших наборах изображений": {
        "markdown": "## Увеличение данных (Data Augmentation)\nПрименение различных преобразований изображений для увеличения размера обучающего набора: повороты, отражения, обрезка, изменение яркости.\n\nПример в PyTorch:\n```python\nfrom torchvision import transforms\n\naugmentation = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2)\n])\n```\n## Использование предобученных моделей\nИнициализация весов из моделей, обученных на больших наборах данных, с последующей настройкой (fine-tuning) или заморозкой начальных слоев.\n\nПример в PyTorch:\n```python\nfrom torchvision import models\n\nmodel = models.resnet18(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False  # Заморозить слои\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)  # Замена выходного слоя\n```\n## Регуляризация\nПрименение dropout, L1 или L2-регуляризации для предотвращения переобучения на малом датасете.\n\nПример Dropout в PyTorch:\n```python\nimport torch.nn as nn\n\ndropout = nn.Dropout(p=0.5)\noutput = dropout(input_tensor)\n```\n## Ранняя остановка\nРанняя остановка — это метод предотвращения переобучения. \nВ процессе обучения, если ошибка (либо любая иная мера качества модели) на валидационной выборке перестает уменьшаться (или начинает расти) за какое-то количество (в формуле буква k) шагов, обучение прекращается. Это позволяет сохранить модель, которая лучше всего обобщает данные.\n\nФормально, если L — функция потерь на валидационной выборке, то обучение прекращается, когда:\n\n$$\nL_{\\text{val}}(t) < \\min \\{ L_{\\text{val}}(t-1), L_{\\text{val}}(t-2), \\dots, L_{\\text{val}}(t-k) \\}\n$$\n\nгде t — номер эпохи."
    },
    "18. Схема работы сверточной сети. Операции свертки, пулинга, общий вид сверточной сети для решения задачи классификации изображения": {
        "markdown": "## Схема работы сверточной сети\nСостоит из сверточных, сжимающих и полносвязных слоев. Основные этапы:\n1. Извлечение признаков через сверточные слои.\n2. Уменьшение размерности данных с помощью сжимающих (pooling) слоев.\n3. Принятие решения в полносвязных слоях.\n\n## Сверточные слои (Convolution Layers)\n- Выполняют свертку входных данных с ядром для выделения признаков.\n- Параметры: число каналов, размер ядра, шаг (stride), паддинг (padding).\n- Формула размерности выхода:\n$$\nO = \\frac{(W - K + 2P)}{S} + 1\n$$\nгде W — размер входа, K — размер ядра, P — паддинг, S — шаг.\n\nПример использования:\n```python\nimport torch\nimport torch.nn as nn\n\nconv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\noutput = conv_layer(torch.randn(1, 3, 64, 64))  # Входной тензор: батч, каналы, высота, ширина\n```\n\n![[Pasted image 20250106174018.png]]\n## Сжимающие слои (Pooling Layers)\n- Уменьшают размерность данных, сохраняя ключевые признаки.\n- Виды: max pooling (максимальное значение) и average pooling (среднее значение).\nПример использования:\n\n```python\npool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\npooled_output = pool_layer(output)\n```\n![[Pasted image 20250106174039.png]]\n## Общий вид сверточной сети\nСостоит из чередующихся слоев свертки и пулинга для выделения признаков, завершающихся полносвязными слоями для классификации.\n\nПример структуры сети:\n```python\nimport torch.nn as nn\n\nclass CNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(32 * 8 * 8, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\n```"
    },
    "19. Виды задач машинного обучения и постановка задачи обучения с подкреплением": {
        "markdown": "## Виды задач машинного обучения\n1. **Обучение с учителем**: модели обучаются на размеченных данных, где для каждого входного примера известен целевой ответ.\n   - Примеры: классификация, регрессия.\n2. **Обучение без учителя**: модели обучаются на неразмеченных данных, выявляя структуры или зависимости.\n   - Примеры: кластеризация, понижение размерности, поиск аномалий.\n3. **Обучение с подкреплением**: модель обучается через взаимодействие с окружающей средой, получая награды за правильные действия.\n## Постановка задачи обучения с подкреплением\nЗадача обучения с подкреплением формулируется как:\n1. **Агент** взаимодействует со **средой**.\n2. На каждом шаге агент выбирает действие, переводя среду в новое состояние.\n3. Агент получает **вознаграждение** (reward), которое он стремится максимизировать.\n4. Цель — найти оптимальную стратегию, которая максимизирует накопленное вознаграждение.\n\nФормально:\n$$\n\\max_\\pi \\mathbb{E}\\left[\\sum_{t=0}^\\infty \\gamma^t R_t \\mid \\pi\\right]\n$$\nгде π — стратегия, $R_t$ — вознаграждение на шаге t, γ — коэффициент дисконтирования. "
    },
    "20. Подходы к определению стратегии. Определение вознаграждения и дисконтированного вознаграждения. Q-функция и V-функция. Уравнение Беллмана для функции значения состояния": {
        "markdown": "В обучении с подкреплением стратегия ($\\pi$) определяет поведение агента, то есть правила выбора действий в каждом состоянии.\n## Подходы к определению стратегии\n1. **Детерминированная стратегия**: однозначно задает действие для каждого состояния.\n   $\\pi(s) = a$, точный выбор действия a в состоянии s. Примером такой стратегии будут стратегии, полученные с помощью Q-learning (всегда выбираем действие с максимальным Q значением)\n1. **Стохастическая стратегия**: определяет распределение вероятностей действий в каждом состоянии.\n   $\\pi(a | s)$, вероятность выбора действия a в состоянии s. Примером такой стратегии будут стратегии, полученные с помощью Policy Gradient (имеем распределение действий и семплируем из него)\n## Определение вознаграждения и дисконтированного вознаграждения\n- **Вознаграждение (R)**: значение, получаемое агентом за выполнение действия в определенном состоянии.\n- **Дисконтированное вознаграждение (G)**: сумма будущих вознаграждений с учетом коэффициента дисконтирования γ:\n  $$\n  G_t = \\sum_{k=0}^\\infty \\gamma^k R_{t+k}\n  $$\n  где γ ∈ [0, 1] регулирует вес будущих вознаграждений.\n\n## Q-функция и V-функция\n\n^a0e423\n\n- **V-функция (функция ценности состояния)**:\n  $$\n  V^\\pi(s) = \\mathbb{E}_\\pi \\left[ G_t \\mid s_t = s \\right]\n  $$\n  Ожидаемое дисконтированное вознаграждение, начиная из состояния s и следуя стратегии π.\n\n- **Q-функция (функция ценности состояния-действия)**:\n  $$\n  Q^\\pi(s, a) = \\mathbb{E}_\\pi \\left[ G_t \\mid s_t = s, a_t = a \\right]\n  $$\n  Ожидаемое дисконтированное вознаграждение, начиная из состояния s, выполняя действие a и далее следуя стратегии π.\n\nЕсли $Q^\\pi(s, a_1) > Q^\\pi(s, a_2)$, то выбор 1 действия приведёт к большему выигрышу. Это свойство позволяет агенту приоритизировать свои действия во время обучения\n## Уравнение Беллмана для функции ценности состояния\nУравнение Беллмана связывает функцию ценности состояния с ожидаемыми вознаграждениями и следующими состояниями:\n$$\nV^\\pi(s) = \\mathbb{E}_\\pi \\left[ r_t + \\gamma V^\\pi(s_{t+1}) \\mid s_t = s \\right]\n$$\nДля Q-функции уравнение Беллмана выглядит так:\n$$\nQ^\\pi(s, a) = \\mathbb{E}_\\pi \\left[ r_t + \\gamma Q^\\pi(s_{t+1}, a_{t+1}) \\mid s_t = s, a_t = a \\right]\n$$\nгде $r_t$ - ожидаемое вознаграждение,\n$\\gamma V^\\pi(s_{t+1})$ или $\\gamma Q^\\pi(s_{t+1}, a_{t+1})$ - следующая дисконтированная ценность действия\nЭти уравнения используются для обучения и оценки стратегии."
    },
    "21. Метод Policy Gradient. Улучшения метода, общие принципы модели Actor-Critic": {
        "markdown": "### **Policy Gradient:**\nPolicy Gradient — это метод обучения с подкреплением, где стратегия ($\\pi_\\theta$) параметризуется нейронной сетью с параметрами $\\theta$, и обновление параметров осуществляется с помощью градиентного спуска для максимизации ожидаемого вознаграждения.\n#### **1. Целевая функция:**\nЦель Policy Gradient — максимизировать ожидаемое дисконтированное вознаграждение агента:\n$$\n\nJ(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\right],\n\n$$\nгде:\n- $\\pi_\\theta(a \\mid s)$: вероятность выбрать действие $a$ в состоянии $s$,\n- $r_t$: вознаграждение в момент времени $t$,\n- $\\gamma$: коэффициент дисконтирования ($0 \\leq \\gamma \\leq 1$).\n#### **2. Теорема Policy Gradient:**\nДля обновления параметров $\\theta$ используется градиент целевой функции $J(\\theta)$:\n$$\n\\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a_t \\mid s_t) G_t \\right],\n$$\nгде:\n- $\\log \\pi_\\theta(a_t \\mid s_t)$: логарифм вероятности выбранного действия $a_t$,\n- $G_t = \\sum_{k=0}^\\infty \\gamma^k r_{t+k}$: накопленное вознаграждение (return).\n#### **3. Обновление параметров:**\nПараметры $\\theta$ обновляются с помощью градиентного спуска:\n$$\n\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta J(\\theta),\n$$\n\nгде $\\alpha$ — скорость обучения.\n#### **4. Проблемы Policy Gradient и их решения:**\n1. **Высокая дисперсия градиентов:**\n   - Используются методы уменьшения дисперсии, например, центрирование $G_t$:\n     $$\n     \\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a_t \\mid s_t) (G_t - b) \\right],\n     $$\n     где $b$ — базовая линия (например, значение $V(s_t)$).\n2. **Стабильность обучения:**\n   - Для повышения стабильности используются продвинутые методы, такие как **Actor-Critic**.\n### **Actor-Critic:**\nActor-Critic — это усовершенствование Policy Gradient, где агент использует две модели:\n1. **Актёр (Actor):**\n   - Отвечает за стратегию ($\\pi_\\theta(a \\mid s)$).\n   - Используется для выбора действий.\n2. **Критик (Critic):**\n   - Оценивает действия с помощью функции ценности ($V(s)$) или $Q(s, a)$.\n   - Предоставляет обратную связь актёру.\n#### **1. Целевая функция:**\nActor-Critic также направлен на максимизацию ожидаемого вознаграждения:\n$$\nJ(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\right].\n$$\n#### **2. Градиент для актёра:**\nГрадиент стратегии (Actor) вычисляется аналогично Policy Gradient:\n$$\n\\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\pi_\\theta} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a_t \\mid s_t) A(s_t, a_t) \\right],\n$$\nгде:\n- $A(s_t, a_t)$: функция преимущества (Advantage Function), которая оценивает, насколько выбранное действие $a_t$ в состоянии $s_t$ лучше среднего уровня.\nФункция преимущества:\n$$\nA(s_t, a_t) = Q(s_t, a_t) - V(s_t),\n$$\nгде:\n- $Q(s_t, a_t)$: ожидаемая ценность пары (состояние-действие),\n- $V(s_t)$: ценность состояния.\n#### **3. Обучение критика:**\nКритик обучается аппроксимировать $V(s_t)$ (или $Q(s_t, a_t)$) ([[20. Подходы к определению стратегии. Определение вознаграждения и дисконтированного вознаграждения. Q-функция и V-функция. Уравнение Беллмана для функции значения состояния.#^a0e423|Q-функция и V-функция]]) с помощью MSE (Mean Squared Error):\n$$\nL(\\phi) = \\mathbb{E} \\left[ \\left( r_t + \\gamma V(s_{t+1}) - V(s_t) \\right)^2 \\right],\n$$\nгде:\n- $\\phi$: параметры модели критика.\n#### **4. Обновление параметров:**\n- **Актёр:** Параметры стратегии ($\\theta$) обновляются с использованием градиента:\n  $$\n  \\theta \\leftarrow \\theta + \\alpha_\\text{actor} \\nabla_\\theta J(\\theta).\n  $$\n\n- **Критик:** Параметры критика ($\\phi$) обновляются с использованием функции ошибки:\n  $$\n  \\phi \\leftarrow \\phi - \\alpha_\\text{critic} \\nabla_\\phi L(\\phi).\n  $$"
    },
    "22. Метод Q-Learning": {
        "markdown": "## Метод Q-Learning\nQ-Learning — это метод обучения с подкреплением, который используется для определения оптимальной стратегии путем приближения Q-функции.\n\n## Основное обновляющее правило\nQ-функция обновляется по следующему правилу:\n$$\nQ(s, a) \\leftarrow Q(s, a) + \\alpha \\left[ R(s, a) + \\gamma \\max_a Q(s', a) - Q(s, a) \\right]\n$$\nгде:\n- s, a — текущее состояние и действие,\n- R — вознаграждение за переход,\n- s' — новое состояние,\n- α — скорость обучения,\n- γ — коэффициент дисконтирования.\n\n## Алгоритм\n1. Инициализация Q-функции произвольными значениями.\n2. Для каждого эпизода:\n   - Выбор действия a в состоянии s (например, с использованием ε-жадной стратегии на первых шагах обучения для наилучшего исследования).\n   - Выполнение действия a и наблюдение нового состояния s' и вознаграждения r.\n   - Обновление Q(s, a) по правилу.\n   - Переход в новое состояние s'.\n3. Повторение до сходимости Q-функции.\n\n## Свойства\n- Метод не требует построению модели среды, агент напрямую взаимодействует с реальной средой\n- Гарантированно сходится к оптимальной Q-функции при достаточном исследовании состояния и действия.\n## Применение\nQ-Learning подходит для задач с дискретными пространствами состояний и действий. Для непрерывных пространств используется расширение, например Deep Q-Learning.\n"
    },
    "23. Типы задач машинного зрения, решаемые с помощью глубоких моделей. Архитектура VGG16, её преимущества и недостатки": {
        "markdown": "## Типы решаемых задач\n1. Классификация изображений\n2. Обнаружение объектов\n3. Сегментация изображений\n4. Распознавание лиц\n5. Детекция ключевых точек\n6. Генерация описаний изображений\n7. Стилизование изображений\n8. Улучшение качества изображений\n## VGG16\nАктуальность модели состоит в:\n- Применении маленьких свёрточных ядер (3 на 3) с большим количеством карт признаков\n- Большой глубине сети (16 слоёв, имеются более маленькие/большие версии сети)\nСама архитектура очень проста, содержит conv и pooling слои с dense(linear) на конце\nПлюсы:\n- Точность\n- Модульность (легко изменяется кол-во блоков)\n- Простота\nМинусы:\n- Большая размер (глубина) модели\n- Высокие вычислительные затраты и затраты по памяти\n![[Pasted image 20250106180900.png]]"
    },
    "24. Архитектура GoogLeNet, описание модуля Inception module, логика использования свертки 1x1 и использование DepthConcat в Inception module. Сравнение с другими архитектурами": {
        "markdown": "## Архитектура GoogLeNet\nGoogLeNet — это сверточная нейронная сеть, представленная для решения задачи классификации ImageNet. Она построена на основе модулей Inception и ориентирована на снижение вычислительной сложности при высокой производительности.\n\nОсновные характеристики:\n1. Глубокая сеть с 22 слоями.\n2. Использование модулей Inception для повышения эффективности.\n3. Дополнительные классификаторы для борьбы с проблемой затухающих градиентов.\n![[Pasted image 20250107143516.png]]\n## Описание Inception module\nInception module — это ключевая составляющая GoogLeNet, которая комбинирует сверточные и пуллинговые операции разного масштаба в одном модуле. \nСостав модуля:\n1. Свертки 1x1, 3x3 и 5x5 для извлечения признаков разного масштаба.\n2. MaxPooling 3x3 для обработки контекста.\n3. Объединение выходов всех операций с помощью DepthConcat (конкатенация результатов этих различных ядер, на картинке в красных овалах).\n## Логика использования свертки 1x1\n1. **Сокращение количества каналов**:\n   Свертка 1x1 используется перед большими фильтрами (3x3, 5x5) для уменьшения размерности по каналам, снижая итоговую вычислительную сложность.\n2. **Извлечение признаков**:\n   Обрабатывает каждый канал по отдельности, добавляя нелинейность через активацию. Например, чтобы из картинки 64 * 64 * 256 получить 64 * 64 * 5 нужно создать 5 свёрток 1 * 1 * 256 \n## Использование DepthConcat\nDepthConcat объединяет выходы всех операций Inception module по размерности каналов, создавая представление признаков, полученное из различных ядер. \nВ классическом примере объединяет параметры, полученные после свёрток: 1x1; 1x1 + 3x3; 1x1 + 5x5; maxpool + 1x1\n## Сравнение с другими архитектурами\n1. **ResNet**:\n   ResNet использует прямые соединения (skip connections), упрощая обучение глубоких сетей. GoogLeNet фокусируется на модулях Inception для снижения вычислительных затрат.\n2. **AlexNet**:\n   GoogLeNet глубже и эффективнее благодаря Inception module. AlexNet проще и требует больше вычислительных ресурсов на единицу параметров.\n3. **VGG**:\n   VGG имеет последовательную архитектуру с одинаковыми фильтрами, что делает ее более предсказуемой, но менее эффективной по вычислениям по сравнению с GoogLeNet.\n\nGoogLeNet балансирует глубину и эффективность, предлагая архитектуру с оптимизированным использованием вычислительных ресурсов."
    },
    "25. Архитектуры с residual connections, основные принципы residual connections. Нарушение симметрии глубоких ИНС с помощью residual connections. Сравнение с другими архитектурами": {
        "markdown": "## Архитектуры с residual connections\nResidual connections (остаточные связи) были представлены в ResNet. Они добавляют прямой путь между слоями через короткое соединение (skip connection), что помогает передавать информацию и градиенты на более глубокие слои.\n\nПример остаточной связи:\n$$\ny = F(x, W) + x\n$$\nгде F(x, W) — преобразование входа x с параметрами W, а x — входной сигнал, добавляемый напрямую.\n![[Pasted image 20250107143732.png]]\n![[Pasted image 20250107143940.png]]\n## Основные принципы residual connections\n1. **Обход нелинейностей**:\n   Прямое соединение добавляет **возможность** передавать входной сигнал напрямую, минуя сложные преобразования.\n2. **Улучшение обучения**:\n   Уменьшают проблему затухающих и взрывающихся градиентов, что облегчает обучение глубоких сетей из-за чего модели с residual connections достигают большей глубины (например, ResNet-152) без деградации точности.\n## Нарушение симметрии глубоких ИНС\n   В традиционных архитектурах преобразования между слоями часто симметричны, что ухудшает ландшафт функции потерь. Остаточные связи разрывают эту симметрию (так  как конкатенация не симметричная операция)\n## Сравнение с другими архитектурами\n1. **ResNet vs VGG**:\n   - ResNet глубже и требует меньше параметров.\n   - VGG строится на одинаковых блоках, что увеличивает сложность вычислений.\n2. **ResNet vs DenseNet**:\n   - DenseNet использует плотные соединения (соединяет каждый слой с каждым), что требует больше памяти.\n   - ResNet проще и более масштабируем.\n3. **ResNet vs AlexNet**:\n   - AlexNet меньше по глубине, хуже обобщает сложные признаки.\n   - ResNet эффективнее за счет использования residual connections.\n## Итог\nResidual connections стали ключевой концепцией для глубоких архитектур, позволяя моделям быть более глубокими, обучаемыми и устойчивыми. Они изменили подход к проектированию сетей, устранив многие проблемы традиционных архитектур. Данный подход применяется в трансформер блоках.\n"
    },
    "25. Типы задач машинного зрения, решаемые с помощью глубоких моделей. Архитектура VGG16, её преимущества и недостатки": {
        "markdown": "## Типы решаемых задач\n1. Классификация изображений\n2. Обнаружение объектов\n3. Сегментация изображений\n4. Распознавание лиц\n5. Детекция ключевых точек\n6. Генерация описаний изображений\n7. Стилизование изображений\n8. Улучшение качества изображений\n## VGG16\nАктуальность модели состоит в:\n- Применении маленьких свёрточных ядер (3 на 3) с большим количеством карт признаков\n- Большой глубине сети (16 слоёв, имеются более маленькие/большие версии сети)\nСама архитектура очень проста, содержит conv и pooling слои с dense(linear) на конце\nПлюсы:\n- Точность\n- Модульность (легко изменяется кол-во блоков)\n- Простота\nМинусы:\n- Большая размер (глубина) модели\n- Высокие вычислительные затраты и затраты по памяти"
    },
    "26. Архитектура UNet - общие принципы, описание архитектуры, использование residual connections и использование модели для решения задачи сегментации": {
        "markdown": "## Общие принципы\nUNet — это архитектура для задач сегментации изображений, которая используется для предсказания пиксельных меток. Она основана на симметричной структуре, состоящей из нисходящей (encoder) и восходящей (decoder) частей, а также Skip Connections между ними\n## Описание архитектуры\n1. **Encoder**:\n   - Состоит из нескольких уровней сверток, за которыми следуют операции пуллинга.\n   - Извлекает пространственные и контекстуальные признаки из входного изображения.\n2. **Decoder**:\n   - Восстанавливает исходное разрешение изображения, применяя транспонированные свертки (up-convolutions).\n   - Использует пропущенные связи (skip connections) для объединения характеристик из encoder.\n3. **Skip Connections**:\n   - Соединяют слои encoder и decoder для передачи информации о мелких деталях.\n   - Это помогает модели лучше справляться с задачами, где важны границы объектов.\n\nИтоговый результат имеет ту же размерность, что и входное изображение, но включает предсказания для каждого пикселя.\n![[Pasted image 20250107144128.png]]\n## Использование residual connections\nResidual connections можно внедрить в UNet для улучшения потоков градиентов. Для каждого уровня encoder и decoder добавляется остаточная связь:\n\n$$\nx_{\\text{out}} = F(x_{\\text{in}}) + x_{\\text{in}}\n$$\n\nгде F — преобразование, включающее свертки и активации. Это ускоряет обучение и стабилизирует процесс оптимизации.\n## Использование для сегментации\nUNet используется для сегментации медицинских изображений, дорожных сцен, спутниковых данных и других областей. Модель предсказывает метку для каждого пикселя, например, классифицирует области как здоровые или пораженные. Благодаря skip connections и симметричной архитектуре, она достигает высокой точности на задачах с ограниченным количеством данных.\nТакже эта модель используется для обратной диффузии, но сейчас всё чаще заменяется моделями на основе трансформеров."
    },
    "27. Подходы к использованию механизма внимания в глубоких моделях машинного зрения. Механизмы и логика использования метода Grad-CAM в глубоких моделях машинного зрения": {
        "markdown": "## **Подходы к использованию механизма внимания в глубоких моделях машинного зрения:**\n\n1. **Внимание в сверточных нейронных сетях (CNN):**\n   - Механизмы внимания интегрируются в CNN для выделения значимых областей изображения, что повышает точность задач, таких как обнаружение объектов и сегментация. \n   - Вычленение признаков происходит с помощью свёрточных ядер и пуллинга, а затем обработку полученной информации берут на себя attention блоки\n  Пример - Residual Attention Network:\n![[Pasted image 20250107160002.png]]\n2. **Трансформеры в компьютерном зрении:**\n   - Архитектуры, основанные на механизме внимания, такие как Vision Transformers (ViT), обрабатывают изображения, разбивая их на патчи и применяя механизм внимания для моделирования глобальных зависимостей между различными частями изображения.\n[[28. Применение модуля Transformer в компьютерном зрении. Архитектура SWIN.|Подробнее]]\n\n## **Механизмы и логика использования метода Grad-CAM (Gradient-weighted Class Activation Mapping) в глубоких моделях машинного зрения:**\n1. **Применение Grad-CAM:**\n   - **Интерпретация модели:** Grad-CAM помогает понять, на какие части изображения модель обращает внимание при классификации, что повышает доверие к её решениям.\n   - **Диагностика ошибок:** Анализ тепловых карт Grad-CAM позволяет выявлять случаи, когда модель фокусируется на нерелевантных областях, что может указывать на необходимость дообучения или изменения архитектуры.\n   - **Обнаружение смещения:** Grad-CAM может выявлять предвзятость модели, показывая, если она основывает свои решения на неподходящих признаках.\n2. **Логика работы Grad-CAM:**\n   - Метод вычисляет градиенты вероятности целевого класса по отношению к активациям выбранного сверточного слоя.\n   - Эти градиенты используются для взвешивания активаций, определяя вклад каждого нейрона в предсказание.\n   - Взвешенные активации суммируются и проходят через функцию ReLU, чтобы получить окончательную карту активации класса, которая затем накладывается на исходное изображение для визуализации.\n## Примеры работы:\n ![[Pasted image 20250107160739.png]]\n![[Pasted image 20250107160651.png]]"
    },
    "28. Применение модуля Transformer в компьютерном зрении. Архитектура SWIN": {
        "markdown": "## Применение Transformer в компьютерном зрении (классическая ViT архитектура)\n1. Изображение делится на патчи (стандартная архитектура ViT), путём разбиения исходного изображения на квадраты.\n   Например, в исходной статье для 224 x 224 использовали патчи 14 x 14 (их получилось 16 x 16 штук)\n2. Затем полученные патчи развёртываются в одномерный вектор, преобразуются в эмбеддинги через прохождение сквозь начальные линейные слои\n3. Также используются эмбеддинги патчей (то есть их позиционное кодирование), чтобы добавить информацию об месте патча на исходной картинке\n4. После всех этапов кодирования в обычные трансформер блоки подаются векторы размерности (batch size, number of patches, embedding dimension)\n![[Pasted image 20250107144318.png]]\n## Архитектура SWIN\n\nSWIN Transformer обрабатывает изображение через **иерархическую архитектуру**\n1. Изображение разбивается на патчи (в исходной статье это 4x4, что меньше чем в ViT, ось цвета (каналов), также развёртывается), пиксели преобразуются в эмбеддинги также как в ViT\n2. Полученные патчи разбиваются на группы (7 на 7 патчей в каждой, тогда в исходной архитектуре выйдет 64 окна)\n3. Используются только блоки локального внимания. То есть не взаимодействие всех патчей со всеми, а только внутри групп со второго шага\n   Есть два вида блоков локального внимания:\n\t1. Обычный\n\t2. Со сдвигом сетки разбиения патчей. Нужен для взаимодействия патчей друг с другом, но взаимодействие между группами НЕ происходит из-за маскирования\n4. Путём конкатенации групп патчей 2 x 2 в 1 патч, из-за чего размерность эмбеддингов увеличивается в 4 раза.\n5. Шаги 3 и 4 повторяются по глубине сети. С каждой глубиной патчи увеличиваются и несут в себе всё более верхнеуровневые представления.\n![[Pasted image 20250107144605.png]]\n## Разница\n![[Pasted image 20250107144649.png]]\nВ ViT разбиение на патчи происходить 1 раз, а в SWiN в шаге 4 они объединяются в патчи всё большего размера с увеличением глубины сети"
    },
    "29. Векторная интерпретация весов скрытого слоя многослойного перцептрона. Задача восстановления входного сигнала после сжатия в скрытом слое ИНС": {
        "markdown": "В многослойном перцептроне (MLP) веса скрытого слоя можно интерпретировать как векторы в пространстве входных признаков. \nКаждый нейрон скрытого слоя имеет свой вектор весов, определяющий направление в пространстве входных данных, на которое нейрон наиболее чувствителен. \nИными словами, веса нейрона определяют гиперплоскость, разделяющую входное пространство на области, которые нейрон активирует по-разному.\n## Задача восстановления входного сигнала после сжатия в скрытом слое ИНС\nДля этой цели используется архитектура, известная как автоэнкодер. \nАвтоэнкодер состоит из двух основных частей: энкодера и декодера.\n Энкодер сжимает входной сигнал в представление меньшей размерности в скрытом слое, а декодер восстанавливает исходный сигнал из этого сжатого представления. \n В процессе обучения автоэнкодер минимизирует разницу между входным и восстановленным сигналами, что позволяет ему эффективно кодировать и декодировать данные.\n\nВ процессе сжатия и последующего восстановления входного сигнала автоэнкодер обучается выделять наиболее значимые характеристики данных, отбрасывая избыточную информацию. Это позволяет использовать автоэнкодеры для задач уменьшения размерности, устранения шума и генерации новых данных, схожих с обучающими.\nВеса скрытого слоя в автоэнкодере определяют, какие аспекты входного сигнала сохраняются при сжатии, а какие отбрасываются, что напрямую влияет на качество восстановления сигнала."
    },
    "30. Автоэнкодеры. Линейный автоэнкодер и его аналог в статистических методах. Нелинейные и глубокие автоэнкодеры. Области значений латентного пространства": {
        "markdown": "Примеры интерполяции и экстраполяции на многообразиях области значений латентных пространств автоэкодеров\n\n## Автоэнкодеры\nАвтоэнкодеры — это нейронные сети, обучающиеся воспроизводить свои входные данные на выходе. Они состоят из двух основных компонентов: энкодера, который сжимает входные данные в латентное пространство меньшей размерности, и декодера, восстанавливающего данные из этого пространства.\n\n## **Линейный автоэнкодер и метод главных компонент (PCA) (аналог в статистических методах):**\nЛинейный автоэнкодер, использующий линейные функции активации и минимизирующий среднеквадратичную ошибку, по сути, выполняет задачу, аналогичную методу главных компонент (PCA). Оба метода стремятся найти линейное подпространство меньшей размерности, которое максимально сохраняет дисперсию исходных данных. Однако автоэнкодеры могут обучать неортогональные (перпендикулярные) базисы, в отличие от PCA, где главные компоненты ортогональны.\n![[Pasted image 20250107150050.png]]\nВидно, что PCA плохо работает с нелинейными функциями\n![[Pasted image 20250107150032.png]]\n## **Нелинейные и глубокие автоэнкодеры:**\nНелинейные автоэнкодеры используют нелинейные функции активации, что позволяет им моделировать сложные, нелинейные зависимости в данных. Глубокие автоэнкодеры состоят из нескольких слоев в энкодере и декодере, что увеличивает их способность захватывать сложные структуры данных и выявлять скрытые представления более высокого уровня.\n\n## **Латентное пространство:**\nЛатентное пространство — это пространство меньшей размерности, в которое энкодер преобразует входные данные. Оно содержит сжатые представления, сохраняющие наиболее существенные характеристики исходных данных. Структура латентного пространства отражает внутренние зависимости и структуры в данных (которые могут быть проанализированы человеком в малой размерности), что делает его полезным для задач визуализации, кластеризации и генерации новых данных.\n\n## **Интерполяция в латентном пространстве**:\nИнтерполяция в латентном пространстве позволяет создавать новые данные, плавно переходя от одного образца к другому. Например, в случае автоэнкодера, обученного на изображениях рукописных цифр, можно взять латентные представления двух разных цифр и линейно интерполировать между ними. Декодируя промежуточные точки, мы получим изображения, постепенно переходящие от одной цифры к другой, демонстрируя способность модели генерировать новые, осмысленные данные.\n## **Пример интерполяции**:\nРассмотрим автоэнкодер, обученный на наборе данных MNIST, содержащем изображения рукописных цифр от 0 до 9. Выберем два латентных вектора: один, соответствующий цифре \"2\", и другой — цифре \"0\". Выполнив линейную интерполяцию между этими векторами и декодируя полученные промежуточные векторы, мы можем наблюдать постепенное преобразование изображения \"2\" в \"0\". Это демонстрирует, как автоэнкодер может генерировать плавные переходы между различными классами данных.\n## **Экстраполяция в латентном пространстве**:\nЭкстраполяция предполагает выход за пределы известных данных в латентном пространстве. Однако, в отличие от интерполяции, экстраполяция может приводить к менее предсказуемым или даже бессмысленным результатам, поскольку модель не обучалась на таких данных. Поэтому экстраполяция в латентном пространстве автоэнкодеров используется реже и требует осторожности.\n## **Пример экстраполяции**:\nПродолжая предыдущий пример с цифрами \"2\" и \"0\", если мы будем экстраполировать за пределы этих латентных векторов, то есть выходить за диапазон значений, используемых при обучении, декодер может генерировать изображения, не соответствующие никаким реальным цифрам. Это подчеркивает ограниченность модели в генерации осмысленных данных при экстраполяции.\n\nПервый пример (Manifold interpolation), является примером интерполяции. Он показывает плавный переход от 2 к 0, где посреди перехода мы попали в векторное представление цифры 6\n\nВторой пример (Linear interpolation), можно считать примером экстраполяции так как взято среднее между векторами, которое не соответствует никакой цифре, из-за чего получившийся результат не является особо осмысленным.\n![[Pasted image 20250107150702.png]]"
    },
    "31. Задачи дискриминативных и генеративных моделей, сравнение моделей. Классификация генеративных моделей": {
        "markdown": "Прикладные задачи для генеративных моделей в области компьютерного зрения.\n## Задачи дискриминативных моделей\n1. Классификация данных.\n2. Прогнозирование меток $y$ на основе входных данных $x$.\n3. Пример: логистическая регрессия, SVM, ResNet.\n## Задачи генеративных моделей\n1. Изучение распределения $p(x)$ или $p(x, y)$.\n2. Генерация новых данных, похожих на реальные.\n3. Пример: VAE, GAN, PixelCNN, diffusion models\n## Сравнение моделей\n1. **Дискриминативные модели**:\n   - Предсказывают $p(y|x)$.\n   - Ориентированы на классификацию и регрессию.\n   - Архитектурно более просты, не моделируют данные полностью, используют их сжатые внутренние представления.\n2. **Генеративные модели**:\n   - Строят $p(x)$ или $p(x, y)$.\n   - Могут быть использованы для генерации новых изображений, заполнения пропусков.\n   - Архитектурно сложнее, но дают более богатое представление данных.\n## Классификация генеративных моделей\n1. **Латентные вероятностные модели**:\n   - **Вариационные Автоэнкодеры (VAE)**: Модели, которые обучаются представлять данные в латентном пространстве, позволяя генерировать новые образцы путем выборки из этого пространства.\n   - **Гауссовские Смеси (Gaussian Mixture Models, GMM)**: Модели, представляющие данные как смесь нескольких гауссовских распределений, что позволяет моделировать сложные распределения данных.\n2. **Модели с явным распределением**:\n   - **PixelCNN**: Авторегрессионная модель, предсказывающая вероятность каждого пикселя изображения на основе предыдущих, что позволяет генерировать изображения по одному пикселю за раз.\n   - **PixelRNN**: Аналогична PixelCNN, но использует рекуррентные нейронные сети для моделирования зависимости между пикселями.\n3. **Модели с неявным распределением**:\n   - **Генеративно-Состязательные Сети (GAN)**: Состоят из генератора и дискриминатора, обучающихся совместно; генератор создает данные, стремясь обмануть дискриминатор, который пытается отличить реальные данные от сгенерированных.\n4. **Авторегрессионные модели**:\n   - **Transformer**: Модель, основанная на механизме внимания, способная моделировать последовательности данных и генерировать новые последовательности, учитывая контекст предыдущих элементов.\n5. **Нормализующие потоки (Normalizing Flows)**:\n   - Модели, которые преобразуют простое распределение в сложное с помощью последовательности обратимых и дифференцируемых преобразований, позволяя точно вычислять вероятность и эффективно генерировать новые данные.\n6. **Диффузионные модели**:\n   - Модели, которые обучаются генерировать данные путем постепенного добавления и удаления шума, что позволяет получать высококачественные сэмплы, особенно в области генерации изображений.\n## Прикладные задачи для генеративных моделей в области компьютерного зрения\n**1. Генерация фотореалистичных изображений**\n- **Задача**: Создание новых изображений, неотличимых от реальных фотографий, для применения в искусстве, развлечениях и виртуальной реальности.\n- **Архитектура**: Генеративно-состязательные сети (GAN) и диффузионные модели.\n**2. Повышение разрешения изображений (Super-Resolution)**\n- **Задача**: Увеличение разрешения низкокачественных изображений для улучшения их детализации.\n- **Архитектура**: Super-Resolution GAN (SRGAN) .\n**3. Удаление шума с изображений (Denoising)**\n- **Задача**: Очистка изображений от шумов для повышения их качества.\n- **Архитектура**: Вариационные автокодировщики (VAE) и диффузионные модели.\n**4. Аугментация данных**\n- **Задача**: Генерация новых вариантов существующих данных для расширения обучающего набора и повышения устойчивости моделей.\n- **Архитектура**: Генеративно-состязательные сети (GAN) и автокодировщики (AE) .\n**5. Сегментация и аннотация изображений**\n- **Задача**: Разделение изображения на смысловые части и автоматическая аннотация для упрощения анализа.\n- **Архитектура**: U-Net и его вариации.\n**6. Генерация изображений по текстовым описаниям**\n- **Задача**: Создание изображений на основе текстовых описаний, что полезно в дизайне и рекламе.\n- **Архитектура**: диффузионные модели, их трансформерные вариации.\n**7. Восстановление изображений (Inpainting)**\n- **Задача**: Заполнение отсутствующих или поврежденных частей изображения для его восстановления.\n- **Архитектура**: Генеративно-состязательные сети (GAN) с соответствующими модификациями.\n**8. Стилистическая трансформация изображений (Style Transfer)**\n- **Задача**: Изменение стиля изображения при сохранении его содержимого, что используется в искусстве и дизайне.\n- **Архитектура**: Модели на основе сверточных нейронных сетей (CNN) и диффузионных моделей.\n**9. Создание 3D-моделей из 2D-изображений**\n- **Задача**: Генерация трехмерных моделей на основе двухмерных изображений для применения в робототехнике и дополненной реальности.\n- **Архитектура**: Комбинация сверточных нейронных сетей (CNN) и диффузионных моделей.\n"
    },
    "32. Архитектура GAN - описание общей архитектуры, модели обучения и архитектур глубоких моделей в GAN": {
        "markdown": "## Общая архитектура GAN\nGAN (Generative Adversarial Network) состоит из двух нейронных сетей:\n1. **Генератор (Generator)**:\n   - Генерирует новые данные из случайного шума.\n   - Цель: обучиться создавать данные, похожие на реальные.\n2. **Дискриминатор (Discriminator)**:\n   - Классифицирует входные данные как реальные или сгенерированные.\n   - Цель: уметь отличать реальные данные от сгенерированных.\n\nОбе сети соревнуются: генератор пытается обмануть дискриминатор, а дискриминатор стремится точнее различать данные.\n## Модель обучения\nGAN обучается с помощью минимакс-игры:\n$$\n\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log (1 - D(G(z)))]\n$$\nгде:\n- $D(x)$ — вероятность того, что $x$ реально.\n- $G(z)$ — данные, сгенерированные генератором из шума $z$.\n- $p_{data}$ — распределение реальных данных.\n- $p_z$ — распределение шума.\nАлгоритм обучения:\n1. Обновляем дискриминатор для повышения точности различения реальных и сгенерированных данных.\n2. Обновляем генератор для обмана дискриминатора.\n## Архитектуры глубоких моделей в GAN\n1. **Классический GAN**:\n   - Использует полносвязные и сверточные слои для генерации и дискриминации.\n2. **DCGAN (Deep Convolutional GAN)**:\n   - Заменяет полносвязные слои сверточными, улучшая качество генерации.\n   - Применяет BatchNorm и ReLU для стабильности.\n3. **WGAN (Wasserstein GAN)**:\n   - Использует расстояние Васерштейна для улучшения сходимости.\n   - Устраняет проблемы с коллапсом генератора.\n4. **Conditional GAN (cGAN)**:\n   - Генерация данных с учетом условий (например, меток классов).\n5. **StyleGAN**: \n- Использует многомерный латентный вектор для раздельного управления разными аспектами изображения (например, управления стилем).\n## Обучение на примере одномерной функции распределения\nРассмотрим задачу аппроксимации одномерного распределения данных, например, нормального распределения $p_{data} \\sim \\mathcal{N}(0, 1)$:\n1. **Инициализация**:\n   - Генератор принимает на вход шум $z$ из простого распределения (например, равномерного).\n   - Генератор преобразует шум $z$ в данные $x = G(z)$.\n   - Дискриминатор оценивает вероятность того, что данные являются реальными.\n2. **Целевая функция**:\n   Обучение идет по функции:\n   $$\n   \\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]\n   $$\n\n3. **Шаги обучения**:\n   - **Обновление дискриминатора**:\n     Оптимизируем $D$, чтобы увеличить вероятность правильной классификации реальных и сгенерированных данных.\n   - **Обновление генератора**:\n     Оптимизируем $G$, чтобы минимизировать способность дискриминатора отличать сгенерированные данные от реальных.\n4. **Постепенная сходимость**:\n   - Дискриминатор становится лучше в отличении данных, обучая генератор.\n   - Генератор начинает приближать распределение $p_{data}$."
    },
    "33. Модель вариационного автоэнкодера (VAE) - общие и специфические цели модели, общая архитектура модели и баейсовское моделирование": {
        "markdown": "Функция потерь VAE и специфика получаемых скрытых представлений.\n\n## Общие и специфические цели модели VAE\n1. **Общие цели**:\n   - Создание компактных скрытых представлений данных.\n   - Генерация новых данных, похожих на обучающие.\n2. **Специфические цели**:\n   - Явное моделирование вероятностного распределения данных.\n   - Регуляризация скрытого пространства для интерпретируемости и непрерывности.\n## Общая архитектура модели\n1. **Энкодер**:\n   - Преобразует входные данные $x$ в параметры распределения скрытого представления $z$: $\\mu(x)$ и $\\sigma^2(x)$.\n2. **Декодер**:\n   - Генерирует данные $\\hat{x}$ из выборки $z$, взятой из распределения, определяемого энкодером.\n3. **Скрытое пространство**:\n   - $z$ моделируется как латентное пространство, которое должно быть приближено к заранее заданному распределению (обычно $\\mathcal{N}(0, 1)$).\n## [[34. Модель вариационного автоэнкодера (VAE) - баейсовское моделирование|Баейсовское моделирование]]\n## Функция потерь VAE\nФункция потерь состоит из двух частей:\n1. **Реконструкция**:\n   - Сравнивает исходные данные $x$ с реконструированными $\\hat{x}$:\n     $$\n     \\mathbb{E}_{q(z|x)}[\\log p(x|z)]\n     $$\n2. **КЛ-дивергенция**:\n   - Минимизирует расхождение между $q(z|x)$ и $p(z)$:\n     $$\n     \\text{KL}(q(z|x) || p(z)) = \\int q(z|x) \\log \\frac{q(z|x)}{p(z)} dz\n     $$\nИтоговая функция потерь:\n$$\n\\mathcal{L}_{VAE} = - \\mathbb{E}_{q(z|x)}[\\log p(x|z)] + \\text{KL}(q(z|x) || p(z))\n$$\n## Специфика скрытых представлений\n1. **Непрерывность**:\n   - Близкие точки в скрытом пространстве $z$ соответствуют похожим данным.\n2. **Семантическая интерпретируемость**:\n   - Скрытые переменные обучаются на распределении, чтобы отражать важные факторы изменчивости данных, что и помогает хорошо генерировать новые данные.\n3. **Сглаженность**:\n   - Скрытое пространство приближает нормальное распределение, что делает генерацию стабильной."
    },
    "34. Модель вариационного автоэнкодера (VAE) - баейсовское моделирование": {
        "markdown": ", функция ошибки на основе метода максимального правдоподобия, причины построения ELBO и метод построения этой оценки.\n\n## Баейсовское моделирование в VAE\n$x_1, x_2, \\ldots, x_n$ — это наблюдаемые данные из обучающего набора.\n$z_i$ — это скрытые (или латентные) переменные, соответствующие каждому $x_i$.\nВариационные автоэнкодеры (VAE) предполагают, что данные $x$ и скрытые переменные $z$ связаны через совместное распределение:\n  $$\n  p(x, z) = p(x|z) p(z),\n  $$\n  где:\n  - $p(z)$: априорное распределение латентных переменных. Обычно это стандартное нормальное распределение $\\mathcal{N}(0, I)$.\n  - $p(x|z)$: вероятность наблюдения данных $x$, если латентные переменные $z$ заданы. Эта вероятность моделируется декодером.\nВ VAE цель — аппроксимировать апостериорное распределение $p(z|x)$ через вариационное приближение $q(z|x)$ и использовать его для генерации данных. Это основано на баейсовском подходе, где $p(x)$ выражается через интеграл:\n$$\np(x) = \\int p(x|z)p(z)dz\n$$\n## Функция ошибки на основе метода максимального правдоподобия\nОптимизация модели направлена на максимизацию логарифма правдоподобия данных:\n$$\n\\log p(x) = \\log \\int p(x|z)p(z)dz\n$$\nОднако прямой расчет этого выражения сложен из-за вычислительной трудности интеграла.\n## Причины построения ELBO\nELBO (Evidence Lower Bound) вводится как нижняя граница для аппроксимации $\\log p(x)$. Это позволяет оптимизировать модель, избегая прямого вычисления интеграла. ELBO упрощает задачу, разделяя её на две части: реконструкцию данных и регуляризацию скрытого пространства.\n\n## Метод построения ELBO\nИспользуется разложение $\\log p(x)$:\n$$\n\\log p(x) = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{KL}(q(z|x) || p(z))\n$$\n1. **Первая часть**:\n   - $\\mathbb{E}_{q(z|x)}[\\log p(x|z)]$ — мера качества реконструкции данных.\n2. **Вторая часть**:\n   - $\\text{KL}(q(z|x) || p(z))$ — регуляризация, минимизирующая расхождение между $q(z|x)$ и $p(z)$.\n\nЦель — максимизация $\\mathcal{L}_{\\text{ELBO}}$, что приближает $\\log p(x)$.\n## Итог\nБаейсовское моделирование в VAE основано на использовании аппроксимации апостериорного распределения. ELBO упрощает оптимизацию функции правдоподобия, разделяя её на реконструкцию и регуляризацию. Это делает обучение модели вычислительно эффективным.\n\n"
    },
    "35. Denoising diffusion models - общий принцип работы, описание прямого процесса и основные принципы описания обратного процесса": {
        "markdown": "## Общий принцип работы\n\nDenoising diffusion models представляют собой классы моделей генерации данных, основанных на постепенном добавлении шума к данным (прямой процесс) и обучении обратного процесса для восстановления исходных данных из зашумленных.\n## Прямой процесс\n\nПрямой процесс заключается в последовательном добавлении гауссовского шума к данным. Он описывается уравнением:\n\n$$q(x_t \\mid x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{\\alpha_t} x_{t-1}, (1 - \\alpha_t)I),$$\n\nгде $x_t$ - состояние данных на шаге $t$, $\\alpha_t$ - коэффициенты, контролирующие величину добавленного шума.\n\nИтерации продолжаются до тех пор, пока данные не станут распределены как стандартное гауссовское распределение (то есть зашумлены).\nХорошим решением в этой сфере является использование “линейного планировщика”, для увеличения добавляемого шума с каждый шагом зашумления.\n\n## Обратный процесс\n\nОбратный процесс предполагает восстановление данных из полученных зашумленных версий. Он моделируется условным распределением:\n\n$$p_\\theta(x_{t-1} \\mid x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)),$$\n\nгде параметры $\\mu_\\theta$ и $\\Sigma_\\theta$ оцениваются с помощью нейронной сети, обученной минимизировать разницу между истинным распределением $q$ и модельным распределением $p_\\theta$.\n\nОсновной принцип обучения - минимизация вариации Кульбака-Лейблера между распределениями прямого и обратного процессов.\n![[Pasted image 20250106181049.png]]\n## Генерация изображений\n1. _Безусловная генерация изображений_ означает, что модель преобразует шум в любую “случайную репрезентативную выборку данных”. \n   Процесс генерации не контролируется и не управляется, и модель может генерировать изображение любого характера.\n2. _Условная генерация изображений_ - это когда модели предоставляется дополнительная информация с помощью текста (text2img) или меток классов (как в CGANs). \n   Это случай управляемой или управляемой генерации изображений. Предоставляя дополнительную информацию, мы ожидаем, что модель будет генерировать определенные наборы изображений. Например, вы можете обратиться к двум изображениям в начале текстовое описание того, что мы хотим получить.\n\n## Пример на архитектуре Stable Diffusion\n1. **Кодировщик текста**  \n   Преобразует текстовое приглашение в машиночитаемый вектор.\n2. **U-Net**  \n   Диффузионная модель для генерации изображений в уменьшенном пространстве (пошагово удаляет шум, как описано выше).\n3. **Вариационный автоэнкодер**  \n   - Кодер: уменьшает размер изображения перед обработкой U-Net.  \n   - Декодер: восстанавливает изображение до исходного размера после генерации.\n![[Pasted image 20250106181014.png]]"
    },
    "Гиперпараметры. Скорость обучения и размер батча": {
        "markdown": "## Гиперпараметры\nГиперпараметры — это параметры, которые задаются перед началом обучения модели и не изменяются в процессе. Они влияют на качество и скорость обучения. Примеры: скорость обучения, размер батча, количество слоев и нейронов.\n## Скорость обучения\nСкорость обучения (learning rate) определяет, насколько большие шаги делаются при обновлении параметров модели:\n\n$$\nw = w - \\eta \\cdot \\frac{\\partial L}{\\partial w}\n$$\n\nгде η — скорость обучения.  \nОсобенности:\n- Слишком большая скорость обучения может привести к нестабильности и \"перелету\" через минимум функции потерь.\n- Слишком маленькая замедляет обучение и может застрять в локальном минимуме.\nСовременные подходы включают адаптивные методы (Adam, RMSProp) или использование планов изменения скорости (learning rate schedule), таких как уменьшение скорости при отсутствии улучшения метрик.\n## Размер батча\nРазмер батча определяет количество примеров из обучающей выборки, которые используются для одного шага обновления.  \nОсобенности:\n- **Малый размер батча**: обеспечивает более точные обновления, лучше подходит для шумных данных, но увеличивает время обучения.\n- **Большой размер батча**: ускоряет вычисления, но может привести к застреванию в локальных минимумах.\nБаланс между точностью и скоростью обучения достигается выбором оптимального размера батча, обычно 32, 64 или 128 (лучше использовать батчи кратные 2, так как современные GPU и библиотеки, такие как cuBLAS, оптимизированы для работы с матрицами размером, кратным 2. Это обеспечивает более эффективное использование памяти, шины данных и вычислительных ресурсов, ускоряя операции свертки и линейной алгебры)\n[[9. Стохастический градиентный спуск. Батчи обучающей выборки.|Подробнее]]\nПри большом размере батча можно понизить $\\beta_1$ в оптимизаторе Adam для более быстрого учёта изменений, но всё равно все подобные изменения требует экспериментального подтверждения\n## Связь между скоростью обучения и размером батча\nЕдиного ответа нет, в разных источниках предлагается при увеличении размера батча в n раз увеличить скорость в обучения тоже в n так, так и в **корень из n** раз, так и не изменять вовсе при незначительном увеличении."
    },
    "Линейное отображение. Векторно-матричное дифференцирование": {
        "markdown": "## Линейное отображение\nЛинейное отображение — это отображение между векторными пространствами, которое сохраняет операции сложения и умножения на скаляр. Формально, если A — это линейное отображение, то для любых векторов v, w и скаляров alpha, beta выполняются следующие свойства:\n\n$$ A(\\alpha \\mathbf{v} + \\beta \\mathbf{w}) = \\alpha A(\\mathbf{v}) + \\beta A(\\mathbf{w}) $$\n\n## Векторно-матричное дифференцирование\n\nВекторно-матричное дифференцирование используется для нахождения производных векторных и матричных функций. Например, если функция y = A * x + b, где A — матрица, a,b — векторы, то производная функции по вектору x будет:\n\n$$ \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = A $$\n\nЭтот метод широко применяется для вычисления градиентов в задачах оптимизации.\n\n## Пример\n\n^fafd8c\n\n### Прямой проход (Forward Pass)\n1. **Входной вектор:** $\\mathbf{x}$ (размерности $n_{\\text{in}} \\times 1$).\n2. **Выход на скрытом слое, $\\mathbf{z} = \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{b}$:\n   где:\n   - $\\mathbf{W}$ — матрица весов (размерности $n_{\\text{hidden}} \\times n_{\\text{in}}$),\n   - $\\mathbf{b}$ — вектор смещений (размерности $n_{\\text{hidden}} \\times 1$).\n3. **Применение функции активации ReLU, $\\mathbf{a} = \\text{ReLU}(\\mathbf{z})$:\n   где:\n   $\\text{ReLU}(\\mathbf{z}) = \\max(0, \\mathbf{z})$\n4. **Выход сети, $y_{\\text{pred}} = \\mathbf{a}^T \\cdot \\mathbf{w}_{\\text{out}} + b_{\\text{out}}$:\n   где:\n   - $\\mathbf{w}_{\\text{out}}$ — вектор весов выходного слоя (размерности $n_{\\text{hidden}} \\times 1$),\n   - $b_{\\text{out}}$ — смещение выходного слоя (скаляр).\n5. **Функция потерь (MSE), $L = \\frac{1}{2} \\left(y_{\\text{pred}} - y_{\\text{true}}\\right)^2$:\n   где $y_{\\text{true}}$ — истинное значение.\n### Обратное распространение ошибки (Backward Pass)\n#### 1. Градиент ошибки по выходу сети ($y_{\\text{pred}}$):\n$\\frac{\\partial L}{\\partial y_{\\text{pred}}} = y_{\\text{pred}} - y_{\\text{true}}$\n#### 2. Градиент ошибки по активации ($\\mathbf{a}$):\nГрадиент передаётся через выходной слой:\n$\\frac{\\partial L}{\\partial \\mathbf{a}} = \\frac{\\partial L}{\\partial y_{\\text{pred}}} \\cdot \\frac{\\partial y_{\\text{pred}}}{\\partial \\mathbf{a}}$\n\nгде:\n$\\frac{\\partial y_{\\text{pred}}}{\\partial \\mathbf{a}} = \\mathbf{w}_{\\text{out}}$\nИтог:\n$\\frac{\\partial L}{\\partial \\mathbf{a}} = \\left(y_{\\text{pred}} - y_{\\text{true}}\\right) \\cdot \\mathbf{w}_{\\text{out}}$\n#### 3. Градиент ошибки по $\\mathbf{z}$:\nДля ReLU функция активации имеет производную:\n\n$$\n\n\\frac{\\partial \\mathbf{a}}{\\partial \\mathbf{z}} = \\begin{cases}\n\n1, & \\text{если } \\mathbf{z} > 0, \\\\\n\n0, & \\text{если } \\mathbf{z} \\leq 0.\n\n\\end{cases}\n\n$$\nСоответственно, градиент по $\\mathbf{z}$ вычисляется как:\n$\\frac{\\partial L}{\\partial \\mathbf{z}} = \\frac{\\partial L}{\\partial \\mathbf{a}} \\cdot \\frac{\\partial \\mathbf{a}}{\\partial \\mathbf{z}}$\n#### 4. Градиент ошибки по весам $\\mathbf{W}$:\nДля вычисления градиента по весам скрытого слоя используем правило цепочки:\n$\\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}}$\nПоскольку:\n$\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{W}} = \\mathbf{x}^T$\nто:\n$\\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{\\partial L}{\\partial \\mathbf{z}} \\cdot \\mathbf{x}^T$\n### Итоговая процедура обновления весов\nПосле вычисления градиентов параметры обновляются с использованием шага обучения $\\alpha$, например:\n1. Обновление весов выходного слоя:\n   $\\mathbf{w}_{\\text{out}} \\leftarrow \\mathbf{w}_{\\text{out}} - \\alpha \\cdot \\frac{\\partial L}{\\partial \\mathbf{w}_{\\text{out}}}$\n2. Обновление смещения выходного слоя:\n   $b_{\\text{out}} \\leftarrow b_{\\text{out}} - \\alpha \\cdot \\frac{\\partial L}{\\partial b_{\\text{out}}}$"
    },
    "Картинки": {
        "code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\n\ndata_dir = \"eng_handwritten\"\n\n# Предобработка изображений\ntransform = transforms.Compose(\n    [\n        transforms.Resize((128, 128)),  # Изменение размера изображений\n        transforms.ToTensor(),  # Преобразование в тензоры\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Нормализация\n    ]\n)\n\n# Загрузка данных\nfull_dataset = ImageFolder(data_dir, transform=transform)\n\n# Разделение на обучающее и тестовое множество\ntrain_size = int(0.7 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\n# Проверка классов\nprint(f\"Классы: {full_dataset.classes}\")\n\n# Загрузка данных\nfull_dataset = ImageFolder(data_dir, transform=transform)\n\n# Разделение на обучающее и тестовое множество\ntrain_size = int(0.7 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\n# Проверка классов\nprint(f\"Классы: {full_dataset.classes}\")\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass CNN(nn.Module):\n    def __init__(self, num_classes, num_blocks=2):\n        super(CNN, self).__init__()\n        self.conv_layers = nn.ModuleList()\n\n        in_channels = 3\n        for _ in range(num_blocks):\n            self.conv_layers.append(\n                nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n            )\n            self.conv_layers.append(nn.ReLU())\n            self.conv_layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n            in_channels = 32\n\n        self.fc = nn.Linear(\n            32 * (128 // (2**num_blocks)) * (128 // (2**num_blocks)), num_classes\n        )\n\n    def forward(self, x):\n        for layer in self.conv_layers:\n            x = layer(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\n\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\n\n# Гиперпараметры\nbatch_size = 64\nnum_epochs = 10\nprint_every = 2\nnum_classes = len(full_dataset.classes)\nlearning_rate = 0.001\n\n# Модель, критерий, оптимизатор\nmodel = CNN(num_classes=num_classes, num_blocks=3)  # Вы можете варьировать num_blocks\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Обучение\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0\n    correct = 0\n    total = 0\n\n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()\n        outputs = model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == batch_y).sum().item()\n        total += batch_y.size(0)\n\n    if (epoch + 1) % print_every == 0:\n        print(\n            f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {100 * correct / total:.2f}%\"\n        )\n\nfrom sklearn.metrics import f1_score\nimport numpy as np\n\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for batch_X, batch_y in test_loader:\n        outputs = model(batch_X)\n        _, predicted = torch.max(outputs, 1)\n        y_true.extend(batch_y.numpy())\n        y_pred.extend(predicted.numpy())\n\nf1 = f1_score(y_true, y_pred, average=\"micro\")\nprint(f\"Micro F1 Score: {f1:.4f}\")\n\nimport os\nimport torch\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\n\n# Директория для сохранения моделей\nmodel_dir = \"saved_models\"\nos.makedirs(model_dir, exist_ok=True)\n\nnum_blocks_range = [1, 2, 3, 4]\nf1_scores = []\n\nfor num_blocks in num_blocks_range:\n    # Создаем модель\n    model = CNN(num_classes=num_classes, num_blocks=num_blocks)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    # Обучение модели\n    for epoch in range(num_epochs):\n        model.train()\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n\n    # Сохраняем модель\n    model_path = os.path.join(model_dir, f\"model_{num_blocks}_blocks.pth\")\n    torch.save(model.state_dict(), model_path)\n    print(f\"Модель с {num_blocks} блоками сохранена в {model_path}\")\n\n    # Оценка модели\n    y_true = []\n    y_pred = []\n    model.eval()\n    with torch.no_grad():\n        for batch_X, batch_y in test_loader:\n            outputs = model(batch_X)\n            _, predicted = torch.max(outputs, 1)\n            y_true.extend(batch_y.numpy())\n            y_pred.extend(predicted.numpy())\n\n    f1 = f1_score(y_true, y_pred, average=\"micro\")\n    f1_scores.append(f1)\n    print(f\"Blocks: {num_blocks}, Micro F1 Score: {f1:.4f}\")\n\n# Построение графика\nplt.plot(num_blocks_range, f1_scores, marker=\"o\")\nplt.title(\"Зависимость Micro F1 от числа сверточных блоков\")\nplt.xlabel(\"Количество сверточных блоков\")\nplt.ylabel(\"Micro F1\")\nplt.grid()\nplt.show()\n\nfrom torchvision import datasets, transforms\nimport torch\nimport numpy as np\n\n\n# ИЛИИИИИ Функция для вычисления mean и std\ndef calculate_mean_std(dataset):\n    loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=False)\n    mean = 0.0\n    std = 0.0\n    for images, _ in loader:\n        # Извлекаем канал по каналу\n        mean += images.mean(\n            [0, 2, 3]\n        )  # Среднее по всем изображениям для каждого канала (RGB)\n        std += images.std(\n            [0, 2, 3]\n        )  # Стандартное отклонение по всем изображениям для каждого канала\n    mean /= len(loader)\n    std /= len(loader)\n    return mean, std\n\n\n# Загрузка вашего набора данных\nfull_dataset = datasets.ImageFolder(data_dir, transform=transforms.ToTensor())\n\n# Расчет mean и std\nmean, std = calculate_mean_std(full_dataset)\n\nprint(f\"Mean: {mean}\")\nprint(f\"Std: {std}\")\ntransform = transforms.Compose(\n    [\n        transforms.Resize((128, 128)),  # Изменение размера изображений\n        transforms.ToTensor(),  # Преобразование в тензоры\n        transforms.Normalize(\n            mean=mean, std=std\n        ),  # Использование нормализации с вычисленными значениями\n    ]\n)"
    },
    "Регрессия": {
        "code": "import pandas as pd\nimport numpy as np\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv(\"/content/bike_cnt.csv\", parse_dates=[1])\ndata.head()\ndata = pd.read_csv(\"/content/bike_cnt.csv\", parse_dates=[1])\n\ny = data[[\"cnt\"]]\nX = data.drop([\"cnt\", \"instant\"], axis=1)\n\n# categorical_cols = [...]\nnumerical_cols = X.select_dtypes(\"number\").columns\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), numerical_cols)\n        #    ('cat', OneHotEncoder(), categorical_cols)\n    ]\n)\n\nX_processed = preprocessor.fit_transform(X)\ny_processed = StandardScaler().fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_processed, y_processed, test_size=0.2, random_state=42\n)\n\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.float32)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.float32)\n\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n\nclass Model(nn.Module):\n    def __init__(self, n_features):\n        super(Model, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(n_features, 64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x\n\n\nbatch_size = 64\nepochs = 100\nprint_every = 10\n\nn_feat = len(train_dataset[0][0])\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ncriterion = nn.MSELoss()\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\ndef train(model, train_loader, test_loader, optimizer, device=None):\n    #  model.to(device)\n    train_losses = []\n    val_losses = []\n    for epoch in range(epochs):\n        epoch_loss = 0\n        model.train()\n        for batch_X, batch_y in train_loader:\n            #     batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n            optimizer.zero_grad()\n            y_pred = model.forward(batch_X)\n            loss_val = criterion(y_pred, batch_y)\n            epoch_loss += loss_val\n            loss_val.backward()\n            optimizer.step()\n\n        train_losses.append(epoch_loss / len(train_loader))\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                #    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                y_pred = model(batch_X)\n                loss = criterion(y_pred, batch_y)\n                val_loss += loss.item()\n        val_losses.append(val_loss / len(test_loader))\n\n    #       if (epoch+1) % print_every == 0:\n    #        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(test_loader)}')\n    return train_losses, val_losses\n\n\noptimizers = {\"SGD\": optim.SGD, \"Adam\": optim.Adam, \"AdamW\": optim.AdamW}\n\nresults = {}\n\nfor name, optim_cls in optimizers.items():\n    model = Model(n_feat)\n    optimizer = optim_cls(model.parameters(), lr=0.01)\n    train_losses, val_losses = train(model, train_loader, test_loader, optimizer)\n    results[name] = {\n        \"train_losses\": train_losses,\n        \"val_losses\": val_losses,\n        \"model\": model,\n    }\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nfor name, result in results.items():\n    model = result[\"model\"]\n    model.eval()\n    y_pred, y_true = [], []\n\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            # X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pred.extend(model(X_batch).flatten().numpy())\n            y_true.extend(y_batch.numpy())\n\n    mse = mean_squared_error(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n\n    print(f\"{name}:\")\n    print(f\"  MSE: {mse:.4f}\")\n    print(f\"  MAE: {mae:.4f}\")\n    print(f\"  R2: {r2:.4f}\")\n\nfor name, result in results.items():\n    train_losses_cpu = [loss.item() for loss in result[\"train_losses\"]]\n    val_losses_cpu = [loss for loss in result[\"val_losses\"]]\n\n    plt.plot(train_losses_cpu, label=f\"{name} - Train\")\n    plt.plot(val_losses_cpu, label=f\"{name} - Validation\")\n\nplt.title(\"Loss Curves\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()"
    },
    "Классификация": {
        "code": "import pandas as pd\nimport numpy as np\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv(\"/content/bank.csv\")\n\ny = data[[\"deposit\"]]\nX = data.drop(\"deposit\", axis=1)\n\ncategorical_cols = X.select_dtypes(\"object\").columns\nnumerical_cols = X.select_dtypes(\"number\").columns\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), numerical_cols),\n        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_cols),\n    ]\n)\n\nX_processed = preprocessor.fit_transform(X).toarray()\ny_processed = OneHotEncoder(drop=\"first\").fit_transform(y).toarray()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_processed, y_processed, test_size=0.2, random_state=42\n)\n\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\ntrain_dataset = TensorDataset(X_train, y_train)\ntest_dataset = TensorDataset(X_test, y_test)\n\n\nclass Model(nn.Module):\n    def __init__(self, n_features, num_classes):\n        super(Model, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(n_features, 64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x\n\n\nbatch_size = 64\nepochs = 15\nprint_every = 10\nnum_classes = 2\nn_feat = len(train_dataset[0][0])\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ncriterion = nn.CrossEntropyLoss()\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\ndef train(model, train_loader, test_loader, optimizer, device=None):\n    #    model.to(device)\n    train_losses = []\n    val_losses = []\n    for epoch in range(epochs):\n        epoch_loss = 0\n        model.train()\n        for batch_X, batch_y in train_loader:\n            #  batch_X, batch_y = batch_X.to(device), batch_y.squeeze(1).to(device)\n            batch_y = batch_y.squeeze(1)\n            optimizer.zero_grad()\n            y_pred = model.forward(batch_X)\n            loss_val = criterion(y_pred, batch_y)\n            epoch_loss += loss_val\n            loss_val.backward()\n            optimizer.step()\n\n        train_losses.append(epoch_loss / len(train_loader))\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch_X, batch_y in test_loader:\n                #   batch_X, batch_y = batch_X.to(device), batch_y.squeeze(1).to(device)\n                batch_y = batch_y.squeeze(1)\n                y_pred = model(batch_X)\n                loss = criterion(y_pred, batch_y)\n                val_loss += loss.item()\n        val_losses.append(val_loss / len(test_loader))\n\n        # if (epoch+1) % print_every == 0:\n        #    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(test_loader)}')\n    return train_losses, val_losses\n\n\noptimizers = {\"SGD\": optim.SGD, \"Adam\": optim.Adam, \"AdamW\": optim.AdamW}\n\nresults = {}\n\nfor name, optim_cls in optimizers.items():\n    model = Model(n_feat, num_classes)\n    optimizer = optim_cls(model.parameters(), lr=0.01)\n    train_losses, val_losses = train(model, train_loader, test_loader, optimizer)\n    results[name] = {\n        \"train_losses\": train_losses,\n        \"val_losses\": val_losses,\n        \"model\": model,\n    }\n\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfor name, result in results.items():\n    model = result[\"model\"]\n    model.eval()\n    y_pred, y_true = [], []\n\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            #  X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_pr = model(X_batch)\n            _, predicted_class = torch.max(y_pr, 1)\n            y_pred.extend(predicted_class.numpy())\n            y_true.extend(y_batch.numpy())\n\n    acc = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n\n    print(f\"{name}:\")\n    print(f\"  Accuracy: {acc:.4f}\")\n    print(f\"  F1 Score: {f1:.4f}\")\n\nfor name, result in results.items():\n    train_losses_cpu = [loss.item() for loss in result[\"train_losses\"]]\n    val_losses_cpu = [loss for loss in result[\"val_losses\"]]\n\n    plt.plot(train_losses_cpu, label=f\"{name} - Train\")\n    plt.plot(val_losses_cpu, label=f\"{name} - Validation\")\n\nplt.title(\"Loss Curves\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclasses = np.array([0.0, 1.0])\ny = np.squeeze(y_processed)\n\n# Compute class weights\nclass_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y)\n\nfor i, weight in enumerate(class_weights):\n    print(f\"Class {classes[i]}: {weight}\")"
    }
}

questions_numerated = {
    i: {j: v for j, (k, v) in enumerate(v.items())}
    for i, (k, v) in enumerate(questions.items())
}

# themes_numerated = {
#     i: {
#         j: {k: v for k, (k_name, v) in enumerate(q.items())}
#         for j, (q_name, q) in enumerate(v.items())
#     }
#     for i, (theme_name, v) in enumerate(themes.items())
# }

# themes_all_numerated = {
#     i: {j: v for j, (k, v) in enumerate(v.items())}
#     for i, (k, v) in enumerate(themes_all.items())
# }

def get(i=None, j=None, silent: bool = False):
    if i is None:
        info_string = ''
        for i, (question, codes) in enumerate(questions.items()):
            info_string += f'{i} {question.strip("1234567890 .")}\n'
            if len(codes.keys()) > 1:
                for j, code in enumerate(codes.keys()):
                    info_string += f'{"-"*2} {i}.{j} {code}\n'
        if silent:
            pyperclip.copy(info_string)
        else:
            print(info_string)
    else:
        if j is None:
            return_string = ''
            for k, v in questions_numerated[i].items():
                # if k == 'markdown':
                #     return_string += '#' + '#'.join(v.split('\n'))
                # else:
                return_string += v

            pyperclip.copy(return_string.strip())
        else:
            pyperclip.copy(questions_numerated[i][j].strip())

# def get(i=None, j=None, k=None, silent: bool = False):
#     if i is None or j is None:
#         info_string = ''
#         for i, (theme, questions) in enumerate(themes.items()):
#             info_string += f"{i} {theme}\n"
#             for j, (question, codes) in enumerate(questions.items()):
#                 info_string += f'{"-"*2} {i}.{j} {question}\n'
#                 for k, code in enumerate(codes.keys()):
#                     info_string += f'{"-"*4} {i}.{j}.{k} {code}\n'
#         if silent:
#             pyperclip.copy(info_string)
#         else:
#             print(info_string)
#     else:
#         if k is None:
#             pyperclip.copy(themes_all_numerated[i][j].strip())
#         else:
#             pyperclip.copy(themes_numerated[i][j][k].strip())
