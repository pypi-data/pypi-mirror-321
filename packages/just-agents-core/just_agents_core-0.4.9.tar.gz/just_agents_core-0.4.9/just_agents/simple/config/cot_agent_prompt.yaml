class: "ChainOfThoughtAgent" # class name to create could be LLMSession, ChainOfThoughtAgent. Default is LLMSession
system_prompt_path: # path to system prompt exclude use of system_prompt
system_prompt: "You are an expert AI assistant that explains your reasoning step by step. 
  For each step, provide a title that describes what you're doing in that step, along with the content. 
  Decide if you need another step or if you're ready to give the final answer. 
  Respond in JSON format with 'title', 'content', and 'next_action' (either 'continue' or 'final_answer') keys.
  Make sure you send only one JSON step object.
  USE AS MANY REASONING STEPS AS POSSIBLE. AT LEAST 3. 
  BE AWARE OF YOUR LIMITATIONS AS AN LLM AND WHAT YOU CAN AND CANNOT DO. 
  IN YOUR REASONING, INCLUDE EXPLORATION OF ALTERNATIVE ANSWERS. 
  CONSIDER YOU MAY BE WRONG, AND IF YOU ARE WRONG IN YOUR REASONING, WHERE IT WOULD BE. 
  FULLY TEST ALL OTHER POSSIBILITIES. 
  YOU CAN BE WRONG. WHEN YOU SAY YOU ARE RE-EXAMINING, ACTUALLY RE-EXAMINE, AND USE ANOTHER APPROACH TO DO SO. 
  DO NOT JUST SAY YOU ARE RE-EXAMINING. USE AT LEAST 3 METHODS TO DERIVE THE ANSWER. USE BEST PRACTICES.
  
  Example of a valid JSON response:
  \"{
      \"title\": \"Identifying Key Information\",
      \"content\": \"To begin solving this problem, we need to carefully examine the given information and identify the crucial elements that will guide our solution process. This involves...\",
      \"next_action\": \"continue\"
  }\"
  " # system prompt exclude use of system_prompt_path
final_prompt: "Please provide the final answer based solely on your reasoning above." # prompt that will be passed before final answer
title: "title" # title parameter in system prompt
content: "content" # content parameter in system prompt
next_action: "next_action" # next_action parameter in system prompt
action_continue: "continue" # state of next_action parameter determine that next answer will be not final
action_final: "final_answer" # state of next_action parameter determine that next answer will be not final
thought_max_tokes: 300 # maximum length of thought
final_max_tokens: 1200 # maximum length of final answer
max_steps: 25 # maximum number of thought steps
tools: # list of functions that will be used as tools, each record should contain package and function name
#  - package:
#    function:
llm_session: # initialization parameters for inner object LLMSession
  just_streaming_method: "openai" # protocol to handle llm format for function calling
  completion_remove_key_on_error: True # in case of using list of keys removing key from the list after error call with this key
  completion_max_tries: 2 # maximum number of completion retries before giving up
  backup_options: # options that will be used after we give up with main options, one more completion call will be done with backup options
  key_list_path: # path to text file with list of api keys, one key per line