Metadata-Version: 2.2
Name: llmscout
Version: 0.1.0
Summary: An LLM-powered tool for discovering and analyzing research papers
Home-page: https://github.com/cafferychen777/llmscout
Author: Caffery Yang
Author-email: cafferychen777@gmail.com
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: openai>=1.0.0
Requires-Dist: arxiv
Requires-Dist: pyyaml
Requires-Dist: pytz
Requires-Dist: requests>=2.31.0
Requires-Dist: python-dotenv>=1.0.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# LLMScout

An LLM-powered tool for discovering and analyzing research papers. LLMScout helps researchers efficiently search, analyze, and manage academic papers from arXiv, leveraging the power of large language models.

## Features

- üîç Smart keyword generation using LLM
- üìö Automated paper search on arXiv
- üìä Intelligent paper analysis and summarization
- üì• Batch paper downloading
- üìù Detailed logging and progress tracking
- ‚è∏Ô∏è Resume capability for interrupted operations

## Installation

```bash
pip install llmscout
```

Or install from source:

```bash
git clone https://github.com/cafferychen777/llmscout.git
cd llmscout
pip install -e .
```

## Quick Start

1. Set up your environment variables:
```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your OpenAI API key
OPENAI_API_KEY=your-api-key-here
```

2. Use in Python:
```python
from llmscout import ResearchPipeline

# Initialize the pipeline
pipeline = ResearchPipeline()

# Run the complete analysis
pipeline.run(
    topic="watermark attack language model",
    max_results=10,
    date_start="2023-01-01"
)
```

3. Or use the command-line interface:
```bash
llmscout --topic "watermark attack language model" --max-results 10
```

## Environment Variables

The following environment variables can be configured in your `.env` file:

```bash
# Required
OPENAI_API_KEY=your-api-key-here

# Optional
OPENAI_MODEL=gpt-4              # Default: gpt-4
OPENAI_TEMPERATURE=0.7          # Default: 0.7
OPENAI_MAX_TOKENS=1000          # Default: 1000

# Output directories
OUTPUT_DIR=./results            # Default: ./results
DOWNLOAD_DIR=./papers          # Default: ./papers
LOG_DIR=./logs                 # Default: ./logs
```

## Documentation

For detailed documentation, visit [our documentation site](https://llmscout.readthedocs.io/).

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Citation

If you use this tool in your research, please cite:

```bibtex
@software{llmscout,
  title = {LLMScout: An LLM-Powered Tool for Research Paper Discovery and Analysis},
  author = {Caffery Chen},
  year = {2025},
  url = {https://github.com/cafferychen777/llmscout}
}
