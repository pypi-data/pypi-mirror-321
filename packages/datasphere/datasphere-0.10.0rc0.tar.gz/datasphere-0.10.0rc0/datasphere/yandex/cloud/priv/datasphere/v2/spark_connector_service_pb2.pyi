"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""

import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.field_mask_pb2
import google.protobuf.internal.containers
import google.protobuf.message
import typing

try:
    import yandex.cloud.priv.datasphere.v2.spark_connector_pb2
except ImportError:
    import datasphere.yandex.cloud.priv.datasphere.v2.spark_connector_pb2


DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

@typing.final
class CheckProjectPermissionsRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PROJECT_ID_FIELD_NUMBER: builtins.int
    project_id: builtins.str
    def __init__(
        self,
        *,
        project_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["project_id", b"project_id"]) -> None: ...

global___CheckProjectPermissionsRequest = CheckProjectPermissionsRequest

@typing.final
class CheckProjectPermissionsResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    ALLOW_USE_PERMANENT_CLUSTER_FIELD_NUMBER: builtins.int
    ALLOW_CREATE_TEMPORARY_CLUSTER_FIELD_NUMBER: builtins.int
    allow_use_permanent_cluster: builtins.bool
    allow_create_temporary_cluster: builtins.bool
    def __init__(
        self,
        *,
        allow_use_permanent_cluster: builtins.bool = ...,
        allow_create_temporary_cluster: builtins.bool = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["allow_create_temporary_cluster", b"allow_create_temporary_cluster", "allow_use_permanent_cluster", b"allow_use_permanent_cluster"]) -> None: ...

global___CheckProjectPermissionsResponse = CheckProjectPermissionsResponse

@typing.final
class ListSparkClustersRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PROJECT_ID_FIELD_NUMBER: builtins.int
    project_id: builtins.str
    def __init__(
        self,
        *,
        project_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["project_id", b"project_id"]) -> None: ...

global___ListSparkClustersRequest = ListSparkClustersRequest

@typing.final
class GetSparkConnectorRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SPARK_CONNECTOR_ID_FIELD_NUMBER: builtins.int
    spark_connector_id: builtins.str
    def __init__(
        self,
        *,
        spark_connector_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["spark_connector_id", b"spark_connector_id"]) -> None: ...

global___GetSparkConnectorRequest = GetSparkConnectorRequest

@typing.final
class GetSparkConnectorForProjectRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SPARK_CONNECTOR_ID_FIELD_NUMBER: builtins.int
    PROJECT_ID_FIELD_NUMBER: builtins.int
    spark_connector_id: builtins.str
    project_id: builtins.str
    def __init__(
        self,
        *,
        spark_connector_id: builtins.str = ...,
        project_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["project_id", b"project_id", "spark_connector_id", b"spark_connector_id"]) -> None: ...

global___GetSparkConnectorForProjectRequest = GetSparkConnectorForProjectRequest

@typing.final
class CreateSparkConnectorRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        value: builtins.str
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: builtins.str = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...

    @typing.final
    class SessionParamsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        value: builtins.str
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: builtins.str = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...

    PROJECT_ID_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    PERMANENT_CLUSTER_ID_FIELD_NUMBER: builtins.int
    TEMPORARY_CLUSTER_SPEC_NAME_FIELD_NUMBER: builtins.int
    SESSION_PARAMS_FIELD_NUMBER: builtins.int
    S3_ACCESS_KEY_FIELD_NUMBER: builtins.int
    S3_SECRET_KEY_SECRET_ID_FIELD_NUMBER: builtins.int
    MODE_FIELD_NUMBER: builtins.int
    PUBLIC_SSH_KEY_FIELD_NUMBER: builtins.int
    project_id: builtins.str
    name: builtins.str
    description: builtins.str
    permanent_cluster_id: builtins.str
    temporary_cluster_spec_name: builtins.str
    s3_access_key: builtins.str
    s3_secret_key_secret_id: builtins.str
    mode: yandex.cloud.priv.datasphere.v2.spark_connector_pb2.SparkConnector.Mode.ValueType
    public_ssh_key: builtins.str
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
    @property
    def session_params(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
    def __init__(
        self,
        *,
        project_id: builtins.str = ...,
        name: builtins.str = ...,
        description: builtins.str = ...,
        labels: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
        permanent_cluster_id: builtins.str = ...,
        temporary_cluster_spec_name: builtins.str = ...,
        session_params: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
        s3_access_key: builtins.str = ...,
        s3_secret_key_secret_id: builtins.str = ...,
        mode: yandex.cloud.priv.datasphere.v2.spark_connector_pb2.SparkConnector.Mode.ValueType = ...,
        public_ssh_key: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["cluster", b"cluster", "permanent_cluster_id", b"permanent_cluster_id", "temporary_cluster_spec_name", b"temporary_cluster_spec_name"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["cluster", b"cluster", "description", b"description", "labels", b"labels", "mode", b"mode", "name", b"name", "permanent_cluster_id", b"permanent_cluster_id", "project_id", b"project_id", "public_ssh_key", b"public_ssh_key", "s3_access_key", b"s3_access_key", "s3_secret_key_secret_id", b"s3_secret_key_secret_id", "session_params", b"session_params", "temporary_cluster_spec_name", b"temporary_cluster_spec_name"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["cluster", b"cluster"]) -> typing.Literal["permanent_cluster_id", "temporary_cluster_spec_name"] | None: ...

global___CreateSparkConnectorRequest = CreateSparkConnectorRequest

@typing.final
class UpdateSparkConnectorRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        value: builtins.str
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: builtins.str = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...

    @typing.final
    class SessionParamsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        value: builtins.str
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: builtins.str = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...

    SPARK_CONNECTOR_ID_FIELD_NUMBER: builtins.int
    UPDATE_MASK_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    PERMANENT_CLUSTER_ID_FIELD_NUMBER: builtins.int
    TEMPORARY_CLUSTER_SPEC_NAME_FIELD_NUMBER: builtins.int
    SESSION_PARAMS_FIELD_NUMBER: builtins.int
    S3_ACCESS_KEY_FIELD_NUMBER: builtins.int
    S3_SECRET_KEY_SECRET_ID_FIELD_NUMBER: builtins.int
    MODE_FIELD_NUMBER: builtins.int
    PUBLIC_SSH_KEY_FIELD_NUMBER: builtins.int
    spark_connector_id: builtins.str
    name: builtins.str
    description: builtins.str
    permanent_cluster_id: builtins.str
    temporary_cluster_spec_name: builtins.str
    s3_access_key: builtins.str
    s3_secret_key_secret_id: builtins.str
    mode: yandex.cloud.priv.datasphere.v2.spark_connector_pb2.SparkConnector.Mode.ValueType
    public_ssh_key: builtins.str
    @property
    def update_mask(self) -> google.protobuf.field_mask_pb2.FieldMask: ...
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
    @property
    def session_params(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
    def __init__(
        self,
        *,
        spark_connector_id: builtins.str = ...,
        update_mask: google.protobuf.field_mask_pb2.FieldMask | None = ...,
        name: builtins.str = ...,
        description: builtins.str = ...,
        labels: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
        permanent_cluster_id: builtins.str = ...,
        temporary_cluster_spec_name: builtins.str = ...,
        session_params: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
        s3_access_key: builtins.str = ...,
        s3_secret_key_secret_id: builtins.str = ...,
        mode: yandex.cloud.priv.datasphere.v2.spark_connector_pb2.SparkConnector.Mode.ValueType = ...,
        public_ssh_key: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["cluster", b"cluster", "permanent_cluster_id", b"permanent_cluster_id", "temporary_cluster_spec_name", b"temporary_cluster_spec_name", "update_mask", b"update_mask"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["cluster", b"cluster", "description", b"description", "labels", b"labels", "mode", b"mode", "name", b"name", "permanent_cluster_id", b"permanent_cluster_id", "public_ssh_key", b"public_ssh_key", "s3_access_key", b"s3_access_key", "s3_secret_key_secret_id", b"s3_secret_key_secret_id", "session_params", b"session_params", "spark_connector_id", b"spark_connector_id", "temporary_cluster_spec_name", b"temporary_cluster_spec_name", "update_mask", b"update_mask"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["cluster", b"cluster"]) -> typing.Literal["permanent_cluster_id", "temporary_cluster_spec_name"] | None: ...

global___UpdateSparkConnectorRequest = UpdateSparkConnectorRequest

@typing.final
class DeleteSparkConnectorRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SPARK_CONNECTOR_ID_FIELD_NUMBER: builtins.int
    spark_connector_id: builtins.str
    def __init__(
        self,
        *,
        spark_connector_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["spark_connector_id", b"spark_connector_id"]) -> None: ...

global___DeleteSparkConnectorRequest = DeleteSparkConnectorRequest
