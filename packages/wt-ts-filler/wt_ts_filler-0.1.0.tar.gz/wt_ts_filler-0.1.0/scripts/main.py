from wt_ts_filler.Filling_gaps import GapsFiller
from wt_ts_filler.cleaning import SpikeCleaner, FlatPeriodCleaner
from wt_ts_filler.plotting import *

import pandas as pd

# Import dataframe
dataframe = pd.read_csv(
    'C:/Users/picourlat/Documents/040724_Data_recap/DATA/Hydrologic_data/Groundwater_lvls/Analyse_data_drought/Data/wt_ts.csv')
dataframe.iloc[:, 0] = pd.to_datetime(dataframe.iloc[:, 0], format='%Y-%m-%d')  # set dates in datetime format

# Split the dataframe into data series
data_series = []
for i in range(1, len(dataframe.columns)):
    data = pd.Series(dataframe.iloc[:, i].values, index=dataframe.iloc[:, 0], name="data" + str(i))
    data_series.append(data)

# Clean
cleaners = [
    SpikeCleaner(max_jump=10),
    FlatPeriodCleaner(flat_period=10)
]

for data in data_series:
    data_original = data.copy()
    for cleaner in cleaners:
        data = cleaner.clean(data)
    # plot_timeseries(data_original, data)
cleaned_dataframe = pd.concat(data_series, axis=1)

# Fill gaps
estimated_dataframe = GapsFiller(max_gap_lin_interp=5, Corr_min=0.75).fill(cleaned_dataframe)
estimated_dataframe.columns = dataframe.columns[1:]
plot_dataframes(cleaned_dataframe, estimated_dataframe)

# from scipy import stats
# corr_matrix = cleaned_dataframe.corr()
# # print(corr_matrix)
# import matplotlib.pyplot as plt
# import numpy as np
# # sn.heatmap(corr_matrix, annot=True)
# # plt.show()
# corr_matrix = corr_matrix.replace(1, 0)
# # max_corr = corr_matrix.idxmax()
# # max_corr_values = corr_matrix.max()
#
# estimated_dataframe = cleaned_dataframe.copy()
#
# # Step 1 : Interpolate for gaps inf or equal to N days
# N = 5
# print("Interpolate for gaps inf or equal to "+str(N)+' days')
# estimated_df_interpolated = estimated_dataframe.interpolate()
# for c in estimated_dataframe:
#     mask = estimated_dataframe[c].isna()
#     x = (mask.groupby((mask != mask.shift()).cumsum()).transform(lambda x: len(x) > N)* mask)
#     estimated_df_interpolated[c] = estimated_df_interpolated.loc[~x, c]
# estimated_dataframe = estimated_df_interpolated
#
# # Step 2 : Search the more correlated and apply linear regression + compute epsilon left
# print("Apply linear regression and compute epsilon left")
# estimated_dataframe_w_lin_reg = estimated_dataframe.copy()
# df_epsilon = estimated_dataframe.copy()
# correlation_df = estimated_dataframe.copy()
# for i in range(len(cleaned_dataframe.columns)) : # on parcourt les datasets
# # for i in [8] : # on parcourt les datasets
#     j=0
#     for j in range(len(estimated_dataframe_w_lin_reg.index)) : # on parcourt les dates
#         if ~np.isnan(df_epsilon.iloc[j, i]):
#             df_epsilon.iloc[j, i] = np.nan
#         if ~np.isnan(correlation_df.iloc[j, i]):
#             correlation_df.iloc[j, i] = np.nan
#         if ~np.isnan(estimated_dataframe_w_lin_reg.iloc[j-1,i]) and np.isnan(estimated_dataframe_w_lin_reg.iloc[j,i]) : # si value = Nan and prec_value isnot Nan
#             col_corr_matrix = corr_matrix.iloc[:,i]  # on regarde la col de la matrice de correlation correspondante à data_i
#             col_corr_matrix = col_corr_matrix.dropna(axis=0)  # on supprime les rows with nan values
#             Nb_datasets_corr = len(col_corr_matrix.index)
#             col_max_corr = col_corr_matrix.idxmax() # On cherche le dataset le plus corrélé
#             n=0
#             while np.isnan(cleaned_dataframe.iloc[j-1,int(col_max_corr[4:])-1]) and np.isnan(cleaned_dataframe.iloc[j,int(col_max_corr[4:])-1]) and n<Nb_datasets_corr-1: # tant que la valeur aux temps j-1 et j du dataset le + corrélé est nan, et que n<31
#                 col_corr_matrix = col_corr_matrix.drop(labels=[col_max_corr]) # on supprime la ligne de la colonne de correlation
#                 col_max_corr = col_corr_matrix.idxmax() # on recherche le dataset le plus corrélé
#                 n = n+1
#             # print('dataset le + corrélé et dont la valeur est dispo = '+ col_max_corr)
#             if col_corr_matrix.max() >= 0.75:
#                 # print('Pcoeff >= 0.75')
#                 x = cleaned_dataframe[col_max_corr]
#                 y = cleaned_dataframe.iloc[:, i]
#                 mask = ~np.isnan(x) & ~np.isnan(y)
#                 slope, intercept, r_value, p_value, std_err = stats.linregress(x[mask], y[mask])
#                 y_value_pred = slope * x.iloc[j] + intercept
#                 y_value_prec_pred = slope * x.iloc[j-1] + intercept
#                 epsilon = cleaned_dataframe.iloc[j-1, i] - y_value_prec_pred
#                 df_epsilon.iloc[j, i] = epsilon
# #                estimated_dataframe_w_lin_reg.iloc[j,i]=y_value_pred + epsilon
#                 estimated_dataframe_w_lin_reg.iloc[j, i] = y_value_pred
#                 correlation_df.iloc[j, i] = float(col_max_corr[4:])
#                 # if ~np.isnan(correlation_df.iloc[j-1, i]) and correlation_df.iloc[j, i] != correlation_df.iloc[j-1, i] :
#                 #     estimated_dataframe[j-1, i] = y_value_pred
#             else:
#                 # print('Pcoeff insuffisant')
#                 estimated_dataframe_w_lin_reg.iloc[j, i] = np.nan
#
# # Step 3 : Compute estimation length and add values where there is a change in selected correlated dataset
# print("Compute estimation length")
# df_predict_lengths = estimated_dataframe.copy()
# for i in range(len(df_predict_lengths.columns)) : # on parcourt les datasets
# # for i in [8]:  # on parcourt les datasets
#     j=0
#     while j < len(df_predict_lengths.index)-2 : # on parcourt les dates
#         if ~np.isnan(df_predict_lengths.iloc[j,i]):
#             df_predict_lengths.iloc[j, i] = np.nan
#             j=j+1
#         else:
#             L = 0
#             k = j
#             while np.isnan(df_predict_lengths.iloc[k,i]) and k <len(df_predict_lengths.index)-1 and correlation_df.iloc[k, i] == correlation_df.iloc[k + 1, i]:
#                 k=k+1
#                 L=L+1
#             df_predict_lengths.iloc[j:k, i] = L+1
#             j=k
#             if  j <len(df_predict_lengths.index)-2 :
#                 if correlation_df.iloc[j, i] != correlation_df.iloc[j + 1, i] and np.isnan(correlation_df.iloc[j + 1, i]):
#                     j=j+1
#                 if correlation_df.iloc[j, i] != correlation_df.iloc[j + 1, i] and ~np.isnan(correlation_df.iloc[j + 1, i]):
#                     df_predict_lengths.iloc[j, i] = np.nan
#                     df_predict_lengths.iloc[j+1, i] = np.nan
#                     estimated_dataframe.iloc[j, i] = estimated_dataframe_w_lin_reg.iloc[j, i] + df_epsilon.iloc[j-L, i]
#                     estimated_dataframe.iloc[j+1, i] = estimated_dataframe_w_lin_reg.iloc[j, i] + df_epsilon.iloc[j - L, i]
#                     df_predict_lengths.iloc[j-L:j, i] = [L]*L
#                     j=j+2
#
# # Step 4 : Search the more correlated and apply linear regression + compute epsilon left again
# print("Apply linear regression and compute epsilon left again")
# estimated_dataframe_w_lin_reg = estimated_dataframe.copy()
# df_epsilon = estimated_dataframe.copy()
# correlation_df = estimated_dataframe.copy()
# for i in range(len(cleaned_dataframe.columns)) : # on parcourt les datasets
# # for i in [8] : # on parcourt les datasets
#     j=0
#     for j in range(len(estimated_dataframe_w_lin_reg.index)) : # on parcourt les dates
#         if ~np.isnan(df_epsilon.iloc[j, i]):
#             df_epsilon.iloc[j, i] = np.nan
#         if ~np.isnan(correlation_df.iloc[j, i]):
#             correlation_df.iloc[j, i] = np.nan
#         if ~np.isnan(estimated_dataframe_w_lin_reg.iloc[j-1,i]) and np.isnan(estimated_dataframe_w_lin_reg.iloc[j,i]) : # si value = Nan and prec_value isnot Nan
#             col_corr_matrix = corr_matrix.iloc[:,i]  # on regarde la col de la matrice de correlation correspondante à data_i
#             col_corr_matrix = col_corr_matrix.dropna(axis=0)  # on supprime les rows with nan values
#             Nb_datasets_corr = len(col_corr_matrix.index)
#             col_max_corr = col_corr_matrix.idxmax() # On cherche le dataset le plus corrélé
#             n=0
#             while np.isnan(cleaned_dataframe.iloc[j-1,int(col_max_corr[4:])-1]) and np.isnan(cleaned_dataframe.iloc[j,int(col_max_corr[4:])-1]) and n<Nb_datasets_corr-1: # tant que la valeur aux temps j-1 et j du dataset le + corrélé est nan, et que n<31
#                 col_corr_matrix = col_corr_matrix.drop(labels=[col_max_corr]) # on supprime la ligne de la colonne de correlation
#                 col_max_corr = col_corr_matrix.idxmax() # on recherche le dataset le plus corrélé
#                 n = n+1
#             # print('dataset le + corrélé et dont la valeur est dispo = '+ col_max_corr)
#             if col_corr_matrix.max() >= 0.75:
#                 # print('Pcoeff >= 0.75')
#                 x = cleaned_dataframe[col_max_corr]
#                 y = cleaned_dataframe.iloc[:, i]
#                 mask = ~np.isnan(x) & ~np.isnan(y)
#                 slope, intercept, r_value, p_value, std_err = stats.linregress(x[mask], y[mask])
#                 y_value_pred = slope * x.iloc[j] + intercept
#                 y_value_prec_pred = slope * x.iloc[j-1] + intercept
#                 epsilon = estimated_dataframe.iloc[j-1, i] - y_value_prec_pred
#                 df_epsilon.iloc[j, i] = epsilon
# #                estimated_dataframe_w_lin_reg.iloc[j,i]=y_value_pred + epsilon
#                 estimated_dataframe_w_lin_reg.iloc[j, i] = y_value_pred
#                 correlation_df.iloc[j, i] = float(col_max_corr[4:])
#                 # if ~np.isnan(correlation_df.iloc[j-1, i]) and correlation_df.iloc[j, i] != correlation_df.iloc[j-1, i] :
#                 #     estimated_dataframe[j-1, i] = y_value_pred
#             else:
#                 # print('Pcoeff insuffisant')
#                 estimated_dataframe_w_lin_reg.iloc[j, i] = np.nan
#
# # Step 3 : Search the more correlated and apply linear regression + compute epsilon right
# print("Compute epsilon right")
# for i in range(len(cleaned_dataframe.columns)) : # on parcourt les datasets
# # for i in [8]:  # on parcourt les datasets
#     for j in range(len(estimated_dataframe.index)-2,1,-1) : # on parcourt les dates à l'envers
#         if ~np.isnan(estimated_dataframe.iloc[j+1,i]) and np.isnan(estimated_dataframe.iloc[j,i]) : # si value = Nan and prec_value isnot Nan
#             col_corr_matrix = corr_matrix.iloc[:,i]  # on regarde la col de la matrice de correlation correspondante à data_i
#             col_corr_matrix = col_corr_matrix.dropna(axis=0)  # on supprime les rows with nan values
#             Nb_datasets_corr = len(col_corr_matrix.index)
#             col_max_corr = col_corr_matrix.idxmax() # On cherche le dataset le plus corrélé
#             n=0
#             while np.isnan(cleaned_dataframe.iloc[j+1,int(col_max_corr[4:])-1]) and np.isnan(cleaned_dataframe.iloc[j,int(col_max_corr[4:])-1]) and n<Nb_datasets_corr-1: # tant que la valeur aux temps j-1 et j du dataset le + corrélé est nan, et que n<31
#                 col_corr_matrix = col_corr_matrix.drop(labels=[col_max_corr]) # on supprime la ligne de la colonne de correlation
#                 col_max_corr = col_corr_matrix.idxmax() # on recherche le dataset le plus corrélé
#                 n = n+1
#             # print('dataset le + corrélé et dont la valeur est dispo = '+ col_max_corr)
#             if col_corr_matrix.max() >= 0.75:
#                 # print('Pcoeff >= 0.75')
#                 x = cleaned_dataframe[col_max_corr]
#                 y = cleaned_dataframe.iloc[:, i]
#                 mask = ~np.isnan(x) & ~np.isnan(y)
#                 slope, intercept, r_value, p_value, std_err = stats.linregress(x[mask], y[mask])
#                 y_value_pred = slope * x.iloc[j] + intercept
#                 y_value_prec_pred = slope * x.iloc[j + 1] + intercept
#                 epsilon = cleaned_dataframe.iloc[j + 1, i] - y_value_prec_pred
#                 df_epsilon.iloc[j, i] = epsilon
#                 #                estimated_dataframe_w_lin_reg.iloc[j,i]=y_value_pred + epsilon
#
# # Step 4 : Apply ponderated epsilon
# print("Compute interpolation")
# for i in range(len(estimated_dataframe.columns)) :
# # for i in [8]:  # on parcourt les datasets
#     j=0
#     while j < len(df_predict_lengths.index)-1 : # on parcourt les dates
#         if ~np.isnan(estimated_dataframe.iloc[j, i]) or np.isnan(df_predict_lengths.iloc[j, i]) or np.isnan(df_epsilon.iloc[j, i]) or np.isnan(estimated_dataframe_w_lin_reg.iloc[j, i]) :
#             j=j+1
#         else :
#             k = j
#             while np.isnan(estimated_dataframe.iloc[k, i]) and ~np.isnan(df_predict_lengths.iloc[k, i]) and ~np.isnan(df_epsilon.iloc[k, i]) and ~np.isnan(estimated_dataframe_w_lin_reg.iloc[k, i]) :
#                 L = int(df_predict_lengths.iloc[k, i])
#                 epsilon_left = df_epsilon.iloc[j, i]
#                 if ~np.isnan(df_epsilon.iloc[j+L-1, i]):
#                     epsilon_right = df_epsilon.iloc[j + L - 1, i]
#                     estimated_dataframe.iloc[j:j + L, i] = [estimated_dataframe_w_lin_reg.iloc[j + l, i] + (l * epsilon_right + (L - l) * epsilon_left) / L for l in range(L)]
#                 else:
#                     estimated_dataframe.iloc[j:j + L, i] = [estimated_dataframe_w_lin_reg.iloc[j + l, i] + epsilon_left for l in range(L)]
#                 k = k+1
#             j=k
#
#
# for i in estimated_dataframe.columns:
#     plt.plot(estimated_dataframe.index,estimated_dataframe[i],lw=0,marker='.',label=i)
# plt.ylabel('Estimated groundwater level (mNGF)')
# plt.legend()
# plt.grid(True)
# plt.xticks(rotation=45)
# plt.show()
#
# for i in estimated_dataframe.columns:
#     # plt.plot(estimated_dataframe_w_lin_reg.index, estimated_dataframe_w_lin_reg[i], lw=0, marker='.', label=i, color='darkorange')
#     # plt.plot(estimated_dataframe_backward.index, estimated_dataframe_backward[i], lw=0, marker='.', label=i,color='orchid')
#     plt.plot(estimated_dataframe.index, estimated_dataframe[i], lw=0, marker='.', label=i, color='red')
#     plt.plot(cleaned_dataframe.index, cleaned_dataframe[i], lw=0, marker='.', label=i, color='green')
# plt.ylabel('Cleanec groundwater level (mNGF)')
# plt.legend()
# plt.grid(True)
# plt.xticks(rotation=45)
# plt.show()
