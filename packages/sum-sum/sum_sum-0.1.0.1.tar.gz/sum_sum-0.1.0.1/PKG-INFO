Metadata-Version: 2.4
Name: sum-sum
Version: 0.1.0.1
Summary: Minimal CLI tool to summarize any text locally with help of LLM!
Project-URL: homepage, https://github.com/AK3847/sumsum
Author: Abdul Kadir
Author-email: abdulkadir87633@gmail.com
Keywords: Local-LLM,Ollama,text-summarization
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Intended Audience :: End Users/Desktop
Classifier: Operating System :: Microsoft :: Windows :: Windows 8
Classifier: Operating System :: Microsoft :: Windows :: Windows 8.1
Classifier: Operating System :: Microsoft :: Windows :: Windows 10
Classifier: Operating System :: Microsoft :: Windows :: Windows 11
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Utilities
Requires-Python: >=3.8
Requires-Dist: click>=8.1.7
Requires-Dist: huggingface>=0.0.1
Requires-Dist: ollama>=0.3.3
Requires-Dist: requests>=2.32.3
Requires-Dist: rich>=13.9.2
Description-Content-Type: text/markdown

# Sumsum

A minimal CLI tool to locally summarize any text using LLM!

Built around [Ollama](https://github.com/ollama/ollama-python) and [fine-tuned version](https://huggingface.co/AKT47/Llama_3.2_3B_fine_tune_summarization) of [Llama3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)

## Installation:

```terminal
pip install sum-sum
```

## Setup:

- Run the `init` command to check dependency, download model and generate modelfile:
  ```terminal
  sumsum init
  ```

## Usage

- Use the command `run` with your text file path:
  ```terminal
  sumsum run path\to\file.txt
  ```
- you can also use the flag `--verbose` to get additional information:
  (time taken to load the model, time taken for generating new tokens,number of generated tokens etc)
  ```terminal
  sumsum run path\to\file.txt --verbose
  ```
