# @package _global_

data:
  name: CC12M
  type: text_conditional
  img_resolution: 512
  data_resolution: 64
  label_dim: 2048
  num_cond_tokens: 77
  full_batch_size: 2048
  in_channels: 3
  out_channels: 3

  train_instance:
    _partial_: true
    _target_: data.text_dataset.TextWebDataset
    root: ${data_dir}/cc12m/train
    image_transforms: ${data.train_aug}
    train: true
    text_embedding_name: ${model.text_embedding_name}
    vae_embedding_name_mean: ${model.vae_embedding_name_mean}
    return_image: ${model.return_image}
    return_text: ${model.return_text}
    min_image_size: ${data.img_resolution}
    bin_coherence: false
    clip_filter_threshold: 0.0
    aesthetic_threshold: 0.0

  val_instance:
    _partial_: true
    _target_: data.text_dataset.TextDataset
    root: ${data_dir}/cc12m/val
    image_transforms: ${data.val_aug}
    text_embedding_name: ${model.text_embedding_name}
    vae_embedding_name_mean: ${model.vae_embedding_name_mean}
    return_image: ${model.return_image}
    return_text: ${model.return_text}
